work_id,conference_label,conference_short_title,conference_theme_title,conference_year,conference_organizers,conference_series,conference_hosting_institutions,conference_city,conference_state,conference_country,conference_url,work_title,work_url,work_authors,work_type,full_text,full_text_type,full_text_license,parent_work_id,keywords,languages,topics
11705,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Data Diffraction: A Counternarrative to Integration in Digital Humanities Research,,Rabea Kleymann,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>Mixed methods are firmly established in digital humanities (DH) scholarship. While this approach is understood as a research design adopted from social sciences, mixed methods seem to be an umbrella term for defining DH’s methodological framework in general (Sá Pereira 2019; Herrmann 2017). The use of computational procedures in DH is often regarded as a combination of quantitative and qualitative methods. Further conceptual pairs, for example 
                <hi rend=""italic"" xml:space=""preserve"">close </hi>and 
                <hi rend=""italic"">distant reading</hi>, go hand in hand with this. However, mixed methods research rests on two premises (Uprichard and Dawney 2019, 20).
                <note place=""foot"" xml:id=""ftn1"" n=""1"">
                    <p rend=""footnote text""> This paper connects directly to Uprichard & Dawney’s research approach, which already addresses the problem of integration as well as data diffraction in mixed-methods approaches in the social sciences.</p>
                </note> First, the research design indicates that the complexity of an epistemic object is addressed by the plurality of methods used (Fieldling 2012, 127). Second, research data obtained by mixed methods can be integrated. In other words, results of different methodological settings can be put into a coherent narrative. So far integration within mixed methods research is often discussed in a realm of technical challenges concerning data settings, standards and ontologies. Although data integration addresses epistemological and social issues of conformity and interoperability of research data for a global DH community. 
            </p>
            <p>In this short presentation, I argue that integration provides one device to explore questions of difference and diversification within DH scholarship. Therefore, I investigate promises, constraints and pitfalls of the “integration”-narrative, which seems to be deeply enfolded in mixed methods research. The focus of attention will be on compatibilities as well as forms of inferences, which gain relevance manufacturing of knowledge within mixed methods research (Knorr Cetina 1981; Kuhn 1994). In order to tackle these questions, I discuss “data diffraction” (Uprichard and Dawney 2019, 26) – a counternarrative presented by Uprichard and Dawney – as one complementary aim for dealing with different data settings resulting from mixed methods research. What new perspectives open up if we speak of data diffraction instead of data integration? </p>
            <p>The term 
                <hi rend=""italic"">diffraction</hi>, which was originally introduced by Donna Haraway and Karen Barad for epistemological endeavors, initially describes optical interference patterns that arise when two waves are superimposed (Haraway 1992, 300; Barad 2007, 91). Contrary to an holistic idea of integrating parts under a whole, diffraction is about the productive maintenance of differences. Exploring the narrative of data diffraction, this short presentation brings into sharper relief latent integration mechanisms on the one hand, and explore possible alternatives on the other (Drucker 2021, 2; Liu 2020, 130). Beyond or complementary to integration, how could methods or data relate to each other? What if, we explicitly describe diffractions, that is incommensurabilities and dissonances, of methods and data? What would this mean for international collaboration? 
            </p>
            <p>Two examples are shortly discussed in this presentation. The first example brings into focus data integration in the context of mixed methods through ontologies as formal models. Ontologies enable to store and query mixed research data. Therefore, ontologies promise a semantic interoperability that allows different data sets to be integrated with each other (Pidd and Rogers, 2018). But how are different data settings handled? What possibilities do OWL and RDF schemas offer to describe leftovers and surplus of research data? In this context, I speculate about possibilities for data diffraction. One scenario here is ontology hijacking (Eide and Smith-Ore 2019, 188). </p>
            <p>The second example dwells on existing mixed methods approaches from the literary studies, digital stylometry in particular. “DH style studies may be a natural environment for the mixed-methods-paradigm”, as Herrmann has phrased it (Herrmann 2017). In digital stylometry, for instance, authorship attribution with Burrows’ Delta algorithm, agglomerative cluster analysis as well as principal component analysis are widely used (Karsdorp et al. 2021, 248f.). Using the literary category of style, I examine how integration and diffraction might differently enact and constitute style as an object of inquiry within mixed methods research. In doing so, I engage a critical reading of two python scripts from digital stylometry studies. Where does data integration or diffraction actually take place in concrete terms?</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Barad, K.</hi> (2007). 
                        <hi rend=""italic"">Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning</hi>. Durham: Duke Univ. Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Drucker, J.</hi> (2021). Viewpoint: Hetero-ontologies and taxonomies in the wild. 
                        <hi rend=""italic"">Art Libraries Journal</hi> 46 (2), 36–39. 
                        <ref target=""https://doi.org/10.1017/alj.2021.2"">https://doi.org/10.1017/alj.2021.2</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Eide, Ø. and Smith-Ore, C.E.</hi> (2019). Ontologies and data modeling. In Flanders, J. and Jannidis, F. (eds), 
                        <hi rend=""italic"">The shape of data in the digital humanities. Modeling texts and text-based resources</hi>. London/New York, Routledge, pp.178–196.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fielding, N. G.</hi> (2012). Triangulation and Mixed Methods Designs. 
                        <hi rend=""italic"">Journal of mixed methods research</hi> 6 (2): 124–136. 
                        <ref target=""https://doi.org/10.1177/1558689812437101"">https://doi.org/10.1177/1558689812437101</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Haraway, D.</hi> (1992). The Promises of Monsters: A Regenerative Politics for Inappriopriate/d Others. In Grossberg, L., Nelson, C. and Treichler, P. A. (eds), 
                        <hi rend=""italic"">Cultural Studies</hi>. New York, NY, London: Routledge, pp. 295–337.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Herrmann, B. </hi>(2017). In a Test Bed with Kafka. Introducing a Mixed-Method Approach to Digital Stylistics. 
                        <hi rend=""italic"">Digital Humanities Quarterly</hi> 11, (4). 
                        <ref target=""http://www.digitalhumanities.org/dhq/vol/11/4/000341/000341.html"">http://www.digitalhumanities.org/dhq/vol/11/4/000341/000341.html</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Karsdorp, F., Kestemont, M. and Ridell, A. </hi>(2021). 
                        <hi rend=""italic"">Humanities Data Analysis: Case Studies with Python</hi>. Princeton: Princeton University Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Knorr Cetina, K. </hi>(1981). 
                        <hi rend=""italic"">The Manufacture of Knowledge: An Essay on the Constructivist and Contextual Nature of Science</hi>. 1. Edition. Oxford: Pergamon Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Kuhn, T. </hi>(1994). 
                        <hi rend=""italic"">The Structure of Scientific Revolutions</hi>. Chicago: Chicago Univ. Press, 1994.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Liu, A. </hi>(2020). Toward a Diversity Stack: Digital Humanities and Diversity as Technical Problem. 
                        <hi rend=""italic"">PMLA</hi> 135, (1): 130–51. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Pidd, M. and Rogers, K.</hi> (2018). Why Use an Ontology? Mixed Methods Produce Mixed Data. October 18, 2018, 
                        <hi rend=""Hyperlink"">https://talkinghumanities.blogs.sas.ac.uk/2018/10/18/why-use-an-ontology-mixed-methods-produce-mixed-data/</hi> (accessed 20 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Sá Pereira, M. P.</hi> (2019). Mixed Methodological Digital Humanities. In Gold, M. K. and Klein, L. F. (eds), Debates in the Digital Humanities 2019. 5. Minneapolis: University of Minnesota Press, 2019. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Uprichard, E. and Dawney, L.</hi> (2019). Data Diffraction: Challenging Data Integration in Mixed Methods Research. Journal of mixed methods research 13, (1): 19–32. 
                        <hi rend=""Hyperlink"">https://doi.org/10.1177/1558689816674650</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,manufacture of knowledge;mixed methods;new materialism,English,contemporary;english;german;global;history of science;meta-criticism (reflections on digital humanities and humanities computing)
11712,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Towards a Global Analysis of Changes in Shape over Time based on Digitised Artefacts: The East-Asian Perspective,,Giovanni Pala;Lisandra Costiner;Yidan Liu;Shuofei Wang,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">This study tests the use of a novel computational approach, one that analyses changes in shape of historical artefacts across time, in a new context. Previously developed by the authors and tested upon Western art, in particular ancient Greek pottery, this methodology is here applied for the first time to East-Asian art, in particular Chinese vases [1]. The East-Asian perspective is crucial in understanding the adaptability of the approach to different geographical regions and time periods, contributing to the construction of a global history of shape evolution and design progression over time. </p>
            <p style=""text-align: left; "">The study of shapes and styles as embodying the cultural concerns of a particular historical moment has been at the center of several disciplines including art history and archaeology. It has captured the interest of scholars since the eighteenth century when Johann Joachim Winckelmann devised his categorisation of style, focusing particularly on Greek and Roman art [2]. In more recent times, George Kubler proposed new ways of historical sequencing of form based on continuous change across time [3]. In Chinese art, surveys of the development of pottery over time have also been conducted, most recently by Ye Zhemin<hi rend=""Chinese"">叶喆民</hi> [4].</p>
            <p style=""text-align: left; "">The current research inscribes itself within this intellectual tradition yet propose a new way of quantifying changes in shape and exploring connections between objects: a computational technique. A few studies have attempted to move in this direction although they have been restricted by the technology, and materials, namely photographs [5, 6]. This paper employs a new methodology and material, 3D scans of historical artefacts, therefore providing one of the first case studies of corpus research on 3D digitised objects. </p>
            <p style=""text-align: left; "">The approach has been tested on a case study of four Chinese vases of the Beaker type, deriving from late Ming and early Qing Dynasties (1620-1683). These objects are held in the Ashmolean Museum in Oxford, U.K., under ascension numbers EA1978.799, EA1978.798, EA1971.22, and EA1978.1903. These were chosen because of the transformation in shape of beaker vases between the late-Ming and early-Qing Dynasties (1620-1683), due to changing tastes in this period of dynastic transition. This has captured much scholarly interest. Some scholars, such as Geng Baochang <hi rend=""Chinese"">耿宝昌</hi>, Zhu Jun<hi rend=""Chinese"">朱军</hi> and Xu Jingjing<hi rend=""Chinese"">徐菁菁</hi> have examined the changing shapes of vases in this period, noting that appraisers were required to memorise shapes when inspecting and identifying ceramic vases [7, 8, 9]. Other scholars, such as Soame Jenyns and Margaret Medley, applied a topological method of visual analysis of ceramic vases, leading to a revision in their dating [10, 11]. A combination of quantitative methods and topological techniques were used by Ji Dongge
                <hi rend=""Chinese"">纪东歌</hi> and Yu Haiyang <hi rend=""Chinese"">于海洋</hi>, both of whom were interested in the historical and societal influences over shape design and patterns in the two dynasties [12, 13]. This paper proposes a new, quantitative approach to undertake the study of shapes and forms. 
            </p>
            <p style=""text-align: left; "">To analyse the dataset, the vases were captured in three dimensions using photogrammetry, from which a 3D model was built. From the mesh of each model, a random sample of vertices of 1000 points was extracted. The vases were roto-translated and centered so that the orientations were standardised across models. These models were compared by relying on metrics that measured the distance between their distribution of points. In this study, an approximation of the Wasserstein metric, known as the Sinkhorn distance, was used. The benefit of the Wasserstein metric for this comparative approach lies in its capacity to synthetise into one ‘number’ the dissimilarity between two distributions (shapes): the greater the difference, the greater the cost (value) to reposition the points. A pre-existing suite was deployed to implement the algorithm [14, 15]. The Sinkhorn distances are the final output of the analysis. The comparison produced is a series of pairwise distances that can be used to assess the relative closeness or similarity between shapes.</p>
            <p style=""text-align: left; "">This study has outlined the usefulness of this new computational approach for quantifying changes in East-Asian pottery. The method can be scaled to large datasets of 3D objects scans where changes can be computed automatically, without the need for human intervention. As museums and cultural institutions move to digitise their collections in three dimensions, this approach opens new possibilities for the large-scale study of form across time and geographical locations.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend=""western"" style=""text-align: left; "">[1] Pala, G. and Costiner, L. (2022). “Tracing Changes in Shape of Historical Artefacts across Time using 3D Scans: A New Computational Approach”, 
                        <hi rend=""italic"">Journal of Open Humanities Data</hi>, forthcoming. 
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[2] Winckelmann, J. (1764). 
                        <hi rend=""italic"">Johann Winckelmanns, […] Geschichte der Kunst des Alterthums</hi>. Dresden: In der Waltherischen Hof-Buchhandlung. The English translation is Winckelmann, J. (2006), 
                        <hi rend=""italic"" xml:space=""preserve"">The History of the Art of Antiquity. </hi>Los Angeles: Getty Research Institute.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[3] Kubler, G. (1962). 
                        <hi rend=""italic"">The shape of time: Remarks on the history of things</hi>. New Haven: Yale University Press.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[4] Zhemin, Y., <hi rend=""Chinese"">叶喆民</hi> (2011), 
                        <hi rend=""italic"">Zhongguo taoci shi</hi>
                  <hi rend=""Chinese"">中国陶瓷史</hi> [
                        <hi rend=""italic"">History of Chinese Pottery and Porcelain</hi>]. Beijing: SDX Joint Publishing Company. 
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[5] Liming, G., L. Hongjie and J. Wilcock (1989). “The Analysis of Ancient Chinese Pottery and Porcelain Shapes: a Study of Classical Profiles from the Yangshao Culture to the Qing Dynasty Using Computerised Profile Data Reduction, Cluster Analysis and Fuzzy Boundary Discrimination”, in Rahtz, S. (ed.),
                        <hi rend=""italic"" xml:space=""preserve""> Computer Applications and Quantitative Methods in Archaeology</hi>. CAA89 (BAR International Series 548). Oxford: B.A.R., pp. 362-374.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[6] Liying W., and B. Marwick (2020). “Standardization of ceramic shape: A case study of Iron Age pottery from northeastern Taiwan”. 
                        <hi rend=""italic"">Journal of Archaeological Science: Report,</hi> Vol. 33, pp. 1-11. 
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[7] Baochang, G. <hi rend=""Chinese"">耿宝昌</hi> (1993).
                        <hi rend=""italic"" xml:space=""preserve""> Ming Qing ciqi jianding</hi> 
                  <hi rend=""Chinese"">明清瓷器鉴定</hi> [Ming and Qing Porcelain on Inspection]. Beijing: The Palace Museum.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[8] Jun Z. <hi rend=""Chinese"">朱军</hi> (2002). “
                        <hi rend=""italic"">Mingmo Qingchu qinghau huagu jianding</hi> 
                  <hi rend=""Chinese"">明末清初青花花觚鉴定</hi> [A late Ming and early Qing dynasty blue and white goblet identification]”, 
                        <hi rend=""italic"">Wenwu Shijie</hi> 
                  <hi rend=""Chinese"">文物世界</hi> 4, pp. 38-42.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[9] Jingjing, X <hi rend=""Chinese"">徐菁菁</hi> (2017). “
                        <hi rend=""italic"">Mingqing cigu yuanliu ji tezheng</hi>
                  <hi rend=""Chinese"">明清瓷觚源流及特征</hi> [Sources and Characteristics of Ming and Qing beaker vases].” 
                        <hi rend=""italic"">Yishupin</hi> 
                  <hi rend=""Chinese"">艺术品</hi>, 11, pp. 66-73.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[10] Medley, M. (1987). “The Ming-Qing Transition in Chinese Porcelain”, 
                        <hi rend=""italic"">Arts Asiatiques</hi> 42, pp. 65-76.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[11] Jenyns,S. (1955). “The Wares of the Transitional Period Between the Ming and Ch’ing, 1620-1683”, 
                        <hi rend=""italic"">Archives of the Chinese Art Society of Americas</hi> 9, pp. 20-42.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[12] Dongge, J. (2012). <hi rend=""Chinese"">纪东歌</hi>, “
                        <hi rend=""italic"">Qingchuqi Jingdezhen Jinian ciqi fenqi yanjiu</hi> 
                  <hi rend=""Chinese"">清初期景德镇纪年瓷器分期研究</hi>[A staging study of early Qing dynasty Jingdezhen chronological porcelain]”, 
                        <hi rend=""italic"">Zhongguo yishu yanjiu yuan</hi> 
                  <hi rend=""Chinese"">中国艺术研究院</hi>.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[13] Haiyang, Y. (2012) <hi rend=""Chinese"">于海洋</hi>, “
                        <hi rend=""italic"">Mingqing guxing ciqi yanjiu</hi> 
                  <hi rend=""Chinese"">明清觚形瓷器研究</hi> [A study of Ming and Qing beaker vases]”, PhD diss., Jilin Daxue <hi rend=""Chinese"">吉林大学</hi>[Jilin University].
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[14] Point Cloud Utils (pcu) - A Python library for common, 
                        <ref target=""https://github.com/fwilliams/point-cloud-utils"">https://github.com/fwilliams/point-cloud-utils</ref>.
                    </bibl>
                    <bibl rend=""western"" style=""text-align: left; "">[15] Cuturi, M. (2013). 
                        <hi rend=""italic"">Sinkhorn distances: Lightspeed computation of optimal transport. Advances in Neural Information Processing Systems</hi>, 26, pp. 2292-2300.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,3d models;digital humanities;shape analysis,English,"15th-17th century;art history;asia;cultural analytics;data, object, and artefact preservation;design studies;english"
11713,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Tutorial on Fuzzy String Matching with DeezyMatch,,Mariona Coll Ardanuy;Kasra Hosseini;Federico Nanni;Valeria Vitale,workshop / tutorial,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p style=""text-align: left; "">Fuzzy string matching is a common challenge of linking data in many digital humanities projects, which often deal with noisy, historical, or non-standard text (Olieman et al., 2017). Named entities (in particular place names) are often present under a variety of forms, which can range from regional spelling differences to cross-linguistic or diachronic variation, sometimes due to a change in the political and cultural context, to lack of standardization, or to a process of linguistic standardization. In working with digitized materials, an additional, artificial layer of variation can occur, introduced by optical character recognition errors (Butler et al., 2017; Coll Ardanuy and Sporleder, 2017; De Wilde and Hengchen, 2017; van Strien et al., 2020).</p>
                <p style=""text-align: left; "">Several studies have warned of the importance of fuzzy string matching for entity linking, especially in noisy and non-standard text (Coll Ardanuy et al., 2020; De Wilde and Hengchen, 2017; Hachey et al., 2013). However, to date, most entity linking systems rely on either exact or partially overlapping string matching. This is due to the high computation time required by most fuzzy string matching approaches, such as Levenshtein distance (Santos et al., 2018a). In this tutorial, we will introduce DeezyMatch (Hosseini et al., 2020), an open-source, user-friendly Python library for fuzzy string matching and candidate ranking for entity linking that has been developed in the Living with Machines project (https://livingwithmachines.ac.uk/). DeezyMatch builds and expands on Santos et al. (2018b), an approach to fuzzy string matching that uses a deep learning architecture to classify pairs of toponyms as either potentially referring to the same entity or not. DeezyMatch is a tool that integrates recent deep learning advances, and has been specifically designed to be flexible, user-friendly, and fast, and therefore ready to be used in real entity linking scenarios.</p>
                <p style=""text-align: left; "">In this tutorial, we will show how DeezyMatch can be used to mitigate the problem of name variation in noisy, historical, or non-standard data. We will show how to create string pair datasets that can be used to train and test a DeezyMatch model, and how DeezyMatch models can be used to retrieve candidate entities from a gazetteer or knowledge base. By way of motivation, we will provide and discuss some real digital humanities examples which require fuzzy string matching and will show how DeezyMatch can be used to tackle them. During our tutorial, we will focus on the following case studies:</p>
                <list rend=""bulleted"">
                    <item>
                        <hi rend=""bold"">Case study 1:</hi> We will show how a DeezyMatch model can be created from token-level alignments of OCRed text and their manual corrections. We will use the aligned tokens generated in van Strien et al. (2020) using a corpus of OCRed newspaper texts (from the National Library of Australia Trove digitized newspaper collection) that are aligned with human corrections performed by volunteers (Evershed and Fitch, 2014). We will show how to train a DeezyMatch model that learns OCR transformations from newspaper data and will show how it can be used to find a match for a given OCRed query from a pool of potential candidates from a specific knowledge base.
                    </item>
                    <item>
                        <hi rend=""bold"">Case study 2:</hi> We will show how to create DeezyMatch models that are trained on name variations of places, which will enable us to find the best entry in a gazetteer, for a given query. As an example, we will show how these models can be used to consolidate data about names of heritage locations in Arabic speaking countries, like in the Heritage Gazetteer of Libya (https://slsgazetteer.org/). Currently, the high level of spelling variation in Arabic placenames (across time and transcriptions) makes it difficult to consolidate data that lies in different archives and collections, which at the moment rely on perfect string matching to find connections. We will show how DeezyMatch can be used to more easily associate a heritage location to a number of variant names, thus improving accuracy of data and metadata, and facilitating alignment with other knowledge bases such as Wikidata or Geonames.
                    </item>
                </list>
                <p style=""text-align: left; "">This is a hands-on tutorial: participants will be shown how to train a DeezyMatch model and use it for candidate ranking. We will allocate time at the end for discussion, including how to adapt DeezyMatch to different digital humanities projects in different languages and time periods.</p>
                <p style=""text-align: left; "">We will build on the experience gained on providing two different tutorials on DeezyMatch in the past:</p>
                <list rend=""bulleted"">
                    <item>December 2020: ""Linking and Enriching GeoData through Test and Play: a tutorial on DeezyMatch"", as part of the 
                        <hi rend=""italic"">LinkedPasts conference</hi> (Mariona Coll Ardanuy, Kasra Hosseini, Katherine McDonough, and Federico Nanni), followed by a round table. It was held virtually, and there were around 40 participants. Link to the tutorial: 
                        <ref target=""https://github.com/LinkedPasts/LaNC-workshop/tree/main/deezymatch"">https://github.com/LinkedPasts/LaNC-workshop/tree/main/deezymatch</ref>
                    </item>
                    <item>July 2021: ""Best practices in collaborative coding and on using GitFlow for data science research"", as part of the 
                        <hi rend=""italic"">Digital Humanities & Research Software Engineering virtual summer school</hi>, hosted by the Alan Turing Institute. It was held virtually, and there were 25 participants. The focus wat not so much on fuzzy string matching but on collaborative coding. Link to the tutorial: 
                        <ref target=""https://github.com/alan-turing-institute/DH-RSE-Summer-School/tree/main/Day%201/gitflow"">https://github.com/alan-turing-institute/DH-RSE-Summer-School/tree/main/Day%201/gitflow</ref>
                    </item>
                </list>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Outline</head>
                <p style=""text-align: left; "">This is a half-day tutorial which will cover the following core content:</p>
                <list rend=""bulleted"">
                    <item>
                        <hi rend=""bold"">Part 1: Introduction to DeezyMatch and motivation</hi> [60 min]
                        <list rend=""bulleted"">
                            <item>[10 min] Introduction to fuzzy string matching and entity linking</item>
                            <item>[30 min] Description of case studies and data obtaining and preparation</item>
                            <item>[20 min] Overview of DeezyMatch</item>
                        </list>
                    </item>
                    <item>
                        <hi rend=""bold"">Part 2: Interactive hands-on session</hi> [1h20 min]
                        <list rend=""bulleted"">
                            <item>[10 min] Demo 1: candidate ranking using a pre-trained model</item>
                            <item>[20 min] Hands-on exercise</item>
                            <item>[10 min] Touch base</item>
                            <item>[10 min] Demo 2 and hands-on session: DeezyMatch training and candidate ranking</item>
                            <item>[20 min] Hands-on exercise</item>
                            <item>[10 min] Touch base</item>
                        </list>
                    </item>
                    <item>
                        <hi rend=""bold"" xml:space=""preserve"">Part 3: Discussion and feedback </hi>[40 min]
                        <list rend=""bulleted"">
                            <item>[20 min] How to adapt DeezyMatch for your project</item>
                            <item>[20 min] Questions</item>
                        </list>
                    </item>
                </list>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Instructors</head>
                <list rend=""bulleted"">
                    <item>
                        <hi rend=""bold"">Mariona Coll Ardanuy:</hi> Mariona is a computational linguist at the Alan Turing Institute in the Living with Machines project. Her research interests lay in the intersection between the humanities and language technology.
                    </item>
                    <item>
                        <hi rend=""bold"">Kasra Hosseini:</hi> Kasra is a Research Data Scientist at The Alan Turing Institute. He is interested in (artificially) intelligent systems, machine learning, and data analysis and visualisation.
                    </item>
                    <item>
                        <hi rend=""bold"">Federico Nanni:</hi> Federico is a Research Data Scientist at The Alan Turing Institute. He is a historian by training and works exploring the intersections between digital humanities, computational social science, and natural language processing.
                    </item>
                    <item>
                        <hi rend=""bold"">Valeria Vitale:</hi> Valeria Vitale is a researcher in the field of digital cultural heritage. She works at the Alan Turing Institute as Research Associate on the Machines Reading Maps project.
                    </item>
                </list>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Target audience</head>
                <p style=""text-align: left; "">Based on past experience, we believe the number of participants should be 20 at most. Participants should have some experience in programming in Python and running scripts, and ideally be interested in entity linking or fuzzy string matching.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Funding statement</head>
                <p style=""text-align: left; "">This work was supported by Living with Machines (AHRC grant AH/S01179X/1) and The Alan Turing Institute (EPSRC grant EP/N510129/1). The Living with Machines project, funded by the UK Research and Innovation (UKRI) Strategic Priority Fund, is a multidisciplinary collaboration delivered by the Arts and Humanities Research Council (AHRC), with the Alan Turing Institute, the British Library and the Universities of Cambridge, East Anglia, Exeter, and Queen Mary University of London.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" xml:space=""preserve"">Butler, J. O., Donaldson, C. E., Taylor, J. E., and Gregory, I. N. </hi>(2017). Alts, Abbreviations, and AKAs: historical onomastic variation and automated named entity recognition. 
                        <hi rend=""italic"">Journal of Map & Geography Libraries</hi>, 
                        <hi rend=""italic"">13</hi>(1), 58-81.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Coll Ardanuy, M., Hosseini, K., McDonough, K., Krause, A., van Strien, D., and Nanni, F.</hi> (2020). A deep learning approach to geographical candidate selection through toponym matching. In 
                        <hi rend=""italic"">Proceedings of the 28th International Conference on Advances in Geographic Information Systems</hi> (pp. 385-388).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Coll Ardanuy, M., and Sporleder, C.</hi> (2017). Toponym disambiguation in historical documents using semantic and geographic features. In 
                        <hi rend=""italic"">Proceedings of the 2nd International Conference on Digital Access to Textual Cultural Heritage</hi> (pp. 175-180).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">De Wilde, M., and Hengchen, S.</hi> (2017). Semantic enrichment of a multilingual archive with linked open data. 
                        <hi rend=""italic"">Digital Humanities Quarterly</hi>.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Evershed, J., & Fitch, K.</hi> (2014). Correcting noisy OCR: Context beats confusion. In 
                        <hi rend=""italic"">Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage</hi> (pp. 45-51).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Hachey, B., Radford, W., Nothman, J., Honnibal, M., & Curran, J. R.</hi> (2013). Evaluating entity linking with Wikipedia. 
                        <hi rend=""italic"">Artificial intelligence</hi>, 
                        <hi rend=""italic"">194</hi>, 130-150.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Hosseini, K., Nanni, F., and Coll Ardanuy, M.</hi> (2020). DeezyMatch: A flexible deep learning approach to fuzzy string matching. In 
                        <hi rend=""italic"">Proceedings of the 2020 conference on empirical methods in natural language processing: System demonstrations</hi> (pp. 62-69).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Olieman, A., Beelen, K., van Lange, M., Kamps, J., and Marx, M.</hi> (2017). Good applications for crummy entity linkers? the case of corpus selection in digital humanities. In 
                        <hi rend=""italic"">Proceedings of the 13th International Conference on Semantic Systems</hi> (pp. 81-88).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" xml:space=""preserve"">Santos, R., Murrieta-Flores, P., and Martins, B. </hi>(2018). Learning to combine multiple string similarity metrics for effective toponym matching. 
                        <hi rend=""italic"">International journal of digital earth</hi>, 
                        <hi rend=""italic"">11</hi>(9), 913-938.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Santos, R., Murrieta-Flores, P., Calado, P., and Martins, B.</hi> (2018). Toponym matching through deep neural networks. 
                        <hi rend=""italic"">International Journal of Geographical Information Science</hi>, 
                        <hi rend=""italic"">32</hi>(2), 324-348.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Van Strien, D., Beelen, K., Ardanuy, M. C., Hosseini, K., McGillivray, B., and Colavizza, G.</hi> (2020). Assessing the impact of OCR quality on downstream NLP tasks. 
                        <hi rend=""italic"">Special Session on Artificial Intelligence and Digital Heritage: Challenges and Opportunities</hi>, in
                        <hi rend=""italic"" xml:space=""preserve""> Proceedings of the 12th International Conference on Agents and Artificial Intelligence</hi> (pp. 484-496)
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,candidate selection;entity linking;fuzzy string matching;linked data;toponym resolution,English,18th century;19th century;20th century;english;geography and geo-humanities;global;information retrieval and querying algorithms and methods;library & information science;linked (open) data
11719,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"""Archiviz: ""A Tool for the Interactive, Visual Exploration of Digital Archives",,Brad Rittenhouse;Todd Michney;Ines Acosta,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>
                In traditional, paper-based archives, finding aids afford basic means for discovery, but tend to return results shaped by researchers’ preexisting knowledge and queries. With the digitization of archives, new analysis and visualization methods allow researchers to textually map large corpora and not only pinpoint specific materials, but also open new ways of navigation.
                <note place=""end"" xml:id=""end1"" n=""1"">
                    <p rend=""endnote text"">
                        ENDNOTES
                    </p>
                    <p>
                        <hi style=""font-size:12pt"" xml:space=""preserve""> See Graham, S., Milligan, I., and Weingart, S. (2015), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Exploring Big Historical Data: The Historian's Macroscope</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, Imperial College Press, London; Morrissey, R. (2015), “Archives of connection: ‘Whole network’ analysis and social history,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Historical Methods</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 48, no. 2, pp. 67–79; Duff, W., and Haskell, J. (2015), “New uses for old records: A rhizomatic approach to archival access,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">American Archivist</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 78, no. 1, pp. 38-58; Putnam, L. (2016), “The transnational and the text-searchable: Digitized sources and the shadows they cast,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">American Historical Review</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 121, no. 2, pp. 377–402; Edelstein, D., Findlen, P., Ceserani, G., Winterer, C., and Coleman, N. (2017), “Historical research in a digital age: Reflections from the Mapping the Republic of Letters project,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">American Historical Review</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 122, no. 2, pp. 400–424; and Hoekstra, R. and Koolen, M. (2018), “Data scopes for digital history research,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Historical Methods: A Journal of Quantitative and Interdisciplinary History</hi>
                        , vol. 52, no. 2, pp. 79–94.
                    </p>
                </note>
                However, effective use of computational tools including natural language processing (NLP), named entity recognition (NER), and knowledge graphing often requires considerable technical sophistication, forming an access barrier for many researchers.
                <note place=""end"" xml:id=""end2"" n=""2"">
                    <p>
                        <hi style=""font-size:12pt"" xml:space=""preserve""> Piotrowski, M. (2012), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Natural Language Processing for Historical Texts</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, Synthesis Lectures on Human Language Technologies, vol. 17, Morgan & Claypool Publishers, San Rafael; Marrero, M., Urbano, J., Sánchez-Cuadrado, S., Morato, J., and Gómez-Berbís, J.M. (2013), “Named Entity Recognition: fallacies, challenges and opportunities,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Computer Standards and Interfaces</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 35, no. 5, pp. 482–489; Shahin, S. (2016), “When scale meets depth: Integrating Natural Language Processing and textual analysis for studying digital corpora,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Communication Methods and Measures</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 10, no. 1, pp. 28–50; Srinivasa-Desikan, B. (2018), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Natural Language Processing and Computational Linguistics: A Practical Guide to Text Analysis with Python, Gensim, spaCy, and Keras</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, Packt Publishing, Birmingham and Mumbai; Ehrmann, M., Romanello, M., Flückiger, A. and Clematide, S. (2020), “Named Entity Recognition and linking on historical newspapers,” in Arampatzis, A. et al. (eds.), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Experimental IR Meets Multilinguality, Multimodality, and Interaction</hi>
                        , Springer International, Cham, pp. 288–310.
                    </p>
                </note>
            </p>
            <p>
                <hi style=""font-size:12pt"" xml:space=""preserve"">To help bridge this technical gap, we have been developing a toolset, currently funded by an NEH-ODH Digital Humanities Advancement Grant, that integrates large-scale text processing and data visualization capabilities into the open-source </hi>
                <ref target=""https://omeka.org/"">
                    <hi rend=""color(4F81BD)"" style=""font-size:12pt"">Omeka</hi>
                </ref>
                <hi rend=""endnote_reference"">
                    <note place=""end"" xml:id=""end3"" n=""3"">
                        <p rend=""endnote text"">
                            We developed
                            <hi rend=""italic"" style=""font-size:12pt"">Archiviz</hi>
                            for the Omeka Classic version; technical and user support for our plugin will be available in February 2023 in the
                            <ref target=""https://omeka.org/classic/plugins/"">
                                Omeka plugin library
                            </ref>
                            . Additional availability is planned through github and a Docker container for ease of use.
                        </p>
                    </note>
                </hi>
                content management platform. With the tool, users can upload batches of documents, perform NER on them, and manipulate an interactive graph that displays extracted entities (people, places, organizations, etc.) from the collection and how they interconnect in its component documents. The toolset’s components
                <hi rend=""endnote_reference"">
                    <note place=""end"" xml:id=""end4"" n=""4"">
                        <p rend=""endnote text"">
                            The primary tools and plug-ins used to construct Archiviz include Harvard’s
                            <ref target=""https://omeka.org/classic/plugins/Elasticsearch/"">
                                Elasticsearch
                            </ref>
                            <hi style=""font-size:12pt"" xml:space=""preserve"">Omeka plugin for enhanced search capabilities, Google </hi>
                            <ref target=""https://github.com/tesseract-ocr/tesseract"">
                                Tesseract
                            </ref>
                            <hi style=""font-size:12pt"" xml:space=""preserve"">for OCR, </hi>
                            <ref target=""https://spacy.io/"">
                                spaCy
                            </ref>
                            ’s NLP functionality, particularly its NER functionality, with current development focusing on the integration of the Science Museum Group’s
                            <ref target=""https://github.com/TheScienceMuseum/heritage-connector/"">
                                Heritage Connector
                            </ref>
                            for better entity identification, linking, and disambiguation. The graphing of this information is primarily performed with the force-directed graphing of
                            <ref target=""https://d3js.org/"">
                                d3.js
                            </ref>
                            .
                        </p>
                    </note>
                </hi>
                were all specifically developed for (and tested by) non-technical researchers and community advocates, with all computational work taking place in a simple graphical user interface.
            </p>
            <p>
                Our 
                <hi rend=""italic"" style=""font-size:12pt"">Archiviz</hi>
                toolset produces social network-style visualizations that connect results on the basis of the important people, places, organizations, and other entities mentioned. By applying NER to a collection, users can see the full breadth of their research subject at a glance, and explore connections they may not have known exist.
                <hi rend=""endnote_reference"">
                    <note place=""end"" xml:id=""end5"" n=""5"">
                        <p rend=""endnote text"">
                            For a similar application, see Tumbe, C. (2019), ""Corpus linguistics, newspaper archives and historical research methods,"" 
                            <hi rend=""italic"" style=""font-size:12pt"">Journal of Management History</hi>
                            , vol. 25, no. 4, pp. 533–549.
                        </p>
                    </note>
                </hi>
                What our implementation offers that is new, is the efficient display of interrelationships between large numbers of nodes (named entities) combined with the possibility of rapid navigation to search results (documents). In addition, the interface moves beyond traditional query-based archival searching, “flattening” out a collection to show results beyond a researcher’s interests or knowledge.
            </p>
            <figure>
                <graphic n=""1001"" width=""15.91333888888889cm"" height=""8.228180555555555cm"" url=""Pictures/216d68a4a3e47da171317413488654ff.png"" rend=""inline""/>
            </figure>
            <p>
                We are continuing to refine
                <hi rend=""italic"" style=""font-size:12pt"">Archiviz</hi>
                 in ways intended to be intuitive, usable, and readily adoptable by users from a variety of different backgrounds. A primary design goal of the project has been to make it accessible not just to relatively tech-savvy academics, but more importantly, communities beyond the academy. It is our hope that the tool may particularly benefit disadvantaged communities—which in the United States have often faced pressure from gentrification and urban redevelopment, with consequent coercive displacement from historical neighborhoods. Residents in such areas often lack the infrastructure to collect, preserve, and interpret local history. As such, we have partnered with various community groups and activists throughout the process to ensure that the tool can be useful to them. Most ambitiously, in 2019 we hosted a “Community Researcher Workshop” for Atlanta-based librarians, archivists, community organizers, nonprofit staffers, and students to explore the
                <ref target=""https://ivanallen.iac.gatech.edu/mayoral-records/visual/elasticsearch"">
                    <hi rend=""color(4F81BD)"" style=""font-size:12pt"">Mayor Ivan Allen Digital Archive</hi>
                </ref>
                that has served as our first test corpus, using a prototype of our toolset.
                <hi rend=""endnote_reference"">
                    <note place=""end"" xml:id=""end6"" n=""6"">
                        <p>
                            <hi style=""font-size:12pt"" xml:space=""preserve""> On the issues here, see Flinn, A., Stevens, M., and Shepherd, E. (2009), “Whose memories, whose archives? Independent community archives, autonomy and the mainstream,” </hi>
                            <hi rend=""italic"" style=""font-size:12pt"">Archival Science</hi>
                            , vol. 9, no. 71, pp. 71–86.
                        </p>
                    </note>
                </hi>
            </p>
            <p>
                User testing of the interface during this workshop produced very positive feedback, with participants calling the platform “incredibly useful,” with the “potential to break down traditional barriers of why people are hesitant to use archives.” A GLAM (Gallery, Library, Archive, Museum) researcher noted that it “is something almost any archive or library could utilize to their advantage,” while a community advocate stated that she “wanted the information for myself, but also…to share with my fellow residents.” With an additional two years of grant-funded development since this workshop, we are excited to share our work with the DH community. While we have integrated much of the feedback from the workshop, future plans include capabilities to process a wider spectrum of digital, textualized media—documents, video and audio converted to text, and even images identified and categorized with computer vision making our tool relevant for a more diverse array of communities and collections.
                <hi rend=""endnote_reference"">
                    <note place=""end"" xml:id=""end7"" n=""7"">
                        <p rend=""endnote text"">
                            <hi style=""font-size:12pt"" xml:space=""preserve"">Wiriyathammabhum, P., Summers-Stay, D., Fermüller, C., and Aloimonos, Y. (2017), “Computer vision and Natural Language Processing: Recent approaches in multimedia and robotics,” </hi>
                            <hi rend=""italic"" style=""font-size:12pt"">ACM Computing Surveys</hi>
                            , vol. 49, no. 4, pp. 1–44.
                        </p>
                    </note>
                </hi>
            </p>
        </body>
        <back>
            <!-- <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi style=""font-size:12pt"" xml:space=""preserve""> See Graham, S., Milligan, I., and Weingart, S. (2015), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Exploring Big Historical Data: The Historian's Macroscope</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, Imperial College Press, London; Morrissey, R. (2015), “Archives of connection: ‘Whole network’ analysis and social history,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Historical Methods</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 48, no. 2, pp. 67–79; Duff, W., and Haskell, J. (2015), “New uses for old records: A rhizomatic approach to archival access,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">American Archivist</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 78, no. 1, pp. 38-58; Putnam, L. (2016), “The transnational and the text-searchable: Digitized sources and the shadows they cast,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">American Historical Review</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 121, no. 2, pp. 377–402; Edelstein, D., Findlen, P., Ceserani, G., Winterer, C., and Coleman, N. (2017), “Historical research in a digital age: Reflections from the Mapping the Republic of Letters project,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">American Historical Review</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 122, no. 2, pp. 400–424; and Hoekstra, R. and Koolen, M. (2018), “Data scopes for digital history research,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Historical Methods: A Journal of Quantitative and Interdisciplinary History</hi>
                        , vol. 52, no. 2, pp. 79–94.
                    </bibl>
                    <bibl>
                        <hi style=""font-size:12pt"" xml:space=""preserve""> Piotrowski, M. (2012), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Natural Language Processing for Historical Texts</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, Synthesis Lectures on Human Language Technologies, vol. 17, Morgan & Claypool Publishers, San Rafael; Marrero, M., Urbano, J., Sánchez-Cuadrado, S., Morato, J., and Gómez-Berbís, J.M. (2013), “Named Entity Recognition: fallacies, challenges and opportunities,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Computer Standards and Interfaces</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 35, no. 5, pp. 482–489; Shahin, S. (2016), “When scale meets depth: Integrating Natural Language Processing and textual analysis for studying digital corpora,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Communication Methods and Measures</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, vol. 10, no. 1, pp. 28–50; Srinivasa-Desikan, B. (2018), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Natural Language Processing and Computational Linguistics: A Practical Guide to Text Analysis with Python, Gensim, spaCy, and Keras</hi>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">, Packt Publishing, Birmingham and Mumbai; Ehrmann, M., Romanello, M., Flückiger, A. and Clematide, S. (2020), “Named Entity Recognition and linking on historical newspapers,” in Arampatzis, A. et al. (eds.), </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Experimental IR Meets Multilinguality, Multimodality, and Interaction</hi>
                        , Springer International, Cham, pp. 288–310.
                    </bibl>
                    <bibl rend=""endnote text"">
                        We developed
                        <hi rend=""italic"" style=""font-size:12pt"">Archiviz</hi>
                        for the Omeka Classic version; technical and user support for our plugin will be available in February 2023 in the
                        <ref target=""https://omeka.org/classic/plugins/"">
                            Omeka plugin library
                        </ref>
                        . Additional availability is planned through github and a Docker container for ease of use.
                    </bibl>
                    <bibl rend=""endnote text"">
                        The primary tools and plug-ins used to construct Archiviz include Harvard’s
                        <ref target=""https://omeka.org/classic/plugins/Elasticsearch/"">
                            Elasticsearch
                        </ref>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">Omeka plugin for enhanced search capabilities, Google </hi>
                        <ref target=""https://github.com/tesseract-ocr/tesseract"">
                            Tesseract
                        </ref>
                        <hi style=""font-size:12pt"" xml:space=""preserve"">for OCR, </hi>
                        <ref target=""https://spacy.io/"">
                            spaCy
                        </ref>
                        ’s NLP functionality, particularly its NER functionality, with current development focusing on the integration of the Science Museum Group’s
                        <ref target=""https://github.com/TheScienceMuseum/heritage-connector/"">
                            Heritage Connector
                        </ref>
                        for better entity identification, linking, and disambiguation. The graphing of this information is primarily performed with the force-directed graphing of
                        <ref target=""https://d3js.org/"">
                            d3.js
                        </ref>
                        .
                    </bibl>
                    <bibl rend=""endnote text"">
                        For a similar application, see Tumbe, C. (2019), ""Corpus linguistics, newspaper archives and historical research methods,"" 
                        <hi rend=""italic"" style=""font-size:12pt"">Journal of Management History</hi>
                        , vol. 25, no. 4, pp. 533–549.
                    </bibl>
                    <bibl>
                        <hi style=""font-size:12pt"" xml:space=""preserve""> On the issues here, see Flinn, A., Stevens, M., and Shepherd, E. (2009), “Whose memories, whose archives? Independent community archives, autonomy and the mainstream,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Archival Science</hi>
                        , vol. 9, no. 71, pp. 71–86.
                    </bibl>
                    <bibl rend=""endnote text"">
                        <hi style=""font-size:12pt"" xml:space=""preserve"">Wiriyathammabhum, P., Summers-Stay, D., Fermüller, C., and Aloimonos, Y. (2017), “Computer vision and Natural Language Processing: Recent approaches in multimedia and robotics,” </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">ACM Computing Surveys</hi>
                        , vol. 49, no. 4, pp. 1–44.
                    </bibl>
                </listBibl>
            </div> -->
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,digital archives;digital tools;knowledge graphing;ner;nlp,English,"20th century;contemporary;design studies;digital archiving;english;history;interface design, development, and analysis;north america"
11728,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,An experiment in agent-based probabilistic city population reconstruction,,Ivan Kisjes;Leon van Wissen,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p rend=""LO-normal"">Reconstructing past population configurations is no easy task, even when detailed demographic information exists such as birth, death and marriage records (e.g. Bailey et al. 2020, Efremova 2016). Reconstruction is necessary to be able to disambiguate and link people mentioned across various historic sources. The best way to do it is by hand, but that is prohibitively labor intensive. For automatic methods, name and spelling variations and uncertain relations between mentioned names present large problems (see e.g. Idrissou et al. 2018). Missing information does, too: demographic records tend not to include information on migrations into or out of the city in question, in our case Amsterdam.</p>
            <p rend=""LO-normal"">Methods that are being tried tend to reconstruct individuals on the basis of detected name identifications and their relations to other mentioned names (e.g. Bloothooft et al 2015, Bailey et al. 2020). While this seems promising, it fails to include other information we may make use of: demographic and biological statistics (e.g. Störmer 2018, Alter and Clark 2010). Using the latter, we should be able to identify a person mentioned with one name in a certain source with the same person mentioned in another by only a nickname without being dependent on related names being mentioned as well.</p>
            <p rend=""LO-normal"">We explore employing a temporal, iterative agent interaction model, similar to those used in biological population evolution models (e.g. Toni and Stumpf, 2010, Marchetti et al 2017,Levin et al 1997). We set up a Python actor model using 
                <ref target=""https://mesa.readthedocs.io/en/stable"">
                    <hi rend=""underline color(1155CC)"">MESA</hi>
                </ref> (Kazil et al. 2020) that can iterate over time and has access to all birth, death and marriage ‘events’ that are known from the archival records. We iterate over a 50-year sample in the dataset (for Amsterdam data is available from ca. 1600 through 1940, we use 1750-1800 as a test case).
            </p>
            <p rend=""LO-normal"">Each year, all names mentioned in ‘events’ in that year become actors (in the model sense). So if there is a birth record, the name of the child will be ‘born’ in that year, and the parents become actors that have children. The actors then decide how they ended up existing in that year: are they representations of actors that already exist in the current model because of a mention in a previous year? Are they new migrations into the city? Are they births of new citizens, or perhaps deaths of previously known or unknown actors? Do they (re)marry, should they have been married before that year? Actors make these decisions based on the event, their existing relations within the currently running model, and probability.</p>
            <p rend=""LO-normal"">The decisions the actors make are based on statistics of the population in question combined with biological statistics and limitations. For example, it is very unlikely that people in the dataset live longer than 130 years, but very young children also die often, so mortality probability changes over an actor’s lifespan. But we also know that mortality rates are not constant over the whole timespan – certain years may have seen disasters, increasing mortality (see e.g. Aberth 2013, Jensen 2019), and others may have seen immigration waves, increasing population size without a higher birth rate. Other basic probabilities also affect the model: e.g. women rarely have children before age 11 or after age 60, and unmarried women are more likely to be childless than married ones.</p>
            <p rend=""LO-normal"">Running this model we end up with a temporally changing network that we can evaluate in different ways in order to approximate historic reality. First, we can use general demographic knowledge to evaluate it, for example known population sizes (e.g. Lourens and Lucassen 1997, Paping 2014, Frijhoff et al 2006 etc.), mortality rates, birth rate estimations etc. (e.g. Heathcote 2001). Secondly, we can use network properties (e.g. population spikiness, average number of children, average age etc.) to evaluate. A third way is to deduce how ‘solid’ each actor’s life is, recording e.g. whether they have parents, whether the parents have the same last name as themselves, whether they have any relations to others in the model at all, whether they have only one or multiple mentions in the records etc. A fourth way is to compare them to known prosopographic data (we use ECARTICO). We test each of these methods and combine them into a meta-evaluation method.</p>
            <p rend=""LO-normal"">Re-running the model many times, resulting in different models, we evaluate each in order to select the one best approximating reality and will discuss our findings.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Aberth, John</hi> (2013): 
                        <hi rend=""italic"">From the Brink of the Apocalypse: Confronting Famine, War, Plague and Death in the Later Middle Ages</hi>. 2nd Edition 2013, First Published 2010
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Alter, G., & Clark, G</hi>. (2010). 
                        <hi rend=""italic"">The demographic transition and human capital</hi>. In S. Broadberry & K. O'Rourke: The Cambridge Economic History of Modern Europe, pp. 43-69. Cambridge: Cambridge University Press. doi:10.1017/CBO9780511794834.004
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Bayley, Martha J., Connor Cole, Morgan Henderson and Catherine Massey</hi> (2020): 
                        <hi rend=""italic"">How Well Do Automated Linking Methods Perform? Lessons from US Historical Data</hi>. Journal of Economic Literature Vol.. 58, NO. 4, December 2020 (pp. 997-1044)
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Bloothooft, Gerrit, Peter Christen, Kees Mandemakers and Marijn Schraagen</hi> (2015): 
                        <hi rend=""italic"">Population Reconstruction</hi>. Springer
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Efremova, I.</hi> (2016). 
                        <hi rend=""italic"">Mining social structures from genealogical data</hi>. Technische Universiteit Eindhoven.
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Frijhoff, W., M. Prak and M. Hel</hi> (2006):
                        <hi rend=""italic"" xml:space=""preserve""> Geschiedenis van Amsterdam, II-2, Zelfbewuste stadstaat 1650-1813.</hi> Bijdragen en mededelingen betreffende de geschiedenis der Nederlanden 121(3):500 DOI:10.18352/bmgn-lchr.6475
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Heathcote C., Higgins T.</hi> (2001) A Regression Model of Mortality, with Application to the Netherlands. In: Tabeau E., van den Berg Jeths A., Heathcote C. (eds) Forecasting Mortality in Developed Countries. European Studies of Population, vol 9. Springer, Dordrecht. https://doi.org/10.1007/0-306-47562-6_3
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Idrissou, A., Zamborlini, V., Latronico, C., van Harmelen, F., & van den Heuvel, C. M. J. M.</hi> (2018). 
                        <hi rend=""italic"">Amsterdamers from the Golden Age to the Information Age via Lenticular Lenses</hi>: Short paper.
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Jensen, L.E.</hi> (2019): 
                        <hi rend=""italic"">'Disaster upon Disaster Inflicted on the Dutch'. Singing about Disasters in the Netherlands, 1600-1900</hi>. Bijdragen en Mededelingen Betreffende de Geschiedenis der Nederlanden, 134, 2, (2019), pp. 45-70 https://doi.org/10.18352/bmgn-lchr.10449
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Kazil, Jackie, David Masad, and Andrew Crooks</hi> (2020): 
                        <hi rend=""italic"">Utilizing Python for Agent-Based Modeling: The Mesa Framework</hi>. In Robert Thomson, Halil Bisgin, Cristopher Dancy,Ayaz Hyder and Muhammad Hussain: Social, Cultural, and Behavioral Modeling. Springer International Publishing
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Levin, Simon A., Bryan Grenfell, Alan Hastings, Alan S. Perelson</hi> (1997): 
                        <hi rend=""italic"">Mathematical and Computational Challenges in Population Biology and Ecosystems Science</hi>. Science 1997 Vol 275, Issue 5298 pp. 334-343 DOI: 10.1126/science.275.5298.334
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Lourens, Piet, and Jan Lucassen</hi> (1997): 
                        <hi rend=""italic"">Inwonertallen van Nederlandse steden ca. 1300-1800</hi>. Amsterdam: Vereniging Het Nederlandsch Economisch-Historisch Archief..
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Marchetti, Luca, Corrado Priami and Vo Hong Tanh</hi> (2017): 
                        <hi rend=""italic"">Simulation Algorithms for Computational Systems Biology</hi>. 2017 Springer 331963111X 
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Newton, G., & Bennett, R.</hi> (2020). 
                        <hi rend=""italic"">Record-linkage of entrepreneurs in the England and Wales Censuses 1851-91 using BBCE and I-CeM</hi>. https://doi.org/10.17863/CAM.50178
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Paping, Richard</hi> (2014): 
                        <hi rend=""italic"">General Dutch Population development 1400-1850</hi>. 1st ESHD conference, Italy
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Störmer, Charlotte, Corry Gellatly, Anita Boele, and Tine De Moor</hi> (2017): 
                        <hi rend=""italic"">Long-Term Trends in Marriage Timing and the Impact of Migration, the Netherlands (1650-1899)</hi>. Historical Life Course Studies 6 (December):40-68. https://doi.org/10.51964/hlcs9327.
                    </bibl>
                    <bibl rend=""LO-normal"">
                        <hi rend=""bold"">Toni, Tine, Stumpf, Michael P.H</hi> (2010): 
                        <hi rend=""italic"">Simulation-based model selection for dynamical systems in systems and population biology.</hi> Bioinformatics, Volume 26, Issue 1, 1 January 2010, Pages 104–110, https://doi.org/10.1093/bioinformatics/btp619.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,agent-based modeling;demographics;population reconstruction,English,"18th century;digital biography, personography, and prosopography;english;europe;global;history;software development, systems, analysis and methods"
11742,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Processes and Practicalities in Developing and Sustaining a Text Mining Platform: Gale Digital Scholar Lab,,Sarah Ketchley;Jess Ludwig,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">Gale Digital Scholar Lab was developed in 2018 to fulfil requests for a platform for text mining primary source documents without necessarily having to learn to code in Python or R. Based on beta-testing user interviews, it was determined that some of the most significant barriers to entry into the field of text-based digital humanities data mining include not knowing how or where to start in order to build a DH project, not having time to gather a significant data set or to clean and organize data for analysis, and having limited institutional infrastructure and support for projects that include text mining methodologies. In designing the DS Lab, the goal was to provide a scaffolded experience for users new to the field of digital humanities, while offering options for extensibility for researchers with established projects. This included providing pathways for research, teaching and learning by both students, faculty, and librarians.</p>
            <p style=""text-align: left; "">The DS Lab has been iteratively developed since its first release, with updates including tool enhancements and support for pedagogical use of the platform, and more recently a platform migration, workflow tweaks and improved accessibility. The DS Lab integrates six GUI-based tools for conducting text analysis of primary source archives and user-uploaded plaintext documents. These tools comprise Named Entity Recognition, Sentiment Analysis, Ngrams, Parts of Speech Tagging, Topic Modeling and Clustering. Recognizing that quality of OCR text is key in achieving meaningful analysis outputs, the DS Lab also presents options for text cleaning as part of the curation process. Import and export of text and metadata are also supported.</p>
            <p style=""text-align: left; "">To orient users who are new to the field of DH to the workflow and outcomes, the platform incorporates an extensive Learning Center with contextual help documentation including brief recorded videos, images, text, and sample projects. Similarly, for teachers who are looking for ideas or additional support in the platform, there are draft syllabi, outline learning objectives, and downloadable project outlines.</p>
            <p style=""text-align: left; "">This 10-minute talk will focus on describing the process and challenges of developing the DS Lab interface, meeting the often-competing demands of balancing developer time, the scope of individual project sprints, and projected cost. Consideration will be given to the workflows which were successful as well as those that needed to be adapted or scrapped altogether. It will discuss using personas to design the features and functionality in the platform, and the advantages and drawbacks of doing so. The development of the Learning Centre is a case in point, since its development drew on a range of internal and external expertise such as academic advisors, curriculum developers, and UX designers as well as in-house software and content engineers, metadata and content architects and the product and archives team. This collaborative undertaking took considerable management to balance expectations and outcomes, and to ensure that communication flowed clearly. These considerations are not unique to the Gale Digital Scholar Lab development project but can be extrapolated to other similar DH projects. The intent of the talk is to highlight how the lessons learned by the Gale development team and external stakeholders can be used to provide guidance for others.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">Besette, Lee. (2012). “Challenges in Digital Humanities.” 
                        <hi rend=""italic"">Inside Higher Ed.</hi>
                        https://www.insidehighered.com/blogs/college-ready-writing/challenges-digital-humanities. Accessed 16 March 2022.</bibl>
                    <bibl style=""text-align: left; "">Campese, C., Thiago Bertolini, d. S., Lorena Pereira, d. C., & Janaina Mascarenhas, H. C. 
                        (2019). 
                        <hi rend=""italic"">User stories method and assistive technology product development: A new approach to requirements elicitation</hi>. Cambridge: Cambridge University Press. doi:http://dx.doi.org/10.1017/dsi.2019.385
                    </bibl>
                    <bibl style=""text-align: left; "">Coutu, Diane. (2015). “Why Teams Don’t Work.” 
                        <hi rend=""italic"">Harvard Business Review.</hi> https://hbr.org/2009/05/why-teams-dont-work. Accessed 25 Apr. 2022.
                    </bibl>
                    <bibl style=""text-align: left; "">Currier, Brent D. (2017). “They Think all of this is new: Leveraging Librarians’ Project Management Skills for the Digital Humanities.” 
                        <hi rend=""italic"">College & Undergraduate Libraries</hi> 24, 270-289. 
                        <ref target=""https://doi.org/10.1080/10691316.2017.1347541"">https://doi.org/10.1080/10691316.2017.1347541</ref>
                    </bibl>
                    <bibl style=""text-align: left; "">Dingsøyr, Torgeir, et al. (2018). “Coordinating Knowledge Work in Multiteam Programs: Findings From a Large-Scale Agile Development Program.” 
                        <hi rend=""italic"">Project Management Journal</hi>, vol. 49, no. 6. 64–77, doi:10.1177/8756972818798980.
                    </bibl>
                    <bibl style=""text-align: left; "">Gratton, Lynda, and Tamara J. Erickson. (2016). “Eight Ways to Build Collaborative Teams.” 
                        <hi rend=""italic"">Harvard Business Review</hi>. hbr.org/2007/11/eight-ways-to-build-collaborative-teams. Accessed 25 Apr. 2022.
                    </bibl>
                    <bibl style=""text-align: left; "">Jenkins, Nick. (2008) 
                        <hi rend=""italic"">A Software Testing Primer An Introduction to Software Testing</hi>. San Francisco: Creative Commons.
                    </bibl>
                    <bibl style=""text-align: left; "">Nielsen, Jakob. (nd). “Why You Only Need to Test with 5 Users.” 
                        <hi rend=""italic"">Nielsen Norman Group</hi>. 
                        <hi rend=""italic"">www.nngroup.com</hi>, 
                        <hi rend=""underline"">https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/</hi>. Accessed 30 Apr. 2022.
                    </bibl>
                    <bibl style=""text-align: left; "">Siemens, L. (2011). The Balance between On-line and In-person Interactions: Methods for the Development of Digital Humanities Collaboration. 
                        <hi rend=""italic"">Digital Studies/le Champ Numérique</hi>, 
                        <hi rend=""italic"">2</hi>(1). DOI: 
                        <ref target=""http://doi.org/10.16995/dscn.259"">http://doi.org/10.16995/dscn.259</ref>. Accessed 16 March 2022.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,development;project-management;text-mining,English,"contemporary;curricular and pedagogical development and analysis;english;global;history;humanities computing;interface design, development, and analysis"
11743,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Poetry as Error. A ‘Tool Misuse’ Experiment on the Processing of German Language Poetry,,Henny Sluyter-Gäthje;Peer Trilcke,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">
                <hi rend=""bold"">1. Research question</hi>
            </p>
            <p style=""text-align: left; "">In Computational Literary Studies texts are typically pre-processed with Natural Language Processing (NLP) tools. However, due to historical and/or aesthetic characteristics, literary texts sometimes deviate notably from the data the tools are trained on. Due to this difference in domain, the performance of the tools drops (Scheible et al., 2011; Rayson et al., 2007; Herrmann, 2018; Bamman, 2020). Instead of considering this to be a problem, the ‘erroneousness’ of the tools could provide a computational understanding of the ‘deviance of literary texts’; produced errors might reveal something about the characteristics of literature.</p>
            <p style=""text-align: left; "">In the following, we report on a 
                <hi rend=""italic"">Tool Misuse</hi> experiment on German lyric poetry – a genre that is usually associated with a high degree of deviance (Müller-Zettelmann, 2000: 100; Zymner, 2019: 29–30) – in which we develop a pipeline that provokes tokenization, lemmatization and POS tagging 'errors' of NLP tools and typologises these 'errors' in a rule-based way. 
            </p>
            <p style=""text-align: left; "">
            <hi rend=""bold"">2. Operationalization</hi>
         </p>
            <figure>
                <graphic n=""1001"" width=""15.920861111111112cm"" height=""8.528402777777778cm"" url=""Pictures/a2db260a3aba82fe4a88712f797527c3.png"" rend=""inline""/>
                <head>Pipeline for error typing of the corpora.</head>
            </figure>
            <p style=""text-align: left; "">Since gold standard annotations are not available for our scenario, we base our evaluation on the assumption that correctly produced lemmas can be found in dictionaries of German language. Based on the 
                <ref target=""https://textgridrep.org/"">TextGridRepository</ref>, we build a canon-based corpus of 'prototypical' German-language poetry comprising 5,144 poems. For comparison, we use a prose corpus of 100 German-language novels from the 19th century, compiled from the TextGridRepository and 
                <ref target=""https://www.projekt-gutenberg.org/"">Project Gutenberg</ref>. As dictionaries we use ‘GermaNet‘ (Hamp & Feldweg, 1997; Henrich & Hinrichs, 2010) and the ‘Digitales Wörterbuch der deutschen Sprache‘ (Klein & Geyken, 2010). To ensure that the resulting errors are not tagger specific, we use several NLP tools for tokenization, lemmatization and POS tagging of the corpora (fig. 01) and consider all content word types as potential errors that are lemmatized by at least two tools and for which none of the produced lemmas are found in the dictionaries (fig. 02, column ""pFail"").
            </p>
            <p style=""text-align: left; "">Our 'error pipeline' prefers recall over precision, thus it produces only circumstantial evidence of potential errors. A larger number of false positives is to be expected, because we process out-of-vocabulary words of the dictionaries.</p>
            <figure>
                <table rend=""rules"">
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default""/>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Poetry</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Poetry</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Prose</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Prose</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default""/>
                        <cell style=""text-align: left;"" rend=""DH-Default"">all</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">pFail</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">All</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">pFail</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Types</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">70,422</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">24,244</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">263,042</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">115,785</cell>
                    </row>
                </table>
                <head>Number of word types (NOUN, VERB, ADJECTIVE) for the entire corpus (""all"") and for the sets with potential errors (""pFail"").</head>
            </figure>
            <p style=""text-align: left; "">
                <hi rend=""bold"">3. Analysis</hi>
            </p>
            <p style=""text-align: left; "">Based on manual inspections of the pFail set, we postulate 13 error types described in figure 03. For each type we formulate a rule
                <note place=""foot"" xml:id=""ftn1"" n=""1"">
                    <p rend=""footnote text""> For the rules see: 
                        <ref target=""https://gitup.uni-potsdam.de/sluytergaeth/poetry_as_error"">https://gitup.uni-potsdam.de/sluytergaeth/poetry_as_error</ref>
                    </p>
                </note> which is then applied to the pFail set following the order of the error types listed below. Multiple typings are not possible.
            </p>
            <figure>
                <graphic n=""1002"" width=""16.002cm"" height=""16.69873611111111cm"" url=""Pictures/0960c097bf9db429b9efb0b418c600c6.png"" rend=""inline""/>
                <head>Description of error types.</head>
            </figure>
            <p style=""text-align: left; "">
            <hi rend=""bold"">4. Results</hi>
         </p>
            <figure>
                <graphic n=""1003"" width=""12.272141666666666cm"" height=""12.483169444444444cm"" url=""Pictures/f3d5d7e4292c1cc925909a7a425d92ac.png"" rend=""inline""/>
                <head>Relative frequency for the types of potential errors for the two pFail sets.</head>
            </figure>
            <p style=""text-align: left; "">53.33 % of the word types in the pFail set for poetry and 59.88 % of the word types in the pFail set for prose are identified. PUNC and SHORT are predominantly sub-word level characters, mostly noise which appears to a comparable extent in poetry and prose. ORTH_SZ reflects the effect of Historical Orthography which a normalisation step could remedy.</p>
            <p style=""text-align: left; "">The ten remaining types can be combined into three groups:</p>
            <list type=""unordered"">
                <item>COMP_DASH, COMP, PART_ ADJECTIVE, PREFIXED gather 
                    <hi rend=""italic"">Creative Lexis</hi>, i.e. word formation mechanisms (composition, derivation); these are often out-of-vocabulary words and therefore pipeline errors, not tool errors. In poetry, 45.25 % of the ""pFail"" set can be assigned to this group, in prose 57.09 %. 
                </item>
                <item>As expected, the pipeline produces a higher error rate for poetry (0.62 %) than for prose (0.02 %) for ORTH_UPPER, which identifies a characteristic of 
                    <hi rend=""italic"">Lyric Typography</hi> (capitalizing first letters in lines). 
                </item>
                <item>The error rate of 
                    <hi rend=""italic"">Prosodic Deformation</hi> consisting of ELISION_APO, ELISION_SIMPLE, ELISION_END, EPITHESIS and CONTRACT is also higher for poetry than for prose (6.62 % compared to 1.93 %). We assume that the deformations are due to the addition or deletion of vowels for metric reasons.
                </item>
            </list>
            <p style=""text-align: left; "">5. Outlook</p>
            <p style=""text-align: left; "">Our pipeline identifies 
                <hi rend=""italic"">Prosodic Deformation</hi>, 
                <hi rend=""italic"">Lyric Typography</hi> and 
                <hi rend=""italic"">Creative Lexis</hi> as typical sources of error when processing poetry with NLP tools. However, our pipeline needs to be optimized: too many potential errors are, as in the case of 
                <hi rend=""italic"">Creative Lexis</hi>, in fact not tool errors but pipeline errors. Additionally, our rule-based typology is only able to describe 53.33 % of the pFail set. This reveals two areas for follow-up research: the pipeline could be improved on to decrease the number of pipeline errors and the rule-based typologisation procedure could be optimized against our baseline.
            </p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Bamman, D.</hi> (2020). LitBank: Born-Literary Natural Language Processing. [Preprint]. https://people.ischool.berkeley.edu/~dbamman/pubs/pdf/Bamman_DH_Debates_CompHum.pdf [Last accessed November 16, 2021].
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Braam, H.</hi> (2019). 
                        <hi rend=""italic"">Die berühmtesten deutschen Gedichte. Auf der Grundlage von 300 Gedichtsammlungen</hi>. Stuttgart: 2. Aufl., Kröner.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Hamp, B. and Feldweg, H.</hi> (1997). GermaNet - a Lexical-Semantic Net for German. In 
                        <hi rend=""italic"">Proceedings of the ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications</hi>. Madrid, Spain, pp. 9–15. https://aclanthology.org/W97-0802.pdf [Last accessed November 16, 2021]. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Henrich, V. and Hinrichs, E.</hi> (2010). GernEdiT - The GermaNet Editing Tool. In 
                        <hi rend=""italic"">Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC 2010)</hi>, Valletta, Malta, pp. 2228-35. http://www.lrec-conf.org/proceedings/lrec2010/pdf/264_Paper.pdf [Last accessed November 16, 2021].
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Herrmann, J. B</hi>. (2018). Praktische Tagger-Kritik. Zur Evaluation des PoS-Tagging des Deutschen Textarchivs. In 
                        <hi rend=""italic"" xml:space=""preserve"">DHd2018: Kritik der digitalen Vernunft. Book of Abstracts. </hi>Cologne, Germany, pp. 287-90. https://zenodo.org/record/3684897#.YO_x1W5CTOQ [Last accessed November 16, 2021].
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Honnibal, M. et al.</hi> (2020). spaCy: Industrial-strength Natural Language Processing in Python. Zenodo. https://doi.org/10.5281/zenodo.1212303 [Last accessed November 16, 2021]. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Klein, W. and Geyken, A.</hi> (2010). Das ‘Digitale Wörterbuch der Deutschen Sprache DWDS’, in: Lexicographica 26: 79–96.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Müller-Zettelmann, E.</hi> (2000). 
                        <hi rend=""italic"">Lyrik und Metalyrik. Theorie einer Gattung und ihrer Selbstbespiegelung anhand von Beispielen aus der englisch- und deutschsprachigen Dichtkunst</hi>. Heidelberg, Germany, Winter.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Qi, P. et al.</hi> (2018). Universal dependency parsing from scratch, in: 
                        <hi rend=""italic"">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</hi>, Brussels, Belgium, pp. 160-70.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Rayson, P. et al.</hi> (2007). Tagging the bard: Evaluating the accuracy of a modern POS tagger on Early Modern English corpora. In 
                        <hi rend=""italic"">Proceedings of Corpus Linguistics (CL2007)</hi>. https://eprints.lancs.ac.uk/id/eprint/13011/1/192_Paper.pdf [Last accessed November 16, 2021]. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Schmid, H.</hi> (1994). Probabilistic part-of speech Tagging using decision trees. In 
                        <hi rend=""italic"">Proceedings of International Conference on New Methods in Language Processing</hi>, Manchester, UK, pp. 154-62.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Schmid, H.</hi> (1995). Improvements in Part-of-Speech Tagging with an Application to German. In 
                        <hi rend=""italic"">Proceedings of the ACL SIGDAT-Workshop</hi>, Dublin, Ireland, 13-25. https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger2.pdf [Last accessed November 16, 2021]. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Schmid, H</hi>. (2019). Deep learning-based morphological taggers and lemmatizers for annotating historical texts. 
                        <hi rend=""italic"">In Proceedings of the 3rd international conference on digital access to textual cultural heritage</hi>, Brussels, Belgium, 133-37.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Scheible, S. et al.</hi> (2011). A gold standard corpus of Early Modern German. In: 
                        <hi rend=""italic"">Proceedings of the 5th Linguistic Annotation Workshop</hi>, pp. 124–28. https://dl.acm.org/doi/abs/10.5555/2018966.2018981 [Last accessed November 16, 2021]. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Zymner, R.</hi> (2019). Begriffe der Lyrikologie. In: Hildebrandt, Claudia et al. (eds.) Lyrisches Ich, Textsubjekt, Sprecher? (= Grundfragen der Lyrikologie, Bd. 1). Berlin, Germany: De Gruyter 25–50.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,error;literaricity;nlp;poetry,English,18th century;19th century;20th century;english;europe;linguistics;literary studies;natural language processing;text mining and analysis
11747,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Workshop: HathiTrust Research Center’s Extracted Features 2.0 Dataset,,Ryan Dubnicek;Jennifer Christie;Deren Kudeki;Glen Layne-Worthey;John A. Walsh;J. Stephen Downie,workshop / tutorial,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Abstract</head>
                <p style=""text-align: left; "">This workshop will introduce participants to the HathiTrust Research Center’s Extracted Features Dataset, and demo new data fields and functionality introduced in the latest version, 2.0. Generated from the over 17 million volumes (over 60% still in copyright) in the HathiTrust Digital Library, the EF 2.0 Dataset supports text and data mining in this corpus while still being distributed as open, restriction-free data. This tutorial will introduce the EF 2.0 Dataset, the key concepts behind its creation, and hands-on research use cases for the Dataset using IPython notebooks. </p>
                <p style=""text-align: left; "">Index Terms—digital libraries, text and data mining, HathiTrust, HTRC Extracted Features Dataset, collections as data </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p style=""text-align: left; "">Digital libraries are in a state of flux: as institutional collections have grown, their purposes have been transformed from “preservation and access” into “big data” repositories. “The Santa Barbara Statement on Collections as Data” identifies foundational principles for this new focus of digital libraries, encouraging library providers and researchers to view these vast digital collections as sources of data for computational research (Santa Barbara Statement on Collections as Data, 2019). This approach opens new possibilities of inquiry and discovery, but also carries with it the weight of copyright limitations and implications; questions of bias, completeness and representation in data; and additional requirements for new skills, sophisticated infrastructures, and increased funding from stakeholders at all levels.</p>
                <p style=""text-align: left; "">Having foreseen some of these issues, the HathiTrust Research Center (HTRC) developed an approach to “non-consumptive research,” a framework that supports computational research of digital items in the HathiTrust Digital Library (HTDL) while complying with copyright limitations on data access. Similarly, through its Extracted Features (EF) Dataset, HTRC supports an approach to computational research that seeks to minimize skill and infrastructure requirements while also aligning with the broader considerations mentioned above. First released in 2015 with version 0.2, the EF Dataset blends MARC-derived, volume-level metadata with computationally generated, page-level metadata and data (Capitanu et al., 2015). The EF Dataset is open (available under a Creative Commons Attribution 4.0 International License), and includes data for each volume in the HathiTrust Digital Library (HTDL) in a bag-of-words format, supporting a multitude of computational use cases.</p>
                <p style=""text-align: left; "">This workshop will focus on introducing the context and application of the EF Dataset version 2.0, for the first time published in a linked-data-compliant format that includes new and updated data fields, a revised structure, and meaningful uniform resource identifiers (URIs) (Jett, et al., 2020). Attendees will learn about the data from which the EF Dataset is generated, the motivation for the dataset’s creation, its structure and format, and its potential applications and limitations. Additionally, workshop attendees will work hands-on programmatically with EF 2.0 data using IPython notebooks, and will use the HTRC FeatureReader Python library, developed specifically to facilitate use of the EF Dataset (Organisciak and Capitanu, 2016).</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Workshop Description</head>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Overview </head>
                    <p style=""text-align: left; "">Section In this three-hour workshop, attendees will first be introduced to HathiTrust, the data of the HathiTrust Digital Library, and the HathiTrust Research Center, followed by context and motivation of the Extracted Features Dataset, the specifics features (or “fields”) included in the dataset, its format, and a discussion of its potential uses and limitations. Finally, attendees will have a chance to work directly with Python code to analyze HTRC EF data and to use the HTRC FeatureReader Python library. Hands-on work will also present new linked data fields and their potential application for research with the EF Dataset. A more detailed breakdown of the workshops modules follows:</p>
                    <p>Section 1: Intro to HathiTrust Digital Library and HTRC</p>
                    <list rend=""bulleted"">
                        <item>What is HathiTrust?</item>
                        <item>What is/isn’t the HathiTrust Digital Library?</item>
                        <item>What is the HathiTrust Research Center?</item>
                    </list>
                    <p>Section 2: Context and motivation for the HTRC EF Dataset</p>
                    <list rend=""bulleted"">
                        <item>Non-consumptive research</item>
                        <item>What is in the data?</item>
                        <item>Data models and analysis techniques</item>
                    </list>
                    <p>Section 3: Ethical considerations of text datasets</p>
                    <list rend=""bulleted"">
                        <item>Bias in libraries, datasets, data, and algorithms</item>
                    </list>
                    <p>Section 4: Getting and Exploring EF data</p>
                    <list rend=""bulleted"">
                        <item>Hands on with EF data, Python notebooks and the HTRC FeatureReader library</item>
                    </list>
                    <p style=""text-align: left; "">The workshop will be a mix of presentation, discussion, and hands-on activity, with an emphasis on open discussion. Our discussion on the ethics of dataset construction, big data and algorithmic analysis will highlight work from Katherine Bode (2020), Catherine D’Ignazio and Lauren Klein (2020), Mimi Ọnuọha (2021) and Roopika Risam (2019).</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Audience </head>
                    <p style=""text-align: left; "">The workshop is open to all, and is targeted at digital library and digital humanities scholars of all levels, library and information professionals, and anyone interested in computational research using HathiTrust Digital Library data. Attendees will develop an understanding of HathiTrust Digital Library, the HathiTrust Research Center’s services, tools and platforms, selected ethical issues associated with digital libraries, dataset and data analysis, and the Extracted Features model, its suitability for various text and data mining applications, and hands-on familiarity with using the dataset for exploratory data analysis. The workshop can accommodate 10 - 40 attendees.</p>
                    <p style=""text-align: left; "">This workshop builds on years of HTRC workshops ranging from general introductions to text and data mining to more advanced work with HTRC’s tools, services, and data. This workshop will provide an in-depth focus on the Extracted Features Dataset version 2.0, demo new ways for exploring and using the dataset and also engage with the ethics of datasets, data and algorithms.</p>
                    <p style=""text-align: left; "">The general objectives of this workshop are to introduce the HathiTrust context, motivation for, and development and release of the Extracted Features Dataset, and to familiarize participants with the data format, its potential applications, and the latest additions in the 2.0 version. Topics of instruction and potential discussion will include:</p>
                    <p style=""text-align: left; "">• How does the Extracted Features Dataset help make the HTDL more accessible for text and data mining?</p>
                    <p style=""text-align: left; "">• What is the EF Dataset model and the structure of its files?</p>
                    <p style=""text-align: left; "">• What research use cases or exploratory data analysis can be supported using HTRC EF data, especially using the new features of the 2.0 dataset”? </p>
                    <p style=""text-align: left; "">• What tools are available for working with EF data, and hands-on experience using them in Python notebooks? </p>
                    <p style=""text-align: left; "">Our goal is for attendees to leave this workshop with a general understanding of the utility of derived datasets and to be comfortable beginning exploratory data analysis using the EF Dataset. </p>
                    <p style=""text-align: left; "">In addition to more HTRC-centric learning objectives, hands-on activities will have added bonuses of an introduction to common cultural analytics tasks in Python, and the associated software libraries used for such tasks, including Pandas, NLTK and Gensim.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Instructor Biographical Information </head>
                    <p style=""text-align: left; "">Ryan Dubnicek is a Digital Humanities Specialist with HTRC, where he works on external and internal research support and outreach and education. He has a Master of Science in Library and Information Science from the University of Illinois at Urbana-Champaign. </p>
                    <p style=""text-align: left; "">Jennifer Christie is an Associate UX Specialist at the HathiTrust Research Center. She is interested in user-centered interaction design and front-end web development. Her research is grounded in qualitative and quantitative assessments of HTRC’s user base, as well as assisting with outreach and education efforts to engage with HTRC’s growing user community.</p>
                    <p style=""text-align: left; "">The remaining listed authors have contributed to the development of this curriculum and its associated instructional materials and concepts, but will not be part of the instructional team.</p>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Acknowledgements</head>
                <p style=""text-align: left; "">The curriculum presented in this workshop was developed with support from HathiTrust, University of Illinois, Indiana University, and the Institute of Museum and Library Services, award number RE-00-15-0112-15. Additionally, former Associate Director of Outreach and Education with HTRC, Eleanor Koehl, contributed heavily to the development and design of the teaching materials and activities.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">Bode, K. (2020). Why You Can’t Model Away Bias. Modern Language Quarterly, 81(1): 95–124 doi:
                        <ref target=""https://doi.org/10.1215/00267929-7933102"">10.1215/00267929-7933102</ref>.
                    </bibl>
                    <bibl style=""text-align: left; "">D’Ignazio, C. and Klein, L. (2020). ‘What Gets Counted Counts’. Data Feminism 
                        <ref target=""https://data-feminism.mitpress.mit.edu/pub/h1w0nbqp/release/3"">https://data-feminism.mitpress.mit.edu/pub/h1w0nbqp/release/3</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">Jett, J., Capitanu, B., Kudeki, D., Cole, T., Hu, Y., Organisciak, P., Underwood, T., Dickson Koehl, E., Dubnicek, R. and Downie, J. S. (2020). The HathiTrust Research Center Extracted Features Dataset (2.0) HathiTrust Research Center doi:
                        <ref target=""https://doi.org/10.13012/R2TE-C227"">10.13012/R2TE-C227</ref>. 
                        <ref target=""https://wiki.htrc.illinois.edu/pages/viewpage.action?pageId=79069329"">https://wiki.htrc.illinois.edu/pages/viewpage.action?pageId=79069329</ref> (accessed 2 June 2022).
                    </bibl>
                    <bibl style=""text-align: left; "">Organisciak, P. and Capitanu, B. (2016). Text Mining in Python through the HTRC Feature Reader. Programming Historian 
                        <ref target=""https://programminghistorian.org/en/lessons/text-mining-with-extracted-features"">https://programminghistorian.org/en/lessons/text-mining-with-extracted-features</ref> (accessed 2 June 2022).
                    </bibl>
                    <bibl style=""text-align: left; "">Risam, R. (2019). The Stakes of Postcolonial Digital Humanities. New Digital Worlds. (Postcolonial Digital Humanities in Theory, Praxis, and Pedagogy). Northwestern University Press, pp. 23–46 doi:
                        <ref target=""https://doi.org/10.2307/j.ctv7tq4hg.5"">10.2307/j.ctv7tq4hg.5</ref>. 
                        <ref target=""http://www.jstor.org/stable/j.ctv7tq4hg.5"">http://www.jstor.org/stable/j.ctv7tq4hg.5</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">Partners Always Already Computational - Collections as Data 
                        <ref target=""https://collectionsasdata.github.io/partners/"">https://collectionsasdata.github.io/partners/</ref> (accessed 30 November 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">The Library of Missing Datasets — MIMI ONUOHA MIMI  ONUOHA 
                        <ref target=""https://mimionuoha.com/the-library-of-missing-datasets"">https://mimionuoha.com/the-library-of-missing-datasets</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">The Santa Barbara Statement on Collections as Data Always Already Computational - Collections as Data 
                        <ref target=""https://collectionsasdata.github.io/statement/"">https://collectionsasdata.github.io/statement/</ref> (accessed 30 November 2021).
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,collections as data;digital libraries;hathitrust;htrc extracted features dataset;text and data mining,English,18th century;19th century;20th century;cultural studies;english;global;linguistics;linked (open) data;north america;text mining and analysis
11762,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Archive of the Digital Present (ADP), COVID-19 Period: Collecting and Visualizing Metadata of Online Literary Events Hosted in Canada, March 2020 - September 2021",,Jason Camlot;Tomasz Neugebauer;Francisco Berrizbeitia;Ben Joseph;Alexandre Bustamante;Sukesh Gandham,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>
                <hi rend=""bold"">Archive of the Digital Present for Online Literary Performance in Canada (COVID-19 Pandemic Period)</hi> is a research and development project that arises out of the need to address foundational, practical and theoretical research questions about the impact of the recent (and ongoing) COVID-19 pandemic, and attendant social disruptions and restrictions, upon literary communities in Canada through the study of organised literary events as they have occurred online since March 2020.
            </p>
            <p>The papers that constitute this panel focus on the design and development work pursued in building a searchable, open access database and directory – The Archive of the Digital Present (ADP) – to allow scholars, literary practitioners, and the public to gain knowledge about the nature and significance of literary events (online, hybrid, and in-person) that have occurred during the pandemic period, through the collection and structuring of metadata, and, in some cases, with direction to audiovisual (AV) documentation of the events themselves as they were held using platforms such as Zoom and YouTube.</p>
            <p>Our papers explain key facets of development by presenting approaches to (1) data collection and structuring, (2) stack development, (3) data visualisation, and (4) front end design, that have emerged through the process of community and user-oriented design research and development used to create the ADP.</p>
            <p>
                <hi rend=""bold"" style=""font-size:16pt"" xml:space=""preserve"">Finding and Structuring Metadata about Pandemic Literary Events </hi>
                (Jason Camlot)
            </p>
            <p>Public readings represent a significant form of literary communication, dissemination, circulation and community-building. The study of literary performances, events and activities through audiovisual media documentation, digital images (posters) and textual records, raises important new questions about literary work as it acts 
                <hi rend=""italic"">in situ</hi> among artists and audiences (Camlot, Fong and Shearer).  Such materials and the events they document reveal unique traces of sociality and affective response in literary exchange, foreground tonal and performative aspects of cultural transmission, document formations of literary community in action, and highlight the mediated nature of such events as they first occurred and as we subsequently access them through archived recordings. Focusing on the presentation of digital documentation and records of online events of the COVID-19 pandemic period, the ADP is designed to help us understand the impact of pandemic disruptions on literary communities in Canada. 
            </p>
            <p>The ADP project necessarily began with questions about the data we were seeking to collect.  In February 2021 we performed a preliminary analysis of online and social media postings for listings of literary events hosted in Canada.  This revealed 77 discrete organisers of over one thousand (1,011, to be exact) literary events between 20 March 2020 - 31 December 2020.  This list served as the starting point for an expanded catalogue of events, and for team discussions about the nature and number of metadata fields we would use. We proceeded by adapting extant categories of the SpokenWeb metadata schema that has been designed for the description of historical literary audio recordings. This allowed us to repurpose the backend of the Swallow Metadata Ingest System (
                <hi rend=""italic"">Swallow</hi>), built for metadata management of historical research collections, through the development of a crosswalk that best serves the goals of data collection for ADP. Storing the metadata as unstructured JSON, 
                <hi rend=""italic"">Swallow</hi> makes it possible to quickly generate and modify a cataloguing interface, and changes in metadata schemas, and this flexibility has proven useful for the iterative design and feedback process we have pursued in ADP UX development. Data fields we have shaped for this project include categories related to Title, Creator/Contributor, Language, Production Context, Genre, Duration, Date, Location, Online Platform, and Contents, among others.
            </p>
            <p>This section of our presentation presents our ongoing methods of discovering events to be included in the ADP database, explains the rationale of our selection of metadata categories and our approach to structuring those fields, and raises some of the philosophical and ontological questions that have arisen in the process of abstracting the complex and mediated literary activities of the pandemic period into categories of searchable data. Our methods of data collection extended beyond the analysis of social media notices of events to the identification and research of key organisations involved in hosting events, and to crowdsourcing calls within diverse literary communities.  Our selection of the specific fields identified were based on feedback from researchers and practitioners about the kinds of information they would seek from a database such as this, and on our goals in data visualisation, discussed below. Philosophical and ontological questions raised by our data determination and collection process included questions about the nature of an event, the roles of participants in relation to categories such as creator and contributor, and generic categories that include or preclude the overarching category of the “literary” event, and the status of such events as entities within a data structure.</p>
            <p>
                <hi rend=""bold"" style=""font-size:16pt"" xml:space=""preserve"">Stack Development and the Rationale of a Headless CMS </hi>
                (Ben Joseph, Francisco Berrizbeitia)
            </p>
            <p>In this section we present the software stack chosen to develop the solution and the rationale behind it. The right technical stack is, to a great extent, the key to a project’s success, while the wrong choice of web application development technologies may be a reason for failure. Our stack had to manage the trade-offs for processing heavy loads and maintaining a low latency with high responsiveness. </p>
            <p>The data was collected using 
                <hi rend=""italic"">Swallow</hi> (Camlot et al. 2020), an open-source metadata management system developed by the SpokenWeb partnership. Interacting with this backend system, cataloguers collected and compiled the information of the different events. This corpus of data is then exported as whole and ingested by the Strapi headless content management system (
                <ref target=""https://strapi.io/"">https://strapi.io/</ref>) as shown in 
                <hi rend=""bold"">Figure 1</hi>. MeiliSearch (https://www.meilisearch.com) provides advanced search functionalities and Strapi allows for digital asset management while providing a backend to the presentation layer. The presentation layer was developed using AngularJS (
                <ref target=""https://angularjs.org/"">https://angularjs.org/</ref>).  The component-based structure of Angular makes specific sections of code highly reusable across our application and for future frontend developments. The AngularJS layer interacts with the data sources via a GraphQL (https://graphql.org/) thus ensuring data consistency.
            </p>
            <figure>
                <graphic n=""1001"" width=""14.605cm"" height=""19.473333333333333cm"" url=""Pictures/35e09f1d8366fe95a9561250f46e50a9.png"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">
                <hi rend=""bold"" style=""font-size:9pt"">Figure 1</hi>
                . Software stack schema and information flow. 
            </p>
            <p>
                <hi rend=""bold"" style=""font-size:16pt"" xml:space=""preserve"">Visualizing Time, Place and Relations of Literary Activity in a Pandemic </hi>
                (Tomasz Neugebauer, Sukesh Gandham)
            </p>
            <p>A user survey identified the host location of the event as one of the more important elements of event description, along with event type, contributors, links to recordings, and the titles of texts read.  The most important metadata elements for navigation of content were identified as: names of participants, names of organizers and event, titles of texts read/performed/discussed, and date/time of event. This lead to an initial front page design for the ADP site that included three visualizations of the data: A) Timeline: a spiral histogram (Condegram) showing the number of events that took place on specific dates during the pandemic period B) Connections: a network graph showing adjacency relations between contributors and events, using hierarchical edge bundling based on the events’ organizations, and C) Places: geographical map showing number of events that took place in each of the events’ host cities.  These visualizations touched on all the important metadata elements identified in the user surveys, except for the titles of texts read/performed.  </p>
            <p>During the user-centered design process, a usability session evaluating some proposed wireframes for the site with scholars from the Spokenweb network, event organizers, practitioners and students confirmed that there is interest and enthusiasm for the data visualizations on the interface, especially for any interactive functionalities of these.  To keep the visualizations interactive, we decided to treat them as tools that navigate into the data.  For example, clicking on a name of a contributor or event in the edge bundling visualization leads the user to the browse view of the search results in the dataset for that name.  Similarly, clicking on a bar for a specific date on the condegram, or the city name on the map visualization, leads the user to the browse view of events that took place on that date or that were hosted in that city.  </p>
            <p>For the implementation of these visualizations, keeping complexity in check, we wanted the same code base for all three of them.  We also wanted a solution that is based on open-source code that is free from license restrictions on usage and sharing, which eliminated solutions such as amCharts (
                <ref target=""https://www.amcharts.com/"">https://www.amcharts.com/</ref>). We chose the D3.js (
                <ref target=""https://d3js.org/"">https://d3js.org/</ref>) JavaScript library as our code base to generate Scalable Vector Graphics (SVG) that we present with custom HTML5 and Cascading Style Sheets (CSS). We added the Bootstrap library (
                <ref target=""https://getbootstrap.com/docs/3.4/"">https://getbootstrap.com/docs/3.4/</ref>) for responsive functionality. The D3 Gallery (
                <ref target=""https://observablehq.com/@d3/gallery"">https://observablehq.com/@d3/gallery</ref>) served as an excellent starting place for choosing the closest existing examples to build on.  We used Python to transform the ADP JSON data from our Swallow Metadata Management System into data shapes that are required for the three visualizations using D3.   
            </p>
            <p>
                <hi rend=""bold"" style=""font-size:16pt"" xml:space=""preserve"">User-Oriented Design and Aesthetics for a Pandemic-Period Website </hi>
                (Alexandre Bustamante)
            </p>
            <p>The avenue for building the front-end of ADP was, from an early phase, directed as a user-centred project. After the design was initiated, discussions evolved for experimenting with the lines of a Participatory Design (PD) approach. A user-centred methodology is considered executed ""on behalf of users"" while PD approaches design ""with the users"" (Spinuzzi 2005, 165), We chose this option to have ensure greater involvement of the stakeholders of the ADP in all development phases of the front-end design. We organized a series of workshops, PD activities and user-experience research surveys distributed to invited participants and the direct team of the front-end development, with the project designer playing a facilitating rather than individual authorial role. The workshops adopted established design methods (Martin 2012) such as personas and user journeys for delineating stakeholder needs. Card sorting, tree-testing and first-click tests were used to create and confirm an informational architecture (figure 2). We adapted to the added challenge of conducting workshops remotely due to the pandemic. This led to the exploration of available tools, such as 
                <hi rend=""italic"">Miro Boards</hi> (
                <ref target=""https://miro.com"">https://miro.com</ref>), 
                <hi rend=""italic"">Google Jamboards</hi> (
                <ref target=""https://jamboard.google.com/"">https://jamboard.google.com/</ref>) and 
                <hi rend=""italic"">Optimal Workshop</hi> (
                <ref target=""https://www.optimalworkshop.com"">https://www.optimalworkshop.com</ref>). 
            </p>
            <figure>
                <graphic n=""1002"" width=""16.002cm"" height=""9.001125cm"" url=""Pictures/8ad2d6f36f0e01ec14a176d44205b861.png"" rend=""inline""/>
            </figure>
            <p>
                <hi style=""font-size:9pt"" xml:space=""preserve"">Figure 2 - Results from an online workshop, with automated interpretation of a card sorting exercise compiled by the user-experience tool </hi>
                <hi rend=""italic"" style=""font-size:9pt"">Optimal Workshop</hi>
                . Screenshot by the authors.
            </p>
            <p>The initial outcome of the PD process was the creation of a three-level information architecture for the prototype of the front-end design: starting at the first level with an overall glimpse at the directory of events on the home page which presents content through visualizations and browsing functions. From the homepage, the user moves to a second level where content is presented on either a dashboard or in the form of lists in pre-established categories, displaying more information and details and introducing different filters for the content. Finally, the third and final level of the information architecture is detailed access to the metadata, which can be visualized, exported or shared. The front-end design allows a search function to be performed at all three levels, for direct access to the directory of events.</p>
            <figure>
                <graphic n=""1003"" width=""16.002cm"" height=""11.156597222222222cm"" url=""Pictures/e13090eba5103f12ab4df65182ee8488.png"" rend=""inline""/>
            </figure>
            <p>Figure 3 - Latest front-end design for the ADP website. A glimpse of the landing page of the Archive. Screenshot by the authors.</p>
            <p>Once the information architecture was established, the participatory approach to design was expanded to inform the final look of the prototype (figure 3). Team members and stakeholders were invited to guide the visual design by reflecting on their perception of the pandemic and providing keywords that capture the experience of living through this period. The final prototype was then designed to reflect on these shared perceptions, drawing from participant’s contributions to inspire a mood board for the design work, which directed the design decisions to achieve a final result that aims to be characteristic of its particular time.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">AngularJS - HTML enhanced for web apps!</hi> (n.d.). AngularJS. 
                        <ref target=""https://github.com/angular/angular.js"">
                            <hi rend=""color(1155CC)"">https://github.com/angular/angular.js</hi>
                        </ref> (accessed 12 September 2021).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Camlot, Jason.</hi> (2013). The Sound of Canadian Modernisms: The Sir George Williams University Poetry Series, 1966-1974.  
                        <hi rend=""italic"">Journal of Canadian Studies / Revue d’études canadiennes,</hi> 46(3): 28-59.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Camlot, Jason , Neugebauer, Tomasz and Berrizbeitia, Francisco.</hi> (2020). Dynamic Systems for Humanities Audio Collections : The Theory and Rationale of Swallow.
                        <hi rend=""italic"" xml:space=""preserve""> DH2020 (Digital Humanities 2020 Virtual Conference), 23 July 2020, Ottawa, Canada.</hi>
                        <ref target=""https://spectrum.library.concordia.ca/id/eprint/987014/"" xml:space=""preserve""> https://spectrum.library.concordia.ca/id/eprint/987014/</ref> (accessed 10 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fong, Deanna, and Karis Shearer.</hi> (2018). Gender, Affective Labour, and Community Building Through Literary Audio Artifacts. 
                        <hi rend=""italic"">SpokenWebBlog</hi>. 
                        <ref target=""https://spokenweb.ca/spokenweblog/"">https://spokenweb.ca/spokenweblog/</ref> (accessed 20 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">GraphQL: A query language for your API.</hi> (n.d.). GraphQL. 
                        <ref target=""https://graphql.org/"">
                            <hi rend=""color(1155CC)"">https://graphql.org/</hi>
                        </ref> (accessed 9 December 2021).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Martin, Bella, and Bruce M Hanington.</hi> (2012). 
                        <hi rend=""italic"">Universal Methods of Design: 100 Ways to Research Complex Problems, Develop Innovative Ideas, and Design Effective Solutions.</hi> Beverly, MA: Rockport.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">MongoDB database. </hi>(n.d.). MondoDB Github Repository. 
                        <ref target=""https://github.com/mongodb/mongo"">
                            <hi rend=""color(1155CC)"">https://github.com/mongodb/mongo</hi>
                        </ref> (accessed 12 September 2021).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Spinuzzi, Clay.</hi> (2005). The Methodology of Participatory Design. 
                        <hi rend=""italic"">Technical Communication</hi>, 52(2): 163–74.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Strapi: Open source Node.js headless CMS to easily build customisable APIs.</hi> (n.d.). Strapi Github Repository. 
                        <ref target=""https://github.com/strapi/strapi"">
                            <hi rend=""color(1155CC)"">https://github.com/strapi/strapi</hi>
                        </ref> (accessed 9 December 2021).
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,covid-19 pandemic;literary events;metadata;ux design;web development,English,"contemporary;design studies;english;global;interface design, development, and analysis;literary studies;north america;user experience design and analysis"
11769,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Knowledge organization of the Hong Kong Martial Arts Living Archive to capture and preserve intangible cultural heritage,,Davide Picca;Alessandro Adamou;Yumeng Hou;Mattia Egloff;Sarah Kenderdine,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p style=""text-align: left; "">Since the 2003 UNESCO convention stated the importance of preserving intangible cultural heritage (ICH), numerous efforts were undertaken to expand traditional cultural heritage to encompass immaterial aspects. However, the boundaries of what should be intended as ICH are not set: the intangible element can be found in such areas as the aesthetics (e.g. performing arts), epistemology (style, semiotics) and transmission (oral history) of culture.</p>
                <p style=""text-align: left; "">Treating martial arts as cultural heritage potentially incorporates all these categories of immateriality 
                    <ref target=""#bookmark10"">(Hou, Picca, Egloff, & Adamou,</ref>
                    <ref target=""#bookmark10"">2021).</ref> The Hong Kong Martial Arts Living Archive (HKMALA) 
                    <ref target=""#bookmark8"">(Chao, Delbridge, Kenderdine,</ref>
                    <ref target=""#bookmark8"" xml:space=""preserve"">Nicholson, & Shaw, </ref>
                    <ref target=""#bookmark8"" xml:space=""preserve"">2018), </ref>as a testimony of arts, styles and methods that are passed down onto small communities, is a prominent example of multiple degrees of ICH occurring together. Whilst gathering a mass of audio-visual and motion capture content to visually preserve endangered Southern Chinese cultures (see Figure 
                    <ref target=""#bookmark0"">1),</ref> it offers an opportunity to turn it into structured knowledge, being originally organized around its past run of exhibitions.
                </p>
                <p style=""text-align: left; "">We present an ongoing endeavor to extract and formalize Hakka martial arts knowledge out of HKMALA content into a knowledge graph of linked datasets, thus offering a ground truth for future research questions on the understanding of cultural contact across martial arts communities. </p>
                <figure>
                    <graphic n=""1001"" width=""15.195291666666666cm"" height=""5.102930555555556cm"" url=""Pictures/84b15235e21bbd7201ca783660f529c2.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 1: 
                    <anchor xml:id=""bookmark0""/>Overview of HKMALA content types.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>A basic ontological framework for martial arts</head>
                <p style=""text-align: left; "">Barring sports or military contexts, no known ontology presents a unified theory of the martial discipline, to form the basis of such a knowledge organization of archival content. As an initial task, this project built one such framework. This is modelled as an ontology network grounded on foundational ontologies, rather than cultural heritage models, but whose modularity reflects the intent to highlight the aesthetic, epistemic and social traits of martial arts (Figure 
                    <ref target=""#bookmark1"">2).</ref> The identification of which traits to be considered culturally relevant will subsequently be delegated to inference models (rule systems, reasoners) combining domain ontologies with cultural ones like CIDOC-CRM and ArCo 
                    <ref target=""#bookmark6"">(Carriero et</ref>
                    <ref target=""#bookmark6"">al.,</ref>
                    <ref target=""#bookmark6"">2019).</ref> See 
                    <ref target=""#bookmark7"">(Adamou, Hou, Picca, Egloff, Kenderdine</ref>, 
                    <ref target=""#bookmark7"">2021)</ref> for details on our ontology engineering work.
                </p>
                <figure>
                    <graphic n=""1002"" width=""15.522222222222222cm"" height=""6.766277777777778cm"" url=""Pictures/b7b7c777c5954034dc9f23490a447ff3.jpg"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 2: 
                    <anchor xml:id=""bookmark1""/>Documented ontology at 
                    <ref target=""https://crossings.github.io/ont/"">https://crossings.github.io/ont/</ref>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Instantiation on the HKMALA content</head>
                <p style=""text-align: left; "">A knowledge organization of HKMALA involves (1) annotating media content of technique demonstrations, MoCap segments and interviews to masters, and (2) indexing these media so that they can be consumed using computational methods like ontology-based data access and semantic query languages like SPARQL. The above ontologies offer a basic framework for a martial arts data domain, yet do not specifically model HKMALA’s Hakka Kung Fu domain: therefore, an instantiation effort is required. This is accomplished, as per Figure 
                    <ref target=""#bookmark2"" xml:space=""preserve"">3, </ref>by:
                </p>
                <figure>
                    <graphic n=""1003"" width=""15.522222222222222cm"" height=""7.563555555555555cm"" url=""Pictures/7cf76b5bd5ae0cdfc121e72e0288fb70.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 3: 
                    <anchor xml:id=""bookmark2""/>Pipeline of HKMALA knowledge organization.
                </p>
                <list type=""ordered"">
                    <item>Constructing the Hakka martial arts dataset from selected sources.</item>
                    <item>Semantically annotating HKMALA media content using terminology lifted from the dataset in question.</item>
                    <item>Iteratively refining our martial arts ontologies to satisfy the versatility required by the media annotation schema.</item>
                    <item>Continuously publishing the knowledge graph resulting from datasets (1,2) as FAIR data 
                        <ref target=""#bookmark9"" xml:space=""preserve"">(Groth & Dumontier, </ref>
                        <ref target=""#bookmark9"">2020).</ref>
                    </item>
                </list>
                <p style=""text-align: left; "">To generate the dataset that instantiates the Martial Arts ontology (1), we performed data extraction and reengineering from the following sources:</p>
                <p style=""text-align: left; "">a) texts of past HKMALA exhibition panels and captions; b) glossaries in the literature on Southern Chinese martial arts referenced by said texts; c) manifest files containing tabular data to assemble exhibitions out of the archive content; d) transcripts of interviews to masters. </p>
                <p style=""text-align: left; "">Entity extraction from the texts was performed using the Stanford named entity tagger. Part of these sources had previously been used to bootstrap the ontology itself, therefore the terms not used then that denoted instances were included in the dataset. </p>
                <p style=""text-align: left; "">Semantic media annotation (2) is performed using the ELAN toolkit, a multi-tiered video annotation software that allows custom terminology and stores annotation in the open format EAF (
                    <ref target=""#bookmark12"">Sloetjes & Seibert,</ref>
                    <ref target=""#bookmark12"">2016),</ref> which can be exported to JSON-LD and is therefore interoperable with the standards underneath knowledge graphs. Our tiered organization of EAF reflects the three dimensions of cultural heritage that constitute the ontology modules: for example, a video of a Southern Praying Mantis master demonstrating a technique will be annotated along a layer for the aesthetic dimension (e.g. movement, stance and body parts involved), one for the epistemic dimension (technique, style and symbolic reference such as the mantis itself), and one for the social/transmission dimension (the master’s identity).
                </p>
                <p style=""text-align: left; "">The scrutiny and annotation of HKMALA media files brought to light a need to refine the original ontological framework (3) to accommodate the expressivity of the knowledge encoded in the medium. For example, a master explaining what qualities are developed by a training exercise on what parts of the body required that an n-ary relation should be materialized as a 
                    Development class. Similarly, distinguishing techniques where the energy flow (
                    <hi rend=""italic"">qi</hi> ) comes from the point of contact (external) or from the attacker’s body (internal) hinted that a class 
                    FlowTransmissionType should be formalized.
                </p>
                <p style=""text-align: left; "">The dataset and annotations (4) are published in formats compliant with the Linked Data standards (i.e. Turtle, N-Triples and JSON-LD), both on GitHub
                    <note place=""foot"" xml:id=""ftn1"" n=""1"">
                        <p rend=""footnote text""> CROSSINGS knowledge graph sources, 
                            <ref target=""https://github.com/CROSSINGS/kg"">https://github.com/CROSSINGS/kg</ref>
                        </p>
                    </note> and on Zenodo
                    <note place=""foot"" xml:id=""ftn2"" n=""2"">
                        <p rend=""footnote text""> DOI for data citation: 
                            <ref target=""https://doi.org/10.5281/zenodo.5886867"">https://doi.org/10.5281/zenodo.5886867</ref>
                        </p>
                    </note>
                    <ref target=""#bookmark4"" xml:space=""preserve""> </ref>and following a rolling release / continuous update model. The choice of representation formats and publishing channels was driven by the need to a) ensure data FAIRness and the ability to load them onto any triple store for querying; b) ease of availability for programming libraries to download and use the data in client code, as exemplified in the concluding section.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Conclusions</head>
                <p style=""text-align: left; "">Aiming at creating a gold standard for building knowledge graphs on martial arts, we offer data and annotations for a subset of the HKMALA content that was originally made publicly available
                    <note place=""foot"" xml:id=""ftn3"" n=""3"">
                        <p rend=""footnote text""> Hakka Kung Fu portal, 
                            <ref target=""http://www.hakkakungfu.com/"">http://www.hakkakungfu.com/</ref>
                        </p>
                    </note>,
                    <ref target=""#bookmark5"" xml:space=""preserve""> </ref>with a view on extending it to the entire archive in the future.
                </p>
                <p style=""text-align: left; "">The next step is to align our datasets with the open data cloud: although full third-party coverage is not expected for our domain, Wikidata offers limited authority coverage for some masters, techniques and most importantly geographical and ethnological coordinates.</p>
                <p style=""text-align: left; "">The project will provide a way to programmatically consume public HKMALA media through an extension of the DHTK Python library, an ontology- based computational model for Humanities data access 
                    <ref target=""#bookmark11"" xml:space=""preserve"">(Picca & Egloff, </ref>
                    <ref target=""#bookmark11"">2017).</ref>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Acknowledgement </head>
                <p style=""text-align: left; "">This work was supported by CROSSINGS - Computational Interoperability for Intangible and Tangible Cultural Heritage, a project in Collaborative Research on Science and Society (CROSS 2021). The authors also acknowledge the 
                    <hi rend=""italic"">Hong Kong Martial Arts Living Archive</hi>, a research collaboration between the International Guoshu Association, City University of Hong Kong, and the Laboratory of Experimental Museology at EPFL.
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">Adamou, A., Hou, Y., Picca, D., Egloff, M., Kenderdine, S. (2021). 
                        <hi rend=""italic"">Ontology- mediated cultural contact detection through motion and style in Southern Chinese martial arts.</hi> In Semantic web and ontology design for cultural heritage (swodch 2021) (Vol. 2949). CEUR-WS.org. Retrieved from 
                        <anchor xml:id=""bookmark6""/>
                        <ref target=""HYPERLINK"">
                            http://ceur-ws.org/Vol-2949#short2
                        </ref>
                    </bibl>
                    <bibl style=""text-align: left; "">Carriero, V. A., Gangemi, A., Mancinelli, M. L., Marinucci, L., Nuzzolese, A. G.,Presutti, V., & Veninata, C. (2019). 
                        <hi rend=""italic"">ArCo ontology network and LOD on italian cultural heritage.</hi> In A. Poggi (Ed.), Proceedings of the first international workshop on open data and ontologies for cultural heritage, odoch@caise 2019 (Vol. 2375, pp. 97–102). CEUR-WS.org. Retrieved from 
                        <anchor xml:id=""bookmark8""/>
                        <ref target=""HYPERLINK"">
                            http://ceur-ws.org/Vol-2375/short3.pdf
                        </ref>
                    </bibl>
                    <bibl style=""text-align: left; "">Chao, H., Delbridge, M., Kenderdine, S., Nicholson, L., & Shaw, J. (2018). Kapturing 
                        <hi rend=""italic"" xml:space=""preserve"">Kung Fu: Future proofing the Hong Kong martial arts living </hi>
                        <anchor xml:id=""bookmark9""/>
                        <hi rend=""italic"">archive</hi>. In Digital echoes (pp. 249–264). Springer.
                    </bibl>
                    <bibl style=""text-align: left; "">Groth, P., & Dumontier, M. (2020). 
                        <hi rend=""italic"">Introduction - FAIR data, systems and analysis</hi>. Data Sci., 3 (1), 1–2. Retrieved from 
                        <ref target=""https://doi.org/10.3233/ds-200029"">
                            https://doi.org/10.3233/
                        </ref>
                        <anchor xml:id=""bookmark10""/>
                        <ref target=""HYPERLINK"">
                            ds-200029
                        </ref>doi: 10.3233/ds-200029
                    </bibl>
                    <bibl style=""text-align: left; "">Hou, Y., Picca, D., Egloff, M., & Adamou, A. (2021). 
                        <hi rend=""italic"">Digitizing intangible cultural heritage embodied: state of the art.</hi> Journal on Computing and 
                        <anchor xml:id=""bookmark11""/>Cultural Heritage. (To appear)
                    </bibl>
                    <bibl style=""text-align: left; "">Picca, D., & Egloff, M. (2017). 
                        <hi rend=""italic"">DHTK: the digital humanities toolkit.</hi> In A. Adamou, E. Daga, & L. Isaksen (Eds.), Proceedings of the second workshop on humanities in the semantic web (whise II
                        <hi rend=""italic"" xml:space=""preserve"">) </hi>(Vol. 2014, pp. 81–86). CEUR-WS.org. Retrieved from 
                        <ref target=""http://ceur-ws.org/Vol-2014/paper-09.pdf"">
                            http://ceur-ws.org/Vol-2014/
                        </ref>
                        <anchor xml:id=""bookmark12""/>
                        <ref target=""HYPERLINK"">
                            paper-09.pdf
                        </ref>
                    </bibl>
                    <bibl style=""text-align: left; "">Sloetjes, H., & Seibert, O. (2016). 
                        <hi rend=""italic"">New facets of the multimedia annotation tool ELAN.</hi> In M. Eder & J. Rybicki (Eds.), 11th annual international conference of the alliance of digital humanities organizations, DH 2016 (pp. 888–889). ADHO. Retrieved from 
                        <ref target=""http://dh2016.adho.org/abstracts/161"">
                            http://dh2016.adho.org/abstracts/
                        </ref>
                        <ref target=""http://dh2016.adho.org/abstracts/161"">
                            161
                        </ref>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,asian studies;intangible cultural heritage;knowledge organization,English,20th century;asia;asian studies;contemporary;data modeling;digital archiving;english;ethnography and folklore
11824,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Digital debating cultures: Communicative practices on Reddit,,Thomas C. Messerli;Daria Dayter;Axel Bohmann;Lisa Donlan;Gustavo Maccori Kozma;Sven Leuckert;Aatu Liimatta;Hanna Mahler;Adrienne Massanari;Kyla McConnell;Rafaela Tosin,panel / roundtable,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p rend=""DH-Heading1"">
                Panel abstract
            </p>
            <p style=""text-align: left; "">The social media platform Reddit understands itself as a “home to thousands of communities”, where every used can find their community (
                <ref target=""https://www.redditinc.com/"">https://www.redditinc.com</ref>). As researchers in humanities, we find that the submissions and comments posted to Reddit’s subreddits do indeed comprise authentic digital human interaction by groups of people that are in some cases prototypical communities and in other cases merely chance encounters of users who find themselves oriented towards the same virtual space. The collective communicative acts of Reddit users can be positioned in the tradition of computer-mediated communication (CMC) – as one key site of digitalised communication, shaped partially by the affordances provided by the platform, and uniquely available to researchers not just in terms of their linguistic content, but also their multimodal context and discursive structure. Importantly, however, Reddit (sub-)communities are not necessarily subject to identical communicative patterns – within each community, user types and even individual users communicate following particular patterns or even idiosyncratically. 
            </p>
            <p style=""text-align: left; "">Our recently formed interdisciplinary network, copRe (
                <hi rend=""bold"">co</hi>mmunicative 
                <hi rend=""bold"">p</hi>ractices on 
                <hi rend=""bold"">Re</hi>ddit – copre.org), is dedicated to exploring Reddit discourse(s) from different theoretical perspectives, but all with the aim to contribute to the understanding of Reddit’s own communicative culture as well as the exploration of digital practices more generally. 
            </p>
            <p style=""text-align: left; "">Specifically, our panel at the DH2022 conference explores aspects of digital culture and participatory culture, manifest in the communicative acts of different (sub-)communities on the online social platform Reddit. These subreddit-communities and the digital genres they give rise to are sites of linguistic innovation as well as of new debating practices – from the combative far-right subreddit r/The_Donald to the more harmonious r/changemyview. They let us gain insights into individual and group identities, as on r/Mountaineering, and they raise question of methodology, such as the understanding of text length as both a challenge for research and a motivated choice of text authors and the employment of mixed-methods to gain insights that are both driven by big data as well as by in-depth understanding of individual and collective communicative acts.</p>
            <div type=""div1"" rend=""DH-Heading1"">
                <head type=""main"">Language innovation and diffusion online.</head>
                <p style=""text-align: left; "">Lisa Donlan (University of Manchester)</p>
                <p style=""text-align: left; "">Who are the innovators of lexical terms online? What are the community roles of the early adopters who successfully diffuse linguistic innovations?</p>
                <p style=""text-align: left; "">In offline communities, the weak-tie theory of language change envisions the innovators of linguistic forms as peripheral to a community while early adopters are the community's central members. However, the only study to explore the applicability of the theory in an online Community of Practice (CoFP) was grounded in an unusual linguistic context. My research addresses this gap in the literature by using a mixed-methods approach to analyse the status of the innovators and early adopters of four community-salient innovative linguistic forms which diffused through an online music-orientated CofP, Popheads.</p>
                <p style=""text-align: left; "">Contrary to expectations, three of the four forms studied were innovated by non-peripheral members who scored highly across multiple markers of status. This departure from previous findings may be related to the fact that linguistic creativity is highly valued in many virtual contexts. Consequently, high-status members may perceive linguistic innovation as desirable behaviour online. </p>
                <p style=""text-align: left; "">This research also found that identifying the hierarchical structures that underpin a community leads to more precise descriptions of the characteristics of early adopters. Specifically, it has been possible to conclude that early adopters are prolific contributors, whose posts are successful at generating discussion, and who are on inbound trajectories in the community. Therefore, to speak of an early-adopter as being 'central' or 'high-status' is, I argue, ultimately too vague and fails to acknowledge the multidimensional nature of status. </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head type=""main"">Functions of text length on Reddit</head>
                <p style=""text-align: left; "">Aatu Liimatta (University of Helsinki)</p>
                <p style=""text-align: left; "">In corpus-linguistic studies, text length is typically seen as a potential confounding factor (see e.g. Liimatta, 2020), largely because its effects have been difficult to study using even the largest traditional corpora. However, like any other linguistic choice, the length of a text is also a choice made by the writer or speaker: it is also affected by the communicative purpose of the text and the limitations and affordances of the communicative situation.</p>
                <p style=""text-align: left; "">Fortunately, large social media datasets with a range of text lengths have allowed us to approach this previously unassailable topic. Reddit is particularly interesting in terms of text length, since the length of a Reddit comment is free to vary according to the commenter’s needs. Recent studies have shown that Reddit comment length is linked to the distribution of functional linguistic features: for instance, simple information-seeking comments tend to be very short, whereas narrative registers appear to favor longer comments on average (Liimatta, forthc.).</p>
                <p style=""text-align: left; "">In order to further explore the role and functions of comment length on Reddit, I analyze a number of subreddits in terms of both the distribution of comment lengths and the distribution of functional linguistic features across comment lengths. To do this, I make use of a large-scale dataset of Reddit comments and a simple but powerful pooling-based computational methodology.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head type=""main"">Register variation in Reddit comments - A multidimensional analysis</head>
                <p style=""text-align: left; "">Hanna Mahler, Kyla McConnell, Axel Bohmann, Gustavo Maccori Kozma, Rafaela Tosin (University of Freiburg)</p>
                <p style=""text-align: left; "">Researchers are increasingly becoming interested in the many opportunities that Reddit provides for linguistic analysis. In this large-scale natural language processing project, we focus on register variation within Reddit comments (inspired by Liimatta 2016, 2020).</p>
                <p style=""text-align: left; "">We analyze Biber’s (1998) linguistic features for register analysis, as well as platform-specific features, on all Reddit comments since 2005, using the Pushshift Reddit Corpus (Baumgartner et al. 2020). We are using this feature annotation to implement a short-text MDA (Clarke & Grieve 2019), a version of Biber’s (1988) multi-dimensional analysis, to find out which dimensions describe the linguistic variation found on the platform and whether the topical ""subreddits"" can be described as different registers. Our method also promises to serve as a useful tool for analysing other topics such as adaptation of linguistic norms or register diversification over time.</p>
                <p style=""text-align: left; "">Our study therefore adds to the state of knowledge in several ways:</p>
                <p style=""text-align: left; "">1. We regard a single comment as one text (with features extracted on the sentence level), which allows us to accurately locate linguistic variation within individual users.</p>
                <p style=""text-align: left; "">2. We train a tagger specifically to overcome previous difficulties of tagging social media data (e.g. Banga & Mehndiratta 2017), based on data from Behzad & Zeldes (2020) and Gessler et al. (2020).</p>
                <p style=""text-align: left; "">3. The feature extraction script, a refined and elaborated version of Biber's (1988) initial features, is written in Python and will be made openly available.</p>
                <p style=""text-align: left; "">4. Our long-term goal is to develop an MDA solution that captures variation within and among all (English) subreddits.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head type=""main"">Combating the Far-/Alt-Right on Reddit: Lessons from r/AgainstHateSubreddits</head>
                <p style=""text-align: left; "">Adrienne Massanari (American University, Washington D.C.)</p>
                <p style=""text-align: left; "">Reddit embodies a carnivalesque spirit, often reflecting a kind of geek masculinity (Kendall, 2011) that champions both niche, technical prowess and clever humor (Massanari, 2015). At the same time, communities engaging in far-right rhetoric, such as the now-banned (and widely popular) r/The_Donald, have flourished in part because the platform relies almost exclusively on volunteer labor to moderate and grow communities (Matias, 2019). Shifting the responsibility and risk of moderating onto unpaid individuals allows Reddit to remain a “lean” organization with few employees, but also creates a kind of plausible deniability when it comes to so-called “alt-right” subreddits.</p>
                <p style=""text-align: left; "">In response to the growing threat that these subreddits present, and the lack of response from Reddit administrators, activists on the platform have created their own communities focused on highlighting hate speech pervasive on the platform. One such example is r/AgainstHateSubreddits, which is dedicated to exposing subreddits that may superficially conform to Reddit’s few rules, but also engage in transphobic, misogynistic, Islamophobic, and racist rhetoric. Through a critical discourse analysis (Fairclough, 2013) of popular postings on the subreddit, I explore how this community challenges Reddit’s politics and offers an ethical counterpoint to the toxic geek masculinity that pervades much of the platform. Drawing on work from platform studies (Bucher, 2018; Gillespie, 2010) and design justice (Costanza-Chock, 2020; D'Ignazio & Klein, 2020), I argue that Reddit’s governance, design, and platform policies work implicitly welcome and mainstream far-right communities, but that spaces like r/AgainstHateSubreddits provide critical forms of resistance and community for activists.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head type=""main"">Share my view: Harmonious debating culture on r/changemyview</head>
                <p style=""text-align: left; "">Thomas C. Messerli (University of Basel), Daria Dayter (University of Tampere)</p>
                <p style=""text-align: left; "">In current times, digital discourses are often understood in terms of polarization. Public lay metadiscourses are full of references to social bubbles and disparate parts of society, whereas academic scholars give a lot of focus to binary categories such as information/disinformation, truth/post-truth or outrage culture. Within this context, the debating culture on the subreddit r/ChangeMyView (CMV) stands out because it encourages what we could term persuasibility – the capacity or willingness of someone to change their opinion when encountering new information. While some work has been done on the specific strategies that commenters use to achieve the task at hand, i.e. to change the original poster’s (OP) view, little attention has been paid to the question how prepared OPs actually are to change their mind and how this “malleability of opinion” (Tan et al. 2016: 621) is discursively constructed. From this perspective, original posts – 
                    <hi rend=""italic"">submissions</hi> in Reddit terminology – are firstly performances of persuasibility, and secondly access points to persuasible-persuasive pairings, in which the subreddit community enacts its codified and tacit norms. In order to explore these pairings, we make use of the CMV corpus we have compiled and specifically compare submissions, delta-awarded comments, i.e. those comments that have changed the OP’s view, and the OP’s responses to delta-awarded comments. We do this comparison itself with a mixed-methods approach that is grounded in qualitative annotation of persuasibility in a sample of r/changemyview threads and scaled up to the corpus using corpus linguistic methods.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head type=""main"">“Science has no business in the mountains”: Stance-taking and expert knowledge on r/Mountaineering</head>
                <p style=""text-align: left; "">Sven Leuckert (TU Dresden)</p>
                <p style=""text-align: left; "">Stance-taking, as popularised in pragmatics and sociolinguistics by Du Bois (2007), refers to “the speaker’s (or writer)’s relationship to (a) the topic of discussion, (b) the interlocutor or audience, and (c) the talk (or writing) itself” (Kiesling et al. 2018: 684). On social media, stance-taking plays an important role in the discursive construction of relationships and may be employed as a gatekeeping device. In this talk, I focus on strategies of stance-taking as it is linked to the expression of expert knowledge on the subreddit r/Mountaineering. On this subreddit, stance-taking represents a dominant tool to establish who can be considered an expert and, hence, part of the knowledgeable in-group.</p>
                <p style=""text-align: left; "">In this talk, I explore which specific linguistic phenomena are employed by users of the subreddit to express stance in situations where expertise in mountaineering is in focus. After an initial manual assessment of recurring phenomena on the basis of randomly selected threads, a quantitative approach inspired by Kiesling et al.’s (2018) annotation scheme is used to establish the bigger picture of how stance-taking is employed as a gatekeeping device on r/Mountaineering. For this study, the entirety of r/Mountaineering from 2012 to August 2021 has been scraped and is taken into consideration. In sum, the findings suggest that, while quantitative methods are a useful addition in the investigation of stance on Reddit, they can only be complementary to an in-depth study of stance-taking phenomena in their discursive context.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Banga, R. and Mehndiratta, P.</hi> (2017). Tagging Efficiency Analysis on Part of Speech Taggers: International Conference on Information Technology (ICIT: 264–267.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Baumgartner, J., Zannettou, S., Keegan, B., Squire, M. and Blackburn, J.</hi> (2020). The Pushshift Reddit Dataset: Proceedings of the International AAAI Conference on Web and Social Media, 14th edn.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Behzad, S. and Zeldes, A.</hi> (2020). A Cross-Genre Ensemble Approach to Robust Reddit Part of Speech Tagging. http://arxiv.org/pdf/2004.14312v1.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Biber, D.</hi> (1988). Variation Across Speech and Writing. Cambridge University Press.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Bucher, T.</hi> (2018). If...then : algorithmic power and politics. Oxford University Press.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Clarke, I. and Grieve, J.</hi> (2019). Stylistic Variation on the Donald Trump Twitter Account: A Linguistic Analysis of Tweets Posted between 2009 and 2018. PloS one, 14(9), e0222062.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Costanza-Chock, S.</hi> (2020). Design justice: Community-led practices to build the worlds we need. The MIT Press.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">D'Ignazio, C. and Klein, L. F.</hi> (2020). Data feminism
                        <hi rend=""italic"">.</hi> The MIT Press.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Dayter, D, & Messerli, T. C.</hi> (2021). Persuasive language and features of formality on the r/ChangeMyView subreddit. Internet Pragmatics, 5(1): 165–195. 
                        <ref target=""https://doi.org/10.1075/ip.00072.day"">
                            <hi rend=""underline color(1155CC)"">https://doi.org/10.1075/ip.00072.day</hi>
                        </ref>
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Du Bois, J. W.</hi> (2007). The stance triangle. In Engelbretson, R. (Ed.), Stancetaking in Discourse. John Benjamins, pp. 139–182
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Fairclough, N.</hi> (2013). Critical discourse analysis: The critical study of language. Routledge.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Gessler, L., Peng, S., Liu, Y., Zhu, Y., Behzad, S. and Zeldes, A.</hi> (2020). AMALGUM – A Free, Balanced, Multilayer English Web Corpus: Proceedings of The 12th Language Resources and Evaluation Conference: 5267–5275.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Gillespie, T.</hi> (2010). The politics of ‘platforms’. New Media & Society, 12(3): 347–364.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Kendall, L.</hi> (2011). ‘White and nerdy’: Computers, race, and the nerd stereotype. The Journal of Popular Culture, 44(3): 505–524.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Kiesling, S. F, Pavalanathan, U., Fitzpatrick, J., Han, X. and Eisenstein, J.</hi> (2018). Interactional Stancetaking in Online Forums. Computational Linguistics 44(4): 683-718
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Liimatta, A.</hi> (2016). Exploring Register Variation on Reddit: A Mulit-Dimensional Study
                        <hi rend=""italic"">.</hi> Master thesis, University of Helsinki.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Liimatta, A.</hi> (2020). Using lengthwise scaling to compare feature frequencies across text lengths on Reddit. In Rüdiger, S. and Dayter, D. (Eds.), Corpus Approaches to Social Media
                        <hi rend=""italic"">.</hi> John Benjamins, pp. 111–130.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Liimatta, A.</hi> (forthc.). Register variation across text lengths: Evidence from social media. International Journal of Corpus Linguistics.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Massanari, A. L.</hi> (2015). Participatory culture, community, and play: Learning from reddit
                        <hi rend=""italic"" xml:space=""preserve"">. </hi>Peter Lang.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Matias, J. N.</hi> (2019). The Civic Labor of Volunteer Moderators Online. Social Media + Society, 5(2). https://doi.org/10.1177/2056305119836778
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"">Tan, C., Niculae, V., Danescu-Niculescu-Mizil, C. and Lee, L.</hi> (2016). Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions: Proceedings of the 25th International Conference on World Wide Web: 613–624.
                        <ref target=""https://doi.org/10.1145/2872427.2883081"">
                            <hi rend=""underline color(1155CC)"" xml:space=""preserve""> https://doi.org/10.1145/2872427.2883081</hi>
                        </ref>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,communicative practices;computer-mediated communication;online communities;reddit;social media,English,communication studies;contemporary;cultural analytics;english;europe;linguistics;social media analysis and methods
11832,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,A picture is worth a thousand words: Image analysis for the Digital Humanities: https://tutorial.thousandwords.art,,Stuart James;Mathieu Aubry;Nanne van Noord;Noa Garcia;Leonardo Impett,workshop / tutorial,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p style=""text-align: left; "">In this tutorial, we look at Computer Vision (CV) approaches developed to investigate Digital Humanities (DH) data and, more specifically, fine-art and cultural heritage. We will explain what approaches can achieve, how to train and use with a basic understanding of python to be applied to different types of visual data. By breaking down the tutorial into five parts (one per presenter), the tutorial will provide an overview of the research within CV and its current and future application within DH. We additionally attempt to provide some reflections on the use of Asian data and the limitations or challenges. While considering the current extensive narrative within the CV research community on bias in datasets and collections.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Tutorial Content</head>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Part 1: Retrieval and Knowledge Graphs </head>
                    <p style=""text-align: left; "">The use of CV for distant reading in image collections are generally within the setting of retrieval — searching via an example within a collection. To do this, a computational description of the image needs to generate to be then able to compare one image to another. How such a representation is learned is important to provide a powerful retrieval system. While using pre-trained approaches such as neural networks are useful, they fail to bridge the visual difference between photo-realistic images and common art or humanities image collections. In this part, we explore how anyone can train a neural network representation that is specific to their dataset with varying degrees of supervision, and specifically exploiting supervision that can be provided through Knowledge Graphs (or Semantic Web) to enhance the differential power of the representations.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Part 2: Content-based analysis </head>
                    <p style=""text-align: left; "">Most Deep Learning image techniques rely on annotated collections. While these might be available for some well-studied types of documents, they cannot be expected for more specialized studies or sources. Instead, one would have to rely on techniques that do not require training data. This part will discuss several such techniques to establish links between artworks and historical documents, including the use of generic local features, synthetic data, self-supervised learning, and object discovery techniques. In addition, this will include examples of applications for repeated patterns discovery in artwork collections, fine artwork alignment, document images segmentation, historical watermarks recognition, scientific illustration propagation analysis, and unsupervised Optical Character Recognition. In all cases, it will be shown that standard approaches can give useful baseline results when tuned adequately, but that developing dedicated approaches that take into account the specificity of the data and the problem significantly improves the results.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Part 3: Multi-Task Learning</head>
                    <p style=""text-align: left; "">Multi-Task Learning (MTL) is an increasingly prominent paradigm in CV and in Artificial Intelligence in general. It centers around the ability to perform multiple tasks based on a single input. For instance, it is possible to predict for a single image of an artwork when it was made by who and using what materials. Jointly performing these tasks involves specific modeling choices, resulting in clear benefits (robustness, improved performance), but it also has potential downsides (negative interference, increased complexity). In this part, we show when and how we might want to apply MTL, through a number of use cases, as well as an overview of the technical underpinnings. In addition, highlight the possibilities MTL provides for interpretability by shedding light on relations between tasks.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Part 4: Automatic interpretation</head>
                    <p style=""text-align: left; "">In CV, visual arts are often studied from an aesthetics perspective, mainly by analyzing the visual appearance of an art reproduction to infer its attributes (author, year of creation, theme, etc.), its representative elements (objects, people, locations, etc.), or to transfer the style across different images. However, understanding an artistic representation involves mastering complex comprehension processes, such as identifying the socio-political context of the artwork or recognizing the artist's main influences. In this part, we will explore fine-art paintings from both a visual and a language perspective. The aim is to bridge the gap between the visual appearance of an artwork and its underlying meaning by jointly analyzing its aesthetics and semantics. We will explore multimodal techniques for interpreting artworks, and we will show how CV approaches can learn to automatically generate descriptions for fine-art paintings in natural language.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Part 5: Using Computer Vision within humanities research</head>
                    <p style=""text-align: left; "">Most models in CV research are built to solve specific problems with measurable outcomes (often tied to a set of reference datasets): pixelwise segmentation, object detection, image captioning, keypoint detection, etc. With many open-source computer vision models for each kind of task, we have a wide horizon of powerful tools at our disposal: yet most of them don’t easily fit with research questions in art history, visual culture studies, or the visual humanities more generally. </p>
                    <p style=""text-align: left; "">By dissecting a series of previous projects in this area, this part will look at how researchers have negotiated these connections, including complex and difficult questions of bias, interpretability, and the epistemology of computational results within the humanities (and especially within cultural history). We will look at several methodological modes compatible with the affordances of CV, including image replication, computational iconography, and the study of visual phenomena captured through notational systems. </p>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Tutorial presenters’ brief bios</head>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Stuart James, Istituto Italiano di Tecnologia (IIT) & UCL DH</head>
                    <p style=""text-align: left; "">Researcher (Assistant Professor) in Computer Vision at the Istituto Italiano di Tecnologia (IIT). Stuart's research focus is on Visual Reasoning to understand the layout of visual content from Iconography (e.g. Sketches) to 3D Scene understanding. He is a PI on the MEMEX RIA EU H2020 project and Co-PI on the RePAIR EU FET H2020. Stuart has previously held PostDoc positions at IIT, University College London (UCL) and the University of Surrey. Also, at Surrey, Stuart was awarded his PhD in visual information retrieval using sketches. Stuart continues to hold an honorary position at UCL and UCL Digital Humanities.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Mathieu Aubry, École des Ponts ParisTech</head>
                    <p style=""text-align: left; "">Mathieu Aubry is a tenured researcher in the Imagine team of Ecole des Ponts, focussing on Computer Vision and Digital Humanities. He obtained his PhD from ENS in 2015 and his Habilitation (HDR) in 2019. He had a leading role in several digital humanity projects such as the Young Researcher EnHerit ANR project on enhancing heritage image databases. He was a keynote speaker in several venues, including most recently the ACM Multimedia 2021 workshop on Structuring and Understanding of Multimedia heritAge Contents (SUMAC). He is an associated editor for CVIU and was an area chair at numerous CV conferences.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Nanne van Noord, University of Amsterdam</head>
                    <p style=""text-align: left; "">Nanne van Noord is Assistant Professor in the Multimedia Analytics Lab of the University of Amsterdam. His research is focused on the intersection of multimedia analysis and visual culture. He did his PhD at Tilburg University on modeling the artist's style for recognition and reproduction, as part of the NWO Science4arts project Reassessing Vincent van Gogh. He previously worked in The Sensory Moving Image Archive (SEMIA) project, and coordinated the Computer Vision taskforce in the national infrastructure project CLARIAH.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Noa Garcia, Osaka University</head>
                    <p style=""text-align: left; "">Noa Garcia is an Assistant Professor at the Institute for Datability Science at Osaka University. Her research interests lay at the intersection of computer vision, natural language processing, and art. She has been involved in multiple projects related to computer vision for art, with a special focus on language description and interpretation. She moved to Japan in 2018, after completing her Ph.D. in Computer Science at Aston University, United Kingdom.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Leonardo Impett, University of Cambridge</head>
                    <p style=""text-align: left; "">Leonardo Impett is an Assistant Professor of Digital Humanities at the University of Cambridge. His main work has to do with computer vision for the ""distant reading"" of art history (CS applied to the humanities), and visual studies as a route to understanding computer vision (the humanities applied to CS). He was previously based at Durham University, Harvard University, the Max Planck Institute for Art History, and EPFL.</p>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Schedule</head>
                <figure>
                    <graphic n=""1001"" width=""16.002cm"" height=""9.70138888888889cm"" url=""Pictures/888eda173397b831951f90e26b35caaf.png"" rend=""inline""/>
                </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Acknowledgement</head>
                <p style=""text-align: left; "">This project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 870743</p>
            </div>
        </body>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,computer vision;cultural studies;image analysis;image retrieval;visual humanities,English,15th-17th century;18th century;19th century;artificial intelligence and machine learning;comparative (2 or more geographical areas);computer science;english;europe;humanities computing;image processing and analysis
11838,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Towards a prosopographical ecosystem: modelling, design, and implementation issues:",,Richard William James Hadden;Matthias Schlögl;Georg Vogeler,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading"">
                <head>The International Prosopography Interchange Format </head>
                <p>This presentation intends to describe ongoing work at the Austrian Centre for Digital Humanities and Cultural Heritage (ACDH-CH) on the International Prosopographical Interchange Format (IPIF). It presents IPIF’s design, and explores various conceptual and technical challenges arising from its implementation. </p>
                <p>IPIF is an API definition and data model enabling the sharing and querying of prosopographical data. The original IPIF paper (Vogeler et al. 2019) recognises the power of semantic web tools (RDF, OWL, SPARQL), but also highlights their shortcomings for an interoperable format, chiefly the absence of a standard data model and the complexity of SPARQL. (See Bradley 2020.) Such difficulties circumscribe uses such as ‘light-weight’ data access and querying (as opposed to complex data processing). Accordingly, IPIF opts for a simple RESTful API. </p>
                <p>In addition to a reference implementation, Papilotte (Vasold 2019), IPIF is intended to be implemented on top of existing projects, allowing access to data in a standardised format and providing the facilities for federated queries and as a data discovery tool. (Vogeler et al. 2019) </p>
            </div>
            <div type=""div1"" rend=""DH-Heading"">
                <head>The Data Model and API </head>
                <p>To achieve maximum interoperability, IPIF adopts a version of the ‘factoid model’ (Bradley 2005). This model separates 
                    <hi rend=""italic"">statements made about a person </hi>from the abstract idea of a 
                    <hi rend=""italic"">person</hi>, instead attributing statements to a researcher’s interpretation of a historical 
                    <hi rend=""italic"">source </hi>(Figure 1). This enables contradictory statements, made by distinct sources, to be recorded. As Baillie (2021) argues, this is not always desirable, some historical sources being more trustworthy than others; nevertheless, it is a requirement for an open ecosystem without any single ‘guiding hand’ that contradiction be permitted. 
                </p>
                <p>FIGURE 1: THE IPIF DATA MODEL </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/0d13151114d7b379e26cd4ebe98ffa33.png""/>
                    </figure>
                </p>
                <p>The API — described in OpenAPI — is a RESTful interface, allowing direct access to the four IPIF entity types (Factoid, Source, Person, Statement), and querying of statements through graph-like traversals (Figure 2). It returns JSON-LD for each entity, comprising content and/or metadata, and embeds references to related entities. </p>
                <p>The choice of Statement fields represents a highly pragmatic decision. These fields, allowing a label and a URI, were chosen to match the most obvious use-cases in prosopographical data; the 
                    <hi rend=""italic"">statementType </hi>field allows arbitrary extension beyond these standard statement types. 
                </p>
                <p>
                    <hi rend=""background-color(#ffffff) bold"">FIGURE 2: API EXAMPLES </hi>
                </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/0a6d88bd04f06ddf07876de329afc8bd.png""/>
                    </figure>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading"">
                <head>Implementations, issues and works-in-progress </head>
                <p>Since the original definition of the standard, IPIF endpoints have been implemented on top of several existing frameworks, including the ACDH-CH’s APIS platform (a Django- based platform for prosopographical projects) and as an eXist-DB module for serving TEI- XML personography data (typically from digital scholarly editions). IPIF client libraries for Python and JavaScript, allowing federated queries and data aggregation across several endpoints, have also been developed. Building these tools has afforded a wealth of practical experience, highlighting the strengths of the format and the difficulties involved in its implementation. This has led to several pragmatic decisions regarding the data model, API and the semantics of querying. </p>
                <list type=""unordered"">
                    <item>A 
                        <hi rend=""italic"">label </hi>field was introduced for Persons, allowing use cases such as autocompletes. The theoretically correct modelling — as a ‘naming statement’ — required too many additional requests to retrieve the appropriate information. 
                    </item>
                    <item>Persons and Sources allow multiple URIs (interpreted as owl:sameAs). Strictly, these should be Statements (i.e. non-definitive assertion that one Person or Source is the same as another: see Zedlitz 2009); but reconciling data from multiple endpoints is considerably easier when this information is a ‘meta’ field of a Person entity.</item>
                    <item>IPIF requires a Source for each Factoid. In many projects, data that would comprise an IPIF Statement is given with no source (e.g. name, death, profession of a person”). In this case, the source is taken to be the project itself. </item>
                    <item>
                        TEI-XML personographies can express a factoid model by applying the @source and @resp attributes to the sub-elements of a <person> entry (see Schwarz 2020), <lb/>
                        but this is optional. Pragmatically, we suggest using the metadata of the TEI document as fallback (@source, @resp, ancestor::TEI/teiHeader/ titleStmt/editor etc.).
                    </item>
                    <item>
                        To avoid ambiguity in combining statement filters in Person queries (does person/?place=Graz&role=professor mean “a professor in Graz” or “a professor, located in Graz for any reason”?), we defined a default behaviour (both conditions apply to the 
                            <hi rend=""italic"">same </hi>Statement) and an optional parameter independentStatements=true to allow ‘or’ conditions. 
                        <lb/>
                        In this presentation, we will argue that such decisions are justified by the requirements of interoperability; and that our experiences in developing IPIF thus far contribute usefully to debates surrounded data interoperability in the digital humanities.
                    </item>
                </list>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>Baillie, James. “Alternative Database Structures for Prosopographical Research”. 
                        <hi rend=""italic"">International Journal of Humanities and Arts Computing </hi>15, Nr. 1–2 (October 2021): 117– 32. 
                        <hi rend=""color(#0f54cc)"">https://doi.org/10.3366/ijhac.2021.0265</hi>. 
                    </bibl>
                    <bibl>Bradley, John Douglas. “A Prosopography as Linked Open Data: Some Implications from DPRR”. 
                        <hi rend=""italic"">Digital Humanities Quarterly </hi>014, Nr. 2 (29 July 2020). 
                        <hi rend=""color(#0f54cc)"">http://digitalhumanities.org/ dhq/vol/14/2/000475/000475.html</hi>. 
                    </bibl>
                    <bibl>Brradley, John, and Harold Short. “Texts into Databases: The Evolving Field of New-Style Prosopography”. 
                        <hi rend=""italic"">Literary and Linguistic Computing </hi>20, Nr. Suppl (1 January 2005): 3–24. 
                        <hi rend=""color(#0f54cc)"">https://doi.org/10.1093/llc/fqi022</hi>. 
                    </bibl>
                    <bibl>Pasin, Michele, and John Bradley. “Factoid-Based Prosopography and Computer Ontologies: Towards an Integrated Approach”. 
                        <hi rend=""italic"">Literary and Linguistic Computing </hi>30, Nr. 1 (1 April 2015): 86–97. 
                        <hi rend=""color(#0f54cc)"">https://doi.org/10.1093/llc/fqt037</hi>. 
                    </bibl>
                    <bibl>Vogeler, Georg, Matthias Schlögl, and Gunter Vasold. “Data Exchange in Practice: Towards a Prosopographical API (Preprint)”. Paper given at BD2019 in co-location with RANLP 2019 in Varna (2019). 
                        <hi rend=""color(#0f54cc)"">https://doi.org/10.17613/YW4H-5F09</hi>. 
                    </bibl>
                    <bibl>Schwartz, Daniel L, Nathan P Gibson, and Katayoun Torabi. “Modeling a Born-Digital Factoid Prosopography Using the TEI and Linked Data”. 
                        <hi rend=""italic"">Journal of the Text Encoding Initiative</hi>, 2020, 37. 
                    </bibl>
                    <bibl>Vasold, Gunter: Papilotte. A flexible and extensible IPIF server. 
                        <hi rend=""color(#0f54cc)"">https://github.com/ gvasold/papilotte </hi>(2019) 
                    </bibl>
                    <bibl>Zedlitz, Jasper. “Gedbas4all – New Data Model for Genealogy”. GenWiki, 2009. 
                        <hi rend=""color(#0f54cc)"">http:// wiki-en.genealogy.net/Gedbas4all/Article </hi>= English version of Zedlitz, Jasper. „Gedbas4all – neues Datenmodell für die Genealogie“. 
                        <hi rend=""italic"">Computergenealogie</hi>, Nr. 04 (2009). 
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,api;biography;factoid;lod;prosopography,English,"15th-17th century;5th-14th century;bce-4th century;data publishing projects, systems, and methods;digital biography, personography, and prosopography;english;global;history;humanities computing"
11841,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,A code for Murakami’s Tokyo: spatial diversity analyzed by digital means,,Simone Abbiati,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">From Shibuya ward with its intense nightlife in 
                <hi rend=""italic"" xml:space=""preserve"">After Dark </hi>and the commercial area of Kichijōji in 
                <hi rend=""italic"">Sputnik Sweetheart</hi>, to Setagaya’s highway in 
                <hi rend=""italic"">1Q84</hi>, Bunkyo's Rikugien Garden in 
                <hi rend=""italic"">Norwegian Wood</hi>, Aoyama Cemetery in 
                <hi rend=""italic"">South of the Border, West of the Sun</hi>, and the Pacific Hotel near Shinagawa station in 
                <hi rend=""italic"" xml:space=""preserve"">The Wind-Up Bird Chronicle – </hi>Haruki Murakami, arguably the most famous Japanese contemporary writer, has left his mark on the capital of Japan both within and outside of fiction. In his fourteen novels, Tokyo’s thousand faces appear in great detail, even though they are filtered through a wide variety of characters’ perspectives and reconceptualized by magical realism. Regardless of the literary space abstraction, Seymour Chatman’s theory affirms that literary characters are cognitively experienced in the same way a reader would get to know a person in real life; and Akhil Gupta’s research argues the existence of a link between spatial perception and cultural identity. This would suggest that the spatial conceptualization performed by literary characters entail a 
                <hi rend=""italic"" xml:space=""preserve"">forma vivendi </hi>ascribable to a certain cultural environment. But is it really that simple? Does an identifiable Tokyo's 
                <hi rend=""italic"">genius loci</hi> emerge from Murakami’s novels? In the wake of Computational Criticism, we will use code-writing to help us get a glimpse of the characters’ cognitive mapping processes and thus delve into a literary-cultural analysis, bearing in mind that imaginative literature is the result of layers of mediation and re-presentation causing straightforward cultural seeping-through to be questioned. In order to do this, we present a Python script able to extract spatial data concerning the cognitive mapping of Murakami’s fictional figures. 
            </p>
            <p style=""text-align: left; ""> In fact, in the last few years, literary spatiality has emerged both from a theoretical and a digital perspective. In light of this, the results given by the software application will be discussed in order to reflect on Tokyo as an example of Japanese urbanisation, and to identify pros and cons of digitally-assisted interpretive acts regarding spatiality. Lastly, in treating Murakami’s fictional spatiality with digital tools, particular attention will be given to recent criticism of distant reading and corpus selection. </p>
            <p style=""text-align: left; ""> From a technical perspective, the presented script will use Natural Language Processing to tokenize, tag, and parse a selected corpus from of Murakami's novels to eventually perform Named Entity Recognition. The script will identify when movement verbs present fictional characters as subjects, leading to the extraction of the starting points and destinations of some of their itineraries. Thus, it will be possible to identify meaningful landmarks and itineraries of some characters, leading to the schematization of their cognitive maps. </p>
            <p style=""text-align: left; ""> The spatial structures extracted by digital means will be interpreted in view of cultural differences that Eastern and Western societies present as far as living in metropolitan areas is concerned. Spurious results (counterfactual spatial indications, and phraseological expressions, among others) will also be considered from a technical perspective. Lastly, with respect to the multilingual DH approach, the analysis will be conducted onto the English corpus but a few observations the original text in Japanese language will be presented, thus suggesting new possible research paths.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Algee-Hewitt, M.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2017). Canon/Archive: Studies in Quantitative Formalism from the Stanford Literary Lab, N+1 Foundation</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Bode K.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2018). A World of Fiction: Digital Collections and the Future of Literary History, University of Michigan Press.</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Bode, K.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2020). </hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">«Why You Can</hi>
                        <hi rend=""italic"" style=""font-family:Arial Unicode MS;font-size:9pt"">’</hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">t Model Away Bias»</hi>
                        , Modern Language Quarterly, 81, 95-124
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Bushell, S.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2020). Reading and Mapping Fiction: Spatialising the Literary Text, Cambridge University Press</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Chatman, S.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2019). Story and Discourse: Narrative Structure in Fiction and Film, Cornell University Press</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Cooper, D. and Gregory, I.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2011) «</hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">Mapping the English Lake District: A Literary GIS»</hi>
                        , Transactions of the Institute of British Geographers 36, no. 1, 89–108
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Cooper, D., Donaldson, C., and Murrieta-Flores, P.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2016). Literary Mapping in the Digital Age, Burlington</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Gitelman L.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2013). Raw Data Is an Oxymoron, MIT Press</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Gupta, A. and Ferguson, J.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (1992). «</hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">Space, Identity, and the Politics of Difference»</hi>
                        , in Cultural Anthropology, Vol. 7, No. 1, pp. 6-23
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Herman, D.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2002). Story logic. Problems and possibilities of narrative, University of Nebraska Press.</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Heuser, R., Moretti, M., and Steiner, E.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2016). </hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">«The Emotions of London»</hi>
                        , Pamphlets of the Stan- ford Literary Lab
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve"">Hillman, J. </hi>
                        (1992). The Thought of the Heart and the Soul of the World, Spring
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Loper, E., Klein, E., Bird, S</hi>
                        . (2009). Natural Language Processing with Python, O’Reilly Media
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Marie-Laure Ryan, et al.</hi>
                        (2016). Narrating Space/spatializing Narrative: Where Narrative Theory and Geography Meet, Ohio State University Press
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Moretti F.</hi>
                        (1997). Atlas of the European Novel, Einaudi
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Moretti, F.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2013). Distant Reading, Verso</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Nan Z, D.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2019).</hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">«The Computational Case against Computational Literary Studies»</hi>
                        , in Critical Inquiry, 45
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve"">Schmid, C., Karaman, O., Hanakata, N. C., Kallenberger, P., Kockelkorn, A., Sawyer, L., Streule, M., & Wong, K. P. </hi>
                        (2018). Towards a new vocabulary of urbanisation processes: A comparative approach, Urban Studies, 55(1), 19–52
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Sorensen, A.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (1999). </hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">«Land Readjustment, Urban Planning and Urban Sprawl in the Tokyo Metropolitan Area»</hi>
                        , Urban Studies, 36(13), 2333–2360
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Strecher, M. C.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (1999). </hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">«Magical Realism and the Search for Identity in the Fiction of Murakami Haruki»</hi>
                        , The Journal of Japanese Studies , Vol. 25, No. 2, pp. 263-298
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Strecher, M. C.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2021). Dances with Sheep: The Quest for Identity in the Fiction of Murakami Haruki, University of Michigan Press</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Suter, R.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2008). The Japanization of modernity: Murakami Haruki between Japan and the United States, Harvard University Asia Center</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Tally, R.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2013). Spatiality, Routledge</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Underwood, T.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2019). Distant Horizons: Digital Evidence and Literary Change, University of Chicago Press</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Vasiliev, Y</hi>
                        . (2020). Natural Language Processing with Python and SpaCy: A Practical Intro- duction, No Starch Pres
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Westphal B.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2009). Geocriticism: Real and Fictional Spaces, Armando editore</hi>
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Helvetica Neue;font-size:9pt"">Wilkens, M.</hi>
                        <hi style=""font-family:Helvetica Neue;font-size:9pt"" xml:space=""preserve""> (2021). «</hi>
                        <hi rend=""italic"" style=""font-family:Helvetica Neue;font-size:9pt"">“Too isolated, too insular”: American Literature and the World»</hi>
                        , The journal of Cultural analytics
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,geocriticism;murakami;named entity recognition;nlp;text mining,English,"asia;contemporary;english;europe;geography and geo-humanities;literary studies;north america;spatial & spatio-temporal analysis, modeling and visualization;text mining and analysis"
11846,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Digital Humanities in the Wild: Bringing Humanistic Pedagogy to Open Source,,Lisa Tagliaferri,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">What do the digital humanities look like outside of the library and the classroom? This paper presents a possible site of digital humanities pedagogy within the realm of open source. </p>
            <p style=""text-align: left; "">In 2021, myself and a team built out and began to populate 
                <ref target=""https://learn.sourcegraph.com/"">Sourcegraph Learn</ref> (
                <ref target=""https://github.com/sourcegraph/learn"">https://github.com/sourcegraph/learn</ref>), an open source and open access web project that provides educational resources for software developers. A project with only a few contributors on a singular team is not necessarily in the spirit of open source, so during the month of October the team worked with the momentum of Hacktoberfest, the yearly celebration of open source, to invite and encourage more contributors to become involved in our project. We created a Hacktoberfest-specific readme.md file with instructions, added relevant tags, and created issues specific to programming languages and error messages. 
            </p>
            <p style=""text-align: left; "">Software developers were invited to contribute troubleshooting guides to the project. These guides would go into depth regarding common error messages that programmers encounter. For example, titles of these technical tutorials included “How to troubleshoot Java ArrayIndexOutOfBoundsException,” or “How to troubleshoot Python AttributeError.” Each tutorial included the full text of the error message, a way to replicate the error message, and two or three ways that a developer could recover from the error message. The troubleshooting guides are all available under the “troubleshooting” tag of the Sourcegraph Learn site (
                <ref target=""https://learn.sourcegraph.com/tags/troubleshooting"">https://learn.sourcegraph.com/tags/troubleshooting</ref>). 
            </p>
            <p style=""text-align: left; "">Altogether, over 40 Git issues were created soliciting contributions, nearly 40 pull requests were opened by prospective contributors, and over 30 high-quality pull requests were merged from contributors across 5 continents. These community-based efforts represent a global, distributed outcome of employing pedagogical techniques such as student-centered learning through encouraging practitioners to share what they have learned with others. </p>
            <p style=""text-align: left; "">This paper will present the approach to documentation, templatizing Git issues, and collaborative code reviews in order to demonstrate how others may be able to set up open-source humanities computing projects to encourage public contributors. In particular, I will draw from the body of work related to crowdsourcing in relation to museums and archives, including Mia Ridge’s edited collection 
                <hi rend=""italic"">Crowdsourcing our Cultural Heritage</hi> (2014), Melissa Terras’s “Crowdsourcing in the Digital Humanities” (2015), and the Getty Museum’s and Folger Library’s respective Zooniverse projects to encourage crowdsourcing. Additionally, this paper will explore how engaging in this space may benefit both open source and the humanities. 
            </p>
            <p style=""text-align: left; "">Following the presentation, the author would be interested in hearing from other researchers who may have accepted open-source contributors, and how others may have scaled their approach to digital pedagogy through open source. </p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">Deines, N. (2018). “Six Lessons Learned from Our First Crowdsourcing Project in the Digital Humanities.” 
                        <hi rend=""italic"">Getty Iris Blog</hi>, 
                        <ref target=""https://blogs.getty.edu/iris/six-lessons-learned-from-our-first-crowdsourcing-project-in-the-digital-humanities/"">https://blogs.getty.edu/iris/six-lessons-learned-from-our-first-crowdsourcing-project-in-the-digital-humanities/</ref>. 
                    </bibl>
                    <bibl style=""text-align: left; "">Folger Library. 
                        <hi rend=""italic"">Shakespeare’s World</hi>. 
                        <ref target=""https://www.zooniverse.org/projects/zooniverse/shakespeares-world"">https://www.zooniverse.org/projects/zooniverse/shakespeares-world</ref>. 
                    </bibl>
                    <bibl style=""text-align: left; "">Ridge, M. (2014). 
                        <hi rend=""italic"">Crowdsourcing Our Cultural Heritage</hi>. Ashgate.
                    </bibl>
                    <bibl style=""text-align: left; "">Terras, M. (2016). “Crowdsourcing in the Digital Humanities.” 
                        <hi rend=""italic"">A New Companion to Digital Humanities</hi>, edited by Schreibman, Siemens, Unsworth, Wiley-Blackwell, pp. 420-439.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,computer science;digital pedagogy;open source,English,computer science;contemporary;crowdsourcing;english;global;humanities computing;public humanities collaborations and methods
11851,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Comparing Symbolism Across Asian Cultural Contexts Using Graph Similarity Measures,,Bruno Sartini;Valentin Vogelmann;Marieke van Erp;Aldo Gangemi,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p>Symbols are an essential part of cultures as means to express ideas, values, traditions and as instantiations of belief systems (Kroeber and Kluckhohn, 1952; Brislin, 1976). Unsurprisingly, thus, symbols form the basis of a variety of comparative cultural studies such as evoked concepts in jewellery and ornaments (Zavvāri* and Chitsāziyān, 2021), rituals, mottos, and icons (Manners, 2011), symbolism of trees, dragons, and tree of life (Rival, 2020; Yuan and Sun, 2021; Reno, 1977).</p>
                <p>Guided by Martinho (2018), who argues for a shift in cultural studies towards quantitative approaches, and Zepetnek (1999), who adapted comparative literature methodology to identify parallels between cultures, we propose a computational approach that uses symbols for quantified comparative cultural analyses. Leveraging information contained in HyperReal (Sartini et al., 2021), a novel database of symbolism, we define two quantitative measurements of cultural similarity which we apply to its data.</p>
                <p>Focussing on a set of cultural contexts from the continent of Asia, and using the defined similarity measures, we address two research questions:</p>
                <list type=""ordered"">
                    <item>Does symbolism provide a useful basis for quantitative cultural comparisons? That is, to what extent does it reproduce expected similarities, and does it have the potential to highlight new, unexpected connections?</item>
                    <item>Do cultures tend to be more similar in terms of their symbols or in terms of the symbolic meanings that their symbols refer to?</item>
                </list>
                <p>For RQ1, we analyse the values of our similarity measures and the clusters of cultures they induce. Additionally, we contrast the similarities of Asian cultural contexts among themselves with two European cultural contexts: Christian and Greco-Roman.</p>
                <p>For RQ2, we analyse how similarity values change when applied to either only symbols or only symbolic meanings, as they exist independently in HyperReal.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Linking symbols</head>
                <p>Symbolic knowledge has previously been modelled in a semantic web context by (Sartini and Gangemi, 2021) and (Sartini et al., 2021) resulting in the creation of HyperReal, a multi-cultural knowledge graph containing more than 40,000 symbolic meaning relationships (simulations), following the Simulation Ontology schema
                    <note place=""foot"" xml:id=""ftn1"" n=""1"">
                        <p rend=""footnote text""> https://w3id.org/simulation/docs</p>
                    </note>. In this ontology, symbols (simulacra) are linked to their symbolic meanings (reality counterpart) through an n-ary relationship class Simulation. Simulations are also linked to one or more cultural contexts. Figure 1 shows the example of a mirror (simulacrum), that, in the Japanese context, symbolises the sun (reality counterpart) using HyperReal’s structure.
                </p>
                <figure>
                    <graphic n=""1001"" width=""16.002cm"" height=""5.180541666666667cm"" url=""Pictures/3b919f88b9223f826a1653e0cd29d27a.png"" rend=""inline""/>
                    <head>Mirror-sun simulation example</head>
                </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Data selection and extraction</head>
                <p>From HyperReal, we selected the 15 unambiguously Asian contexts with the highest number of simulations: Ainu, Buddhist, Cambodian, Chinese, Hindu, Indic, Jain, Japanese, Kalmyk, Mongolian, Philippine, Taoist, Tibetan, Vietnamese, Zoroastrian. This set comprises various types of cultural contexts, such as nationalistic (Chinese) or religious-philosophical (Buddhist), and includes intricate relationships (e.g., Chinese and Taoist). Anticipating that these aspects would emerge from our quantitative analyses themselves, we treat all contexts as equivalent and perform direct comparisons. After the selection, we extracted the subgraphs containing the simulations associated with each context along with the labels for their simulacra and reality counterparts.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Measuring similarity</head>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Semantic approach</head>
                    <p>Being embodied by linguistic expression allows us to measure symbols' and their symbolic meanings’ semantic similarity, for which we use the spaCy
                        <note place=""foot"" xml:id=""ftn2"" n=""2"">
                            <p rend=""footnote text""> https://spacy.io/</p>
                        </note> and Wiki2Vec (Yamada et al., 2020) Python implementations.
                        <note place=""foot"" xml:id=""ftn3"" n=""3"">
                            <p rend=""footnote text""> We measure cosine similarities between vectors of symbols and symbolic meanings generated using the mentioned models.</p>
                        </note> We then use the Jaccard similarity metric (Jaccard, 1901) to aggregate sets of semantic similarities for a given pair of cultures. Additionally, we apply weighting according to 
                        <hi rend=""bold"">symbolic impact</hi> and 
                        <hi rend=""bold"">symbolic referencing</hi>, where we define 
                        <hi rend=""bold"">symbolic impact</hi> as the number of symbolic meanings associated with a symbol in a specific context and 
                        <hi rend=""bold"">symbolic referencing</hi> as the number of times a symbolic meaning is denoted by a symbol in a specific context.
                    </p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Structural approach</head>
                    <p>We use graph edit distance (Hagberg et al., 2008) to compute the structural similarity
                        <note place=""foot"" xml:id=""ftn4"" n=""4"">
                            <p rend=""footnote text""> Similarity = 1-graph edit distance</p>
                        </note> of the extracted cultural contexts’ subgraphs. This measurement provides an interface into the similarities of how cultures structurally organise symbols, agnostic of the semantics of symbols, and is thus complementary to the semantic approach.
                    </p>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Results</head>
                <p>As displayed by Figure 2, our measurements lead to an intricate overall picture of cultural similarities. Whereas, for instance, a larger culture like Buddhist is similar to Chinese, Hindu, Japanese and Taoist; smaller ones like Ainu or Kalmyk are distant, especially semantically, from most other cultures. </p>
                <p>Semantic similarity generally seems to be the more conservative, and therefore more often intuitively correct, although counterexamples exist: Jain and Indic, two relatively close cultural contexts, are structurally similar but not semantically so. This underlines the complementary nature of both measurements and is mirrored by the clusters induced from the similarity matrices (Figure 3).</p>
                <p>Here, too, groupings of cultures are mostly according to intuition although it is clear that quantitative measures require being supplemented with other sources of information. Then again, as exemplified by the Greco-Roman and Christian cultures, which distinguish themselves from these Asian cultural contexts, connections emerge that are worth further investigation.</p>
                <figure>
                    <graphic n=""1002"" width=""16.001625cm"" height=""8.313208333333334cm"" url=""Pictures/47f67db9ac22c030dc474c4d2a349d57.PNG"" rend=""inline""/>
                    <head>Heatmap of the semantic (left) and structural (right) semantic matrices</head>
                </figure>
                <figure>
                    <graphic n=""1003"" width=""16.002cm"" height=""8.037366666666667cm"" url=""Pictures/be27b079eae372e2d6130a892a1fa0d6.PNG"" rend=""inline""/>
                    <head>Hierarchical clustering induced by semantic (left) and structural (right) similarity matrices. Colours indicate clusters</head>
                </figure>
                <p>Regarding RQ2, the investigated cultures, on average, have slightly higher similarities in terms of their symbols than their symbolic meanings. Additionally, Figure 4 shows that some cultures tend to be moderately more similar according to one of the two measurements, such as the Chinese-Jain or the Zoroastrian-Ainu pairs. Thus, cultures seem to not be more similar in terms of either symbols or symbolic meanings, but these have complementary effects to explaining cultural similarity.</p>
                <figure>
                    <graphic n=""1004"" width=""16.002cm"" height=""8.189055555555555cm"" url=""Pictures/4444f40e871e68b4e0164bfc7b7fd636.PNG"" rend=""inline""/>
                    <head>Similarity matrix given by the semantics of symbols themselves (left) and symbols‘ meanings (right)</head>
                </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Conclusions</head>
                <p>With this work, we initiate quantitative methods for investigations into the similarities of cultures based on symbolism. We provide evidence for their usefulness as a complement to established comparative cultural studies and predict that situating our findings within this field will facilitate new discussions. To this end, future work should also apply the methodology proposed here to larger global sets of cultures to put the similarities within the set of Asian cultures considered here into perspective.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Brislin, R. W.</hi> (1976). Comparative research methodology: Cross-cultural studies. 
                        <hi rend=""italic"">International Journal of Psychology</hi>, 
                        <hi rend=""bold"">11</hi>(3): 215–29 doi:10.1080/00207597608247359.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Hagberg, A., Swart, P. and Chult, D.</hi> (2008). Exploring Network Structure, Dynamics, and Function Using NetworkX.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Jaccard, P.</hi> (1901). Etude de la distribution florale dans une portion des Alpes et du Jura. 
                        <hi rend=""italic"">Bulletin de La Societe Vaudoise Des Sciences Naturelles</hi>, 
                        <hi rend=""bold"">37</hi>: 547–79 doi:10.5169/seals-266450.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Kroeber, A. L. and Kluckhohn, C.</hi> (1952). Culture: a critical review of concepts and definitions. 
                        <hi rend=""italic"">Papers. Peabody Museum of Archaeology & Ethnology, Harvard University</hi>, 
                        <hi rend=""bold"">47</hi>(1): viii, 223–viii, 223.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Manners, I.</hi> (2011). Symbolism in European integration. 
                        <hi rend=""italic"">Comparative European Politics</hi>, 
                        <hi rend=""bold"">9</hi>(3): 243–68 doi:10.1057/cep.2010.11.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Martinho, T. D.</hi> (2018). Researching Culture through Big Data: Computational Engineering and the Human and Social Sciences. 
                        <hi rend=""italic"">Social Sciences</hi>, 
                        <hi rend=""bold"">7</hi>(12). Multidisciplinary Digital Publishing Institute: 264 doi:10.3390/socsci7120264.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Reno, S. J.</hi> (1977). Religious Symbolism: A Plea for a Comparative Approach. 
                        <hi rend=""italic"">Folklore</hi>, 
                        <hi rend=""bold"">88</hi>(1). [Folklore Enterprises, Ltd., Taylor & Francis, Ltd.]: 76–85.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Rival, L. (ed).</hi> (2020). 
                        <hi rend=""italic"">The Social Life of Trees: Anthropological Perspectives on Tree Symbolism</hi>. London: Routledge doi:10.4324/9781003136040.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Sartini, B., van Erp, M. and Gangemi, A.</hi> (2021). Marriage is a Peach and a Chalice: Modelling Cultural Symbolism on the Semantic Web. 
                        <hi rend=""italic"">Proceedings of the 11th on Knowledge Capture Conference</hi>. (K-CAP ’21). New York, NY, USA: Association for Computing Machinery, pp. 201–08 doi:10.1145/3460210.3493552. https://doi.org/10.1145/3460210.3493552 (accessed 9 December 2021).
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Sartini, B. and Gangemi, A.</hi> (2021). Towards the unchaining of symbolism from knowledge graphs: how symbolic relationships can link cultures. 
                        <hi rend=""italic"">Book of Extended Abstracts of the 10th National AIUCD Conference.</hi> Pisa, pp. 576–80.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Yamada, I., Asai, A., Sakuma, J., Shindo, H., Takeda, H., Takefuji, Y. and Matsumoto, Y.</hi> (2020). Wikipedia2Vec: An Efficient Toolkit for Learning and Visualizing the Embeddings of Words and Entities from Wikipedia. 
                        <hi rend=""italic"">ArXiv:1812.06280 [Cs]</hi> http://arxiv.org/abs/1812.06280 (accessed 11 December 2021).
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Yuan, L. and Sun, Y.</hi> (2021). A Comparative Study Between Chinese and Western Dragon Culture in Cross-Cultural Communication. Atlantis Press, pp. 74–77 doi:10.2991/assehr.k.210121.015. https://www.atlantis-press.com/proceedings/sschd-20/125951577 (accessed 24 November 2021).
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Zavvāri*, M. and Chitsāziyān, A.</hi> (2021). A Comparative Study on the Symbolism in Turkmen and Baluch Ornaments in Iran. 
                        <hi rend=""italic"">Journal of Iranian Handicrafts</hi>, 
                        <hi rend=""bold"">3</hi>(2). دانشگاه کاشان: 121–30.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"">Zepetnek, S. T. D.</hi> (1999). From Comparative Literature Today toward Comparative Cultural Studies. doi:10.7771/1481-4374.1041.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,culture similarity;linked open data;symbolism,English,15th-17th century;18th century;5th-14th century;asia;comparative (2 or more geographical areas);computer science;cultural analytics;cultural studies;english;europe;network analysis and graphs theory and application
11871,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,DFG 3D-Viewer – Development of an infrastructure for digital 3D reconstructions,,Igor Piotr Bajena;Daniel Dworak;Piotr Kuroczyński;René Smolarski;Sander Münster,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p>An important element in digital 3D reconstruction, in the fields of archeology, art and architecture history, is the subsequent visualization of the result (Messemer, 2016). The standardization of the documentation and publication is seen as the most important priority across the board (Cieslik, 2020). Widely established 3D repositories with integrated 3D visualization such as Sketchfab
                    (<ref target=""https://sketchfab.com/"">https://sketchfab.com/</ref>) belong to a commercial offer, while 3D viewers introduced by scientific institutions like Kompakkt 
                    (<ref target=""https://kompakkt.de/home"">https://kompakkt.de/home</ref>)
                    or by other research projects like patrimonium.net (Dworak, Kuroczyński, 2016) have still not provided approved and applied standards for the documentation and publication of 3D models in the field of hypothetical 3D reconstruction of art and architecture.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Project assumptions</head>
                <p>Against this background, the project “DFG 3D-Viewer - Infrastructure for digital 3D reconstructions” was launched, which the goal is to provide an offer of permanent infrastructure for decentralized web-based display of models in the DFG 3D-Viewer and in suitable Virtual Research Environments (VRE), accompanied by low threshold interface usage
                    (<ref target=""http://dfg-viewer.de/en/dfg-3d-viewer"">http://dfg-viewer.de/en/dfg-3d-viewer</ref>).
                    The work presented here concerns the results of the first phase of the project including the definition of documentation standards for web-based 3D publication of the digital reconstruction models and the development of the web-based 3D-viewer for digital datasets as a minimal-effort plugin. Proposed solution considers a generic approach with adaptability and reusability (Münster, 2019), respects FAIR principles
                    (<ref target=""https://www.go-fair.org/fair-principles/"">https://www.go-fair.org/fair-principles/</ref>) and follows existing DFG (German Research Foundation) standards
                    (<ref target=""https://www.dfg.de/en/research_funding/principles_dfg_funding/good_scientific_practice/index.html"">https://www.dfg.de/en/research_funding/principles_dfg_funding/good_scientific_practice/index.html</ref>).
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Minimal documentation standard</head>
                <p>Analysis of documented metadata of the chosen commercial and institutional 3D repositories formed the basis for the definition of a scheme for documentation (Fig. 1). The developed data set was discussed among the community in the form of a survey, which significantly advanced the work towards establishing a standard. It also allowed to emerge documentation-related functionalities of the viewer, such as automatic rendering of the preview images or the displaying the information about model geometry (3D metadata) in the viewer window. The documentation scheme was implemented in a new prototypical 3D repository created in WissKI-based VRE (<ref target=""http://wiss-ki.eu/"">http://wiss-ki.eu/</ref>), which has already been successfully used in several projects of digital reconstructions at the University of Applied Sciences Mainz (Kuroczyński et al., 2022; <ref target=""https://www.new-synagogue-breslau-3d.hs-mainz.de"">https://www.new-synagogue-breslau-3d.hs-mainz.de</ref>). The data model in the repository uses the CIDOC Conceptual Reference Model (<ref target=""https://www.cidoc-crm.org/"">https://www.cidoc-crm.org/</ref>) as an ontology. The fundamental research on data modelling was carried out along the community in order to concerns about different combinations of classes and properties to describe the same aspects of documentation.</p>
                            <figure>
                                <graphic n=""1001"" width=""15.578666666666667cm"" height=""14.499166666666667cm"" url=""Pictures/bbce4e4878f90176ee0d4b8b29de8151.jpeg"" rend=""inline""/>
                        <head>Fig.1</head>
               <p>The comparison of metadata sets in chosen institutional and commercial 3D web-based repositories (©2021, Hochschule Mainz).</p>
                            </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Framework architecture of the 3D Viewer</head>
                <p>Comparing present 3D viewer solutions, it was decided to take the following properties into account: support for 2D & 3D objects, variety of source formats, support for complex objects, modern technology based, suitable for hand-modeled and laser-scanned objects, 3D world operations, level of detail (LoD) as models representations, compression of 3D objects, 3D metadata, utilities/tools, documentation.</p>
                <p>It appears that only a few 3D viewers fulfill more than half of the requirements. In fact, some of the analyzed applications support 2D/3D objects and a variety of formats, but some are still missing (PLY, XYZ, DAE) (Champion, Rahaman, 2020). These technologies are optimized for hand-modeled objects, while others only for laser-scanned ones. Three of them allow 3D world operations and support 3D metadata, nevertheless none of them supports 3D compression.</p>
                            <figure>
                                <graphic n=""1002"" width=""15.536333333333333cm"" height=""8.487833333333333cm"" url=""Pictures/b0be88dad23201e16a47cb7873819cf4.png"" rend=""inline""/>
                        <head style=""text-align: left;"">Fig.2</head>
               <p>Comparison of functionalities of the most competitive 3D viewers on the market (©2021, Hochschule Mainz).
                            </p>
            </figure>
                <p>The architecture of the DFG 3D-Viewer is developed considering existing web-based 3D viewers (Champion, Rahaman, 2020; Fernie at al., 2020). Conducted research compares existing infrastructures and viewers (Fig. 2), as well as the concept of a modular architecture for the DFG 3D-Viewer. It concludes that the framework for the scientific 3D infrastructure (considering documentation and publication) should be cross-browser, platform independent and based on modern, promising and long-term supported technology. The viewer should allow viewing of 3D models with textures, stored in the most common formats used nowadays , i.e. OBJ, DAE, FBX, JSON (Cieslik, 2020). It should be also capable of loading 2D images (JPG, PNG, TIFF) (Cieslik, 2020), 3D metadata and provide 3D world operations on models (Fernie at al., 2020). Solution should be integrable out of the box, open source and client-only in order to distribute workload away from the server and minimize the requirements for repository providers to support the DFG 3D-Viewer.</p>
                <p>The developed framework is based on the existing 3D library - three.js. Implementation was prepared in modern and interchangeable programming languages and technologies as JavaScript, PHP or Python. Architecture is optimized to be technology-independent and can be easily exchanged for any other client-side viewer. The solution is suitable for complex, hand-modeled, laser-scanned objects and 3D metadata as well. The viewer is extended to meet the requirements of the specialist community, including the possibility of displaying highly complex geometries and multiple data formats (inter alia IFC and FBX) (Fernie at al., 2020). Moreover, uploading 3D data triggers automatic unattended compression, based on Draco algorithm, and encoding into the glTF format which is optimized for web-based visualization (Fig. 3).</p>
                            <figure>
                                <graphic n=""1003"" width=""15.726833333333333cm"" height=""14.499166666666667cm"" url=""Pictures/220727_mockup.jpg"" rend=""inline""/>
                        <head style=""text-align: left;"">Fig.3</head>
               <p>Rendered entity in the 3D Repository with visualized 3D model in the DFG 3D-Viewer (©2022, Hochschule Mainz).</p>
                            </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Further research</head>
                <p>The next stage of the project is the implementation of the developed modular DFG 3D-Viewer in various academic institutions' repositories, which will be realized in the next two years. The final solution will be available as minimal-effort plugin (set of scripts) for any environment that supports JavaScript, PHP and Python. The datasets from decentralised library repositories will be indexed and displayed in centralized browser web service. As a result, users are provided with a uniform interface for viewing digitised media. The project serves also for further fundamental research conducted by two PhDs in work in the topic of the scientific validation of published 3D reconstruction data and also visualization of the uncertainty on the published 3D models. </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Champion, E. and Rahaman, H.</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (2020). Survey of 3D digital heritage repositories and platforms, </hi>
                        <hi rend=""italic"" style=""font-size:9pt"">Virtual Archaeology Review,</hi>
                        <hi rend=""bold"" style=""font-size:9pt"">11(23)</hi>
                        :1.
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""https://www.cidoc-crm.org/"">
                            https://www.cidoc-crm.org/
                        </ref>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed 09 December 2021)</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Cieslik, E.</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve"">(2020). </hi>
                        <hi rend=""italic"" style=""font-size:9pt"">3D Digitization in Cultural Heritage Institutions Guidebook</hi>
                        . Baltimore: Dr. Samuel D. Harris National Museum of Dentistry.
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""https://www.dfg.de/en/research_funding/principles_dfg_funding/good_scientific_practice/index.html"">
                            https://www.dfg.de/en/research_funding/principles_dfg_funding/good_scientific_practice/index.html
                        </ref>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed 11 April 2022)</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""http://dfg-viewer.de/en/"">
                            http://dfg-viewer.de/en/
                        </ref>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed 10 December 2021)</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Dworak, D., Kuroczyński, P</hi>
                        . (2016) Virtual Reconstruction 3.0 – New Approach of Web-based Visualisation and Documentation of Lost Cultural Heritage.
                        <hi rend=""italic"" style=""font-size:9pt"">Proceedings of 6th International Conference EuroMed</hi>
                        , Cyprus: Springer International Publishing LNCS Series, pp. 292 – 306.
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""https://www.go-fair.org/fair-principles/"">
                            https://www.go-fair.org/fair-principles/
                        </ref>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed 10 December .2021)</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Fernie, K. et al.</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (2020).</hi>
                        <hi rend=""italic"" style=""font-size:9pt"">3D content in Europeana task force</hi>
                        , Hague: Europeana Network Association.
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""https://kompakkt.de/home"">
                            https://kompakkt.de/home
                        </ref>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed on 10 December 2021).</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Kuroczyński, P.</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve"">(2017). Virtual Research Environment for Digital 3D Reconstructions: Standards, Thresholds and Prospects. In: Frischer, B., Guidi, G., Börner, W., (Hg.) </hi>
                        <hi rend=""italic"" style=""font-size:9pt"">Cultural Heritage and New Technologies 2016 Proceedings</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve"">, </hi>
                        <hi rend=""italic"" style=""font-size:9pt"">Studies in Digital Heritage,</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> Open Access Journal, Vol. 1, No. 2, pp. 456 – 476.</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Kuroczyński, P., Bajena, I., Große, P., Jara, K., Wnęk K.</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve"">(2022) Digital Reconstruction of the New Synagogue in Breslau: New Approaches to Object-Oriented Research. In Niebling, F., Münster, S. (eds.),  </hi>
                        <hi rend=""italic"" style=""font-size:9pt"">Proceedings of the Conference on Research and Education in Urban History in the Age of Digital Libraries & Digital Encounters with Cultural Heritage</hi>
                        , Springer, January 2022.
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Messemer, H.</hi>
                        (2016) The Beginnings of Digital Visualisation of Historical Architecture in the Academic Field. In: Hoppe, S. and Breitling, S. (eds.),  V
                        <hi rend=""italic"" style=""font-size:9pt"">irtual Palaces, Part II. Lost Palaces and their Afterlife. Virtual Reconstruction between Science and Media</hi>
                        , München: PALATIUM, pp. 21-54.
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""bold"" style=""font-size:9pt"">Münster, S.</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (2019) Digital Cultural Heritage as Scholarly Field – Topics, Researchers and Perspectives from a bibliometric point of view In: </hi>
                        <hi rend=""italic"" style=""font-size:9pt"">Journal of Computing and Cultural Heritage</hi>
                        <hi rend=""bold"" style=""font-size:9pt"">12(3)</hi>
                        : 22-49.
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""https://www.new-synagogue-breslau-3d.hs-mainz.de"">
                            https://www.new-synagogue-breslau-3d.hs-mainz.de
                        </ref>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed on 08 December 2021)</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <hi rend=""underline color(0563C1)"" style=""font-size:9pt"">https://www.patrimonium.net</hi>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed on 10 December 2021)</hi>
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""https://sketchfab.com/"">
                            https://sketchfab.com/
                        </ref>
                        (accessed on 19 April 2022)
                    </bibl>
                    <bibl rend=""List Paragraph"">
                        <ref target=""http://wiss-ki.eu/"">
                            http://wiss-ki.eu/
                        </ref>
                        <hi style=""font-size:9pt"" xml:space=""preserve""> (accessed on 09 December 2021)</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,archaeology;art and architecture history;data model;digital 3d reconstruction;documentation,English,"archaeology;contemporary;digital research infrastructures development and analysis;english;global;library & information science;metadata standards, systems, and methods"
11872,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,The Concept of Nature in German Romanticism: An Approximation:,,Inna Uglanova;Evelyn Gius,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p>Nature plays a particular role in the Romantics’ worldview. This concept is characterised by a shift in emphasis from nature as a passive principle (cf. natura naturata by Schelling, 1994) to nature as a subject, an active, creative principle (natura naturans ibid.). The unifying force between these states is the spirit (‘Weltseele’). This leads to the dissolving of established boundaries and oppositions between a human being and nature in romanticist texts (cf. Wanning, 2005). Romantics transform the vertical world order into a horizontal one and create a worldview where human being forms a unity with the world around them. Among other, these transformations manifest themselves in the anthropomorphisation of nature.</p>
                <p>Our approach is therefore to find out how nature is represented in Romanticist texts by analysing whether it is depicted as an active entity and related to the concept of human being, both in terms of anthropomorphism and the possible semantic projection as a holistic concept. While we acknowledge that nature is a complex concept with blurred boundaries, in this contribution we would like to demonstrate how one can gain insights with a relatively simple approach focused on nature as ‘nature’ and comparing Romanticism to other epochs.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Data</head>
                <p>For our analysis, we compiled two corpora. Our main corpus contains 90 novels (10,511,420 tokens) from 1780 until 1850, coinciding with the epoch of German Romanticism. A comparative corpus with 102 novels (10,423,812 tokens) from Realism (56 novels) and Naturalism (46 novels) published from 1880 until 1900 was taken from the d-Prose corpus (Gius et al., 2020). This corpus was selected for a contrastive analysis since, in Naturalism and Realism, writers saw their conception of the world as the antithesis of Romanticism.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Methods</head>
                <p>For exploring nature’s agency in the sociological sense, i.e., the ability to act independently, we took the grammatical position of ‘nature’ as a proxy and parsed both corpora using spaCy (Honnibal et al., 2021). The subsequent analysis of the possible anthropomorphic representation of nature in Romanticism and Naturalism is based on bigram collocations of ‘nature’ identified with NLTK (Bird et al., 2009). The strength of association between collocates was measured by log-likelihood for collocations occurring more than three times. As an exploration of the semantic dimensions of nature, we finally constructed word embedding models for nature and human beings in Romanticism and Naturalism using word2vec in gensim (Mikolov et al. 2013; Rehurek, 2021) and visualised them with the t-SNE-algorithm (Maaten and Hinton, 2008) implemented by scikit-learn (Pedregosa et al., 2011).</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Selected Results</head>
                <p>We now sketch some key results from our project. Table 1 shows the most frequent verbs in sentences where ‘nature’ is used in the subject and thus, from a grammatical perspective, in an active position. In both cases, nature seems to be conceptualised as acting human-like. However, the proportion of sentences with ‘nature’ as subject is higher in Romanticism with 0,38% (i.e., 1,382 sentences out of 363,318) against 0,06% (305 sentences out of 545,023).</p>
                <p>
                    <figure>
                        <graphic url=""Pictures/d2709ae23c867c1cc96ecb83011579a9.jpg""/>
                    </figure>
                    <hi rend=""bold"">Table 1</hi>: Most frequent verbs in sentences with ‘nature’ as subject in Romanticism and Naturalism/Realism
                </p>
                <p>Interestingly, we found more human-related words in bigrams in the Naturalist’s subset than in Romanticism (see highlighted words in Table 2). However, the semantics of these words refer rather to human nature in the sense of character traits than to nature.</p>
                <p>
                    <figure>
                        <graphic url=""Pictures/61335d9e04f47e54a1757c3166dc083c.jpg""/>
                    </figure>
                    <hi rend=""bold"">Table 2</hi>: Collocations with ‘nature’ in Romanticism and Naturalism
                </p>
                <p>The word2vec analysis (see Table 3) seems to confirm this. In the compared datasets, different concepts of ‘nature’ are contextualised. While the Romantics aestheticise 
                    <hi rend=""bold"">nature</hi>, Naturalists refer to ‘nature’ as 
                    <hi rend=""bold"">human</hi> characteristics and thus as 
                    <hi rend=""bold"">human</hi> nature.
                </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/c7121bb1dce0a75ce2e79d7eb0f29485.jpg""/>
                    </figure>
                    <hi rend=""bold"">Table 3: </hi>Similar word vectors to the keyword ‘nature’
                </p>
                <p>Finally, the t-SNE-visualisations with the projections of the vectors ‘human being’ and ‘nature’ into the same two-dimensional space make the different conceptions of Romanticism and Naturalism visible (cf. Fig. 1 and 2).</p>
                <p>
                    <figure>
                        <graphic url=""Pictures/3551f008183186b004963fd7cd0c8171.jpg""/>
                    </figure>
                    <hi rend=""bold"">Figure 1</hi>: The t-SNE projection of the word vectors ‘nature’ and ‘human being’ (Romanticism)
                </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/8cc7c6655b1d3985a07b4f2d63411d62.jpg""/>
                    </figure>
                    <hi rend=""bold"">Figure 2</hi>: The t-SNE projection of the word vectors ‘nature’ and ‘human being’ (Naturalism)
                </p>
                <p>While the–more compact–cluster of the ‘nature’ vector in Romanticism is built by words belonging to the semantic field of human being or aesthetical, metaphysical concepts, in Naturalism, it is more directed towards human-related, often moral or character-related, properties. The ‘human being’ clusters, on the contrary, address humans in their social roles in both epochs. Moreover, the ‘nature’ cluster for Romanticism seems to point at the ‘Universalpoesie’ in Romanticism with its ideal of merging the fields of life, science, art and nature.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Bird, S., Klein, E. and Loper, E.</hi> (2009). 
                        <hi rend=""italic"">Natural Language Processing with Python</hi>. Beijing; Cambridge [Mass.]: O’Reilly.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Gius, E., Guhr, S. and Adelmann, B.</hi> (2020). d-Prose 1870-1920 Zenodo doi:10.5281/zenodo.4315209. https://zenodo.org/record/4315209 (accessed 7 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Honnibal, M., Montani, I. and Van Landeghem, S.</hi> (2021). 
                        <hi rend=""italic"">SpaCy · Industrial-Strength Natural Language Processing in Python</hi>. Python and Cython Berlin: Explosion https://spacy.io/ (accessed 7 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Maaten, L. van der and Hinton, G.</hi> (2008). Visualizing Data using t-SNE. 
                        <hi rend=""italic"">Journal of Machine Learning Research</hi>, 
                        <hi rend=""bold"">9</hi>(86): 2579–605.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S. and Dean, J.</hi> (2013). Distributed Representations of Words and Phrases and their Compositionality. 
                        <hi rend=""italic"">Advances in Neural Information Processing Systems</hi>, vol. 26. Curran Associates, Inc. https://papers.nips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html (accessed 7 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., et al.</hi> (2011). Scikit-learn: Machine Learning in Python. 
                        <hi rend=""italic"">The Journal of Machine Learning Research</hi>, 
                        <hi rend=""bold"">12</hi>: 2825–30.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Řehůřek, R.</hi> (2021). 
                        <hi rend=""italic"">Gensim: Topic Modelling for Humans</hi>. https://radimrehurek.com/gensim/models/word2vec.html (accessed 7 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Schelling, F. W. J. von</hi> (1994). 
                        <hi rend=""italic"">Ideen zu einer Philosophie der Natur: (1797)</hi>. (Ed.) Durner, M. (Historisch-Kritische Ausgabe). Stuttgart: Frommann-Holzboog.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Wanning, B.</hi> (2005). 
                        <hi rend=""italic"">Die Fiktionalität der Natur: Studien zum Naturbegriff in Erzähltexten der Romantik und des Realismus</hi>. Berlin: Weidler.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,computational literary studies;german romanticism;nature;t-sne;word2vec,English,18th century;19th century;cultural analytics;cultural studies;english;europe;literary studies;text mining and analysis
11874,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Sound Iconicity and Digital Humanities. A Case Study of Spanish Golden Age Theatre,,Simon Kroll,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>Recently, the relevance of sound for the meaning of words in a language has increasingly gotten scholarly attention. Works on sonic iconicity in different languages all over the world are gaining importance, regarding both the importance of sound in bound language (lyrics), and in daily spoken language. This research has provided serious evidence suggesting that the sound of a word already gives us information about its meaning, or at least, about the overall associations attached to it. In other words, phonemes already seem to carry semantic information (Auracher, 2020). Whereas a number of studies have investigated phonosemantics concerning single phonemes in a general sense, a noticeable research gap exists in the context of poetry or verse drama. Since it became the first modern mass culture, the early modern verse drama appears to constitute an especially crucial corpus for this field of research. </p>
            <p>The short presentation format was chosen to present the ongoing work of my research including first hints on the use of phonosemantic relations in Spanish early modern theatre (16
                <hi rend=""superscript"">th</hi> and 17
                <hi rend=""superscript"">th</hi> century). As a basis for researching such relations, in a first step, we created a corpus from the existing digital text repositories, collecting over 500 plays by different playwrights such as Pedro Calderón de la Barca, Lope de Vega, Tirso de Molina, Sor Juana Inés de la Cruz, Mira de Amescua, and many others. The second step included the development of a Python script, enabling the analysis of the phonic structure of every single verse line. The program identifies the number of syllables, the rhythmical patterns, the rhymes, identifies between stressed and unstressed vowels, and creates a csv-file to collect all the created data. As a first result, a phonologic transcriptor and a syllabic analysis tool have already been published as Python libraries (see Sanz Lázaro, 
                <hi rend=""italic"">fonemas</hi> and 
                <hi rend=""italic"">silabeador</hi>). These scripts will be presented briefly, taking into account the existing research on automatic verse analysis in Spanish (González-Blanco, Remón, de la Rosa).
            </p>
            <p>In order to analyze these phonetic data on a large scale, a number of shorter Python scripts were developed. Using the libraries pandas and matplotlib, the goal of research is to answer the following questions: Do the different playwrights have preferences for different rhythmical patterns? Do these rhythmical patterns appear randomly throughout the texts? Or is it possible to establish a pattern between negative and positive emotions and the occurrence of certain rhythmical structures? To what extent are rhythmical patterns related to other phonosemantic phenomena? Is there an interrelation between rhyming structures and different rhythms or a connection between the stressed vowels and the rhythmical patterns?</p>
            <p>As it aims to evoke very strong emotions in its spectators, the early modern theatre is often referred to as an affect machinery. This aspect of Spanish Golden Age theatre is usually reduced to visual aspects: the use of baroque theatre machinery, special effects, and the overwhelming costumes of the professional actors.</p>
            <p>In contrast, this research shows, that an important medium to achieve this goal can be found in the sound of the verses themselves. Therefore, this presentation has a threefold aim:</p>
            <list rend=""bulleted"">
                <item>to present the new Python scripts and libraries created for the automatic verse analysis;</item>
                <item>to discuss phonosemantic relations and the digital methods to analyze them;</item>
                <item>to provide new insights into the importance of sound effects in the affect machinery of the early modern theatre.</item>
            </list>
            <p>Thus, the presentation will show important advances in the automatic analysis of metrical texts, which can easily be transferred to texts from other epochs and, with slight adaptations, also to other romance languages like Italian.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Auracher, J., Menninghaus, W. and Scharinger, M. </hi>(2020). Sound Predicts Meaning: Cross-Modal Associations Between Formant Frequency and Emotional Tone in Stanzas. 
                        <hi rend=""italic"">Cognitive Science</hi>, 
                        <hi rend=""bold"">44</hi>:10: e12906. 
                        <ref target=""https://doi.org/10.1111/cogs.12906"">https://doi.org/10.1111/cogs.12906</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Bird, S., Klein, E. and Loper, E.</hi> (2009). 
                        <hi rend=""italic"">Natural Language Processing with Python</hi>. Sebastopol, CA: O’Really.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">De la Rosa, J., Pérez, Á., Hernández, L., Ros, S. and González-Blanco, E</hi>. (2020). Rantanplan, fast and accurate syllabification and scansion of spanish poetry. 
                        <hi rend=""italic"">Procesamiento del Lenguaje Natural</hi>
                        <hi rend=""bold"">65</hi>, 83-90.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Eder, M., Rybicki, J. and Kestemont, M. </hi>(2016). Stylometry with R: A Package for Computational Text Analysis. 
                        <hi rend=""italic"">The R Journal</hi>
                        <hi rend=""bold"">8,1</hi>: 107–21.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">González-Blanco, E. Pérez, Á., Ros, S</hi>. 
                        <hi rend=""italic"">PoetryLab​. An Open Source Toolkit for the Analysis of Spanish Poetry Corpora.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Karsdorp, F., Kestemont, M. and Riddell, A. </hi>(2021). 
                        <hi rend=""italic"">Humanities Data Analysis: Case Studies with Python</hi>. Princeton, Oxford: Princeton University Press. 
                        <ref target=""https://press.princeton.edu/books/hardcover/9780691172361/humanities-data-analysis"">
                            <hi rend=""underline color(0000FF)"">https://press.princeton.edu/books/hardcover/9780691172361/humanities-data-analysis</hi>
                        </ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Manning, C., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S. and McClosky, D.</hi> (2014). The Stanford CoreNLP Natural Language Processing Toolkit. In 
                        <hi rend=""italic"">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</hi>, 55–60. Baltimore, Maryland: Association for Computational Linguistics. 
                        <ref target=""https://doi.org/10.3115/v1/P14-5010"">https://doi.org/10.3115/v1/P14-5010</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Marco, G. De La Rosa, J., Gonzalo, J. Ros, S., González-Blanco, E</hi>. (2021). Automated Metric Analysis of Spanish Poetry: Two Complementary Approaches. 
                        <hi rend=""italic"">IEEE Access</hi>
                        <hi rend=""bold"">9</hi>, 51734-51746.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">McKinney, W</hi>. 
                        <hi rend=""italic"">Python for Data Analysis</hi>, Sebastopol, CA: O’Really.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Plecháč, P.</hi> (2018). Versification and authorship attribution. A pilot study on Czech, German, Spanish and English poetry. 
                        <hi rend=""italic"">Studia Metrica et Poetica</hi>, 
                        <hi rend=""bold"">5, 2</hi>: 30-54.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Remón, GM., Gonzalo, J.</hi> (2021). Escansión automática de poesía española sin silabación. 
                        <hi rend=""italic"">Procesamiento del Lenguaje Natural</hi>
                        <hi rend=""bold"">66</hi>: 77-87.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Sanz Lázaro, F.</hi> (2021). 
                        <hi rend=""italic"">Fonemas. A Python phonologic transcription library for Spanish</hi>. Version 1.0.3. fsanzl, Okt. 2021. Software. 
                        <hi rend=""italic"">GitHub</hi>, 
                        <ref target=""https://github.com/fsanzl/fonemas"">https://github.com/fsanzl/fonemas</ref>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Sanz Lázaro, F.</hi> (2021). 
                        <hi rend=""italic"">Silabeador: A Python library for syllabic division and stress detection for Spanish</hi>. Version 1.0.5, fsanzl, Okt. 2021. Software. 
                        <hi rend=""italic"">GitHub</hi>, 
                        <ref target=""https://github.com/fsanzl/silabeador"">https://github.com/fsanzl/silabeador</ref>
                        <hi rend=""Hyperlink"">.</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,automatic verse analysis;sound iconicity;spanish golden age theatre;verse drama,English,"15th-17th century;attribution studies and stylometric analysis;database creation, management, and analysis;english;europe;humanities computing;literary studies;south america;spanish"
11875,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Literary Text Analysis with Spyral Notebooks, a Notebook Environment Companion to Voyant Tools",,Kaylin Catherine Land;Geoffrey Rockwell;Andrew MacDonald;Bennett Kuwan Tchoc;Elliot Damasah,workshop / tutorial,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">Digital literary text analysis is increasingly becoming an integral part of literary studies. However, many tools designed for performing such analysis remain inaccessible to researchers without significant coding and computing skills. Voyant Tools was designed in part to address this gap. Spyral Notebooks are an extension of Voyant Tools and allow researchers to expand upon their findings from Voyant in a notebook environment. Unlike other notebook environments, Spyral Notebooks are accessible without downloading any programs or advanced set-up. Spyral Notebooks are available in an entirely online format. To use Spyral Notebooks, one needs only a connection to the Internet. The notebooks are easily adaptable, shareable, and editable. </p>
            <p style=""text-align: left; "">Spyral is a notebook development environment that is integrated into Voyant Tools. Notebook environments can be thought of as both extensions of traditional research notebooks and as novel tools that integrate documentation, active analysis and presentation of results. At their core, notebooks are made up of three types of blocks or cells that a user can add or delete in a sequence. </p>
            <list rend=""numbered"">
                <item>There are text cells that can contain headings and other text elements found in word processors or browser editors (usually based in HTML) for typing unstructured text. Depending on the notebook environment, the text blocks can be simple or more sophisticated. Spyral Notebooks use HTML for text and offer an in- browser WYSIWYG HTML editor for the text blocks. </item>
                <item>There are code cells where the user inputs code, be it Python, the Wolfram language used in Mathematica, or JavaScript, which is used in Spyral. The code cells can be run in sequence or individually as you debug your code. Code cells can contain as much or as little code as the user desires. </item>
                <item>There are output cells which produce the output of the code you input in the associated code cell. It is important to recognize that the output of the code is dependent on what you have instructed the computer to do; that is, it is not a printout of the code cell but the results of running your code. You thus have to instruct the computer to print out the desired results. </item>
            </list>
            <p style=""text-align: left; "">In our tutorial we introduce participants to Spyral Notebooks. We illustrate how to create a corpus for textual analysis from Voyant Tools or directly in Spyral Notebooks. After walking through the basic mechanisms for using Spyral Notebooks including saving, editing, and sharing notebooks, we move on to more specific features available in Spyral. Participants will learn how to enhance the capabilities of Voyant and go deeper with their textual analysis using Spyral. Finally we provide participants with several tutorial notebooks designed to highlight some of Spyral’s advanced features such as categories for use in sentiment analysis. </p>
            <p style=""text-align: left; "">Spyral Notebooks are a welcome addition to the field of digital humanities as they provide an accessible notebook environment specifically designed for literary text analysis. Spyral Notebooks are thoughtfully designed to serve researchers with limited coding skills who want to take their analysis from Voyant one step further. We especially envisage Spyral proving useful for digital humanities instructors. Spyral provides a useful platform for student work, allowing students to embed their analysis from Voyant, perform more complex analysis using JavaScript, and annotate their code with their thought processes.</p>
        </body>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,javascript;literary text analysis;notebook environments,English,"contemporary;education/ pedagogy;english;global;interface design, development, and analysis;literary studies;text mining and analysis"
11880,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Minor Labels: Detecting Genre in Pitchfork Reviews, a ""Metamodularity"" Network Analysis",,J.D. Porter;Stewart Varner,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>
                <hi rend=""italic"" xml:space=""preserve"">Pitchfork.com </hi>has published music reviews, news, interviews, feature stories since 1995. Growing out of 1990s zine culture, 
                <hi rend=""italic"" xml:space=""preserve"">Pitchfork </hi>took advantage of the affordances of the internet early and has since become the self-proclaimed “most trusted voice in music.” In that time, they have reviewed over 23,000 albums by more than 10,000 artists. When it began, 
                <hi rend=""italic"" xml:space=""preserve"">Pitchfork </hi>was known for its attention to alternative/punk/indie rock and, though it has increased its coverage of hip-hop, pop, and more mainstream music over the years, it remains a source of information about unconventional and emerging artists across genres.
            </p>
            <p>Though they often cite an extraordinary number of genres, sub-genres, and sub-sub-genres in their reporting, they stick to a very conservative list of nine official genre tags for most of their reviews.</p>
            <figure>
                <graphic n=""1001"" width=""16.51cm"" height=""6.773333333333333cm"" url=""Pictures/01f557090c6310b474de745fb5046532.jpg"" rend=""inline""/>
            </figure>
            <p>
                <hi style=""font-size:9pt"" xml:space=""preserve"">Figure 1: Reviews by genre in </hi>
                <hi rend=""italic"" style=""font-size:9pt"">Pitchfork</hi>
                . Note that one review may have several genres, each of which would be counted in this graph. The “Null” category describes a small subset of reviews that had no genre tags.
            </p>
            <p>Debates over the function of genre are common in music as well as literature, film, and culture studies generally (Sanneh, 2021; Lena, 2012; Brackett, 2016). For an outlet like 
                <hi rend=""italic"">Pitchfork</hi>, they function, at least in part, to set expectations for readers. Yet, given the scale and the breadth of the types of music covered by 
                <hi rend=""italic"">Pitchfork</hi>, these nine highly unevenly distributed tags are somewhat uninformative. While the genre tags alone may do little to set expectations, the reviews themselves do this work in at least one highly characteristic way: by comparing the artist under review to other artists who share similar qualities. Fortunately for us, 
                <hi rend=""italic"" xml:space=""preserve"">Pitchfork </hi>does this in an easily minable fashion by maintaining individual pages for several thousand artists, and then using links to these pages when the artists are mentioned in reviews.
            </p>
            <figure>
                <graphic n=""1002"" width=""9.68375cm"" height=""5.08cm"" url=""Pictures/ec23ab4689cc9056a4b7dbe1eb835d7b.jpg"" rend=""inline""/>
            </figure>
            <p>Figure 2</p>
            <p>Figure 2 is a screenshot from a review. Clicking on “The Meters” or “Dr. John”, indicated by red underlining, will take you to the individual pages for each respective artist. We scraped all of the reviews and relevant metadata, including the artist links. With that data set, we created networks of artists where edges are drawn between any artists who have links in the same review.</p>
            <figure>
                <graphic n=""1003"" width=""11.1125cm"" height=""11.1125cm"" url=""Pictures/ea0773e0641dcd6aefe65754242d39fa.jpg"" rend=""inline""/>
            </figure>
            <p>
                Figure 3. Nodes are artists; edges reflect co-presence in reviews. Node size shows edge count. Color shows detected community.
            </p>
            <p>Tools like Gephi can depict sub-groups in a network like the one we created via community detection (calculated in Gephi using the Louvain method (Blondel et al, 2008)). However, there are important limitations to this method. Because it is non-deterministic, the precise membership of each group, and even the total number of groups, can vary each time the algorithm is run. To work around this, we introduce a method we call “metamodularity”. We simply ran Louvain community detection on the artist network 10,000 times.
                <note place=""foot"" xml:id=""ftn1"" n=""1"">
                    <p rend=""footnote text""> We used the NetworkX and Community libraries in Python. Some artists had no links, because they were never mentioned in an article with anyone else. To avoid very small communities and improve the legibility of results, we also filtered out 34 artists not connected to the main network. This left us with 7,524 unique artists.</p>
                </note> Though there are many other possibilities that would achieve similar ends, including examining the communities detected during the “passes” from which the Louvain method constructs its final groups, our approach has several key advantages: It is simple to run, easy to understand, and eschews a non-deterministic approximation in favor of data about the probability of particular groupings.
            </p>
            <p>Using this method, we can show how often any two artists were sorted into the same group. For instance, the jazz musician Alice Coltrane was grouped with John Coltrane 10,000 times, with Sly and the Family Stone 4,939 times, and with Guns n’ Roses one time. This gives us a more reliable and comprehensible picture of the level of connection between the artists.</p>
            <figure>
                <graphic n=""1004"" width=""16.50647222222222cm"" height=""7.309555555555556cm"" url=""Pictures/fc91520b52bc3b7e5c0b00afc4a54ab7.png"" rend=""inline""/>
            </figure>
            <p>
                Figure 4: Showing the top artists (sorted by number of total connections with other artists) who group with Bon Iver at increasing thresholds of connectedness
            </p>
            <p>Using the results from this method, we examined every group of at least 25 artists at six different thresholds and renamed the groups to reflect our assessment of the underlying artistic community. For instance, we called the rightmost group in Figure 4 “00’s Indie Rock”.</p>
            <p>It is worth underscoring that our group names are subjective. Nonetheless, they help to show the relationship between groups at different tiers. The Sankey diagram, Figure 5, makes clear the branching of closely-knit artist communities from larger, more loosely connected groups.</p>
            <figure>
                <graphic n=""1005"" width=""16.50647222222222cm"" height=""9.90423611111111cm"" url=""Pictures/865d67c1734babf0b3bf8fe444f2ad2d.png"" rend=""inline""/>
            </figure>
            <p>Figure 5</p>
            <p>The richness of these results points to many interesting findings about the operation of genre in 
                <hi rend=""italic"">Pitchfork</hi>; we will mention just one here. Some of the genres suggested by Figure 5 are incredibly specific—e.g., our names for groupings of metal artists include classic, goth, punk, grüv, and crossover. One notable exception is a group of predominately African American musicians, which is remarkably large and stable up until the 9,000 threshold. The artists within it range from instrumental hip hop composer Flying Lotus to Motown legend Marvin Gaye to trap rapper Young Thug to R&B singer-songwriter Sade to funk innovators Funkadelic to crossover hip hop star Cardi B. This is a far more capacious group along aesthetic, market, and even historic grounds than we see in, e.g., the heavy metal clusters at the same metamodularity threshold. This may reflect real-world connections, since many artists in this group have worked together in various ways, perhaps more often than metal bands have. Or this may reflect a structural difference in the way that writers at 
                <hi rend=""italic"">Pitchfork</hi> have covered Black artists relative to their reviews of white musicians, particularly in the early years of the publication. In any case, it is a noteworthy difference in the shape of genre in this corpus.
            </p>
            <p>This finding will be one of three concluding points in the talk. We will also discuss how, in this dataset, metamodularity based solely on artists’ connections seems to demonstrate Carolyn Miller’s description of genre as “social action” rather than some kind of top-down, taxonomic structure (Miller, 1984). We will also reflect on the potential use of metamodularity as a more broadly useful method for understanding (and depicting) network structures.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi style=""font-size:12pt"" xml:space=""preserve"">Blondel, V., Guillaume, J., Lambiotte, R. and Lefebvre, E. (2008). Fast Unfolding of Communities in Large Networks. </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Journal of Statistical Mechanics: Theory and Experiment</hi>
                        . 2008: 10. 9.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        Brackett, D. (2016).
                        <hi rend=""italic"" style=""font-size:12pt"">Categorizing Sound: Genre and 20th Century Popular Music</hi>
                        . Oakland: University of California Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        Lena, J. (2012).
                        <hi rend=""italic"" style=""font-size:12pt"">Banding Together: How Communities Create Genres in Popular Music</hi>
                        . Princeton: Princeton University Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi style=""font-size:12pt"" xml:space=""preserve"">Miller, C. (1984). Genre as Social Action. </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Quarterly Journal of Speech</hi>
                        . Vol 70, 2; 151-76.
                    </bibl>
                    <bibl rend=""footnote description"">
                        <hi style=""font-size:12pt"" xml:space=""preserve"">Sanneh, K. (2021). </hi>
                        <hi rend=""italic"" style=""font-size:12pt"">Major Labels: A History of Popular Music in Seven Genres</hi>
                        . New York: Penguin Press.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,data visualization;genre;modularity class;networks;popular music,English,contemporary;cultural analytics;cultural studies;english;media studies;network analysis and graphs theory and application;north america
11888,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,An International Perspective on Creating an Army of Hacker-Scholars,,Emily Sofi Öhman,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>
                With the increased demand in industry for people with programming skills and the visibility of Digital Humanities in academia, there has been a rise in humanities and other non-computer science students looking to learn programming (Hughes, 2020). However, programming course availability and quality at humanities departments vary greatly (see e.g Abrahams, 2010; Lyon & Magana, 2020) and students risk losing motivation if they cannot see the connection to their own studies with numerical rather than textual content and practical applications (Forte & Guzdial, 2005; Ramsay, 2012; Kokensbarger et al., 2018; Öhman, 2019). 
            </p>
            <p>
                <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">Some research already exists on what makes a programming course successful in terms of high pass rates (see e.g. Nikula et al., 2011), however, in this paper we focus on examining what practices convince students themselves that a course was useful as a measure of success. In order to examine this aspect and to try to create a few guidelines for successful Python courses specifically for students of humanities-related subjects, we examined student course feedback from three courses: an undergraduate course </hi>
                <hi rend=""italic"" style=""font-family:Source Sans Pro"">Python Programming for Digital Humanities</hi>
                <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">(~150 students, early 20s, online) at Waseda University, Japan and the </hi>
                <hi rend=""italic"" style=""font-family:Source Sans Pro"">NLP for Linguists</hi>
                <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> and </hi>
                <hi rend=""italic"" style=""font-family:Source Sans Pro"">Working with Text</hi>
                <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> courses, partially based on the </hi>
                <hi rend=""italic"" style=""font-family:Source Sans Pro"">Applied Language Technology</hi>
                <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> online tutorials (Hiippala, 2021), at the University of Helsinki, Finland (~30 students each, early to late 20s, hybrid style) that are open both for undergraduate and graduate students. The main contents of these courses are fairly similar and so are both the complaints and praise. We compare difficulties students face, explore what keeps them motivated, and analyze their feedback holistically while looking for common denominators of what works: </hi>
            </p>
            <p>
                <hi rend=""italic"" style=""font-family:Source Sans Pro"">“These courses have been the high point of the spring semester, and all of the exercises have been motivating and satisfying to complete.”</hi>
                  (Student. Finland)
            </p>
            <p>
                As is common with humanities-focused programming courses there is a significant skill gap between students (see e.g. Öhman, 2019) and this too shows in the evaluations. In 2022 the question “What was the level of this week’s content?” was asked of students after their first week of the “Python Programming for Digital Humanities” course. With 107 respondents, the distribution of responses shows normal distribution with most students (69%) feeling that the level was just right, and the rest almost evenly split between “I struggled a bit” and “Too easy” (Table 1).
            </p>
            <figure>
                <graphic n=""1001"" width=""14.110338888888888cm"" height=""8.089491666666667cm"" url=""Pictures/d4fc085bd208be9b0bd88851bb47e03b.png"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">
                Table 1. Results of poll regarding content difficulty
            </p>
            <p>
                In the Finnish data, the question “Was the level of the course appropriate?” the answers have the greatest spread as well, suggesting that ideally perhaps students should either be placed in different groups based on initial skill level or that some students could really benefit from a pre-introduction course or extra tutoring where they could gain confidence in the most basic of programming concepts. This is especially true in the light that there does not seem to be a correlation between struggling students and below average final grades as long as the students do not drop out. A correlation matrix of evaluation questions and results (Figure 1.) show that there are high correlations between how students experience the speed of the course and the workload and the level of the course. If one of these parameters are adjusted it will likely affect the others, e.g., if the speed that new topics are introduced is slowed down, the workload will feel more manageable and the contents easier to digest.
            </p>
            <p>
                <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">We also recommend that programming courses such as these are best balanced by using scaffolding methods to keep students in the zone of proximal development (Chaiklin et al, 2003; Vygotsky, 1987). In practice this means telling the students the outline of what they are going to learn first to enable independent learning at the students’ own pace later and not making the contents too easy, but also providing students with the tools to do their own trouble-shooting and advanced learning by introducing StackOverflow and other such tools early on. Additionally, the content should be humanities focused and practical. This could mean introducing the NLTK library (Bird & Loper, 2004) right after teaching the basics (data types & loops) as a way to demonstrate usefulness. </hi>
            </p>
            <p>Overall, student satisfaction ratings are very high for both courses as are enrollment numbers. Ramsay (2012) referred to teaching humanities students programming as raising an army of hacker-scholars, and it certainly seems that the interest is there from the student side once they get past the initial hurdle of enrolling in the course.</p>
            <figure>
                <graphic n=""1002"" width=""16.002cm"" height=""13.387916666666667cm"" url=""Pictures/814059a297135ca189aecabd107ddeb5.png"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">Figure 1. Correlation matrix of feedback responses</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Abrahams,  D.  A.</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">(2010).  Technology adoption in higher education:  A  framework for identifying and prioritizing issues and barriers to the adoption of instructional technology. </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">Journal of Applied Research in Higher Education</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> 2, 2, 34–49.</hi>
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Bird, S. G., & Loper, E.</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> (2004). </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">NLTK: the natural language toolkit</hi>
                        . Association for Computational Linguistics.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Chaiklin, S.</hi>
                        (2003). The zone of proximal development in Vygotsky’s analysis of learning and instruction. Vygotsky’s educational theory in cultural context 1,  39–64.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Forte, A., and Guzdial, M. (</hi>
                        2005). Motivation and nonmajors in computer science: Identifying discrete audiences for introductory courses.
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"" xml:space=""preserve""> IEEE Transactions on Education</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> 48:2, 248–253.</hi>
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Hiippala, T. (</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">2021). Applied Language Technology: NLP for the Humanities. </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">In Proceedings of the Fifth Workshop on Teaching NLP</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> (pp. 46-48).</hi>
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Hughes, O</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">. (2020). </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">Developer training sees spike in demand as more people learn to cod</hi>
                        e. TechRepublic. Retrieved November 29, 2021, from https://www.techrepublic.com/article/the-economic-outlook-is-uncertain-so-more-people-want-to-become-developers/ 
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Kokensparger,  B., and Peyou,  W.</hi>
                        (2018). Programming for the humanities: A whirlwind tour of assignments.  In
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"" xml:space=""preserve""> Proceedings of the 49th ACM Technical Symposium on Computer Science Education,</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> SIGCSE’18, ACM, pp. 1050–1050.</hi>
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Lyon, J.A., and J. Magana, A</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">. (2020). </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">Computational thinking in higher education: A review of the literature</hi>
                        . Computer Applications in Engineering Education.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Öhman, E.S</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">. (2019). Teaching Computational Methods to Humanities Students. In </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">Digital Humanities in the Nordic Countries Proceedings of the Digital Humanities in the Nordic Countries 4th Conference</hi>
                        . CEUR-WS.org.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Nikula, U., Gotel, O. and Kasurinen, J. (</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">2011). A motivation guided holistic rehabilitation of the first programming course. </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">ACM Transactions on Computing Education</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> (TOCE), 11(4), pp.1-38.</hi>
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Ramsay,  S</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">. (2012).  Programming with humanists:  Reflections on raising an army of hacker-scholars in the digital humanities. </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">Digital Humanities Pedagogy:  Practices, Principles, and Politics</hi>
                        , 217–41.
                    </bibl>
                    <bibl style=""text-align: left;"">
                        <hi rend=""bold"" style=""font-family:Source Sans Pro"">Vygotsky, L.</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve"">(1987). Zone of proximal development. </hi>
                        <hi rend=""italic"" style=""font-family:Source Sans Pro"">Mind in society: The development of higher psychological processes</hi>
                        <hi style=""font-family:Source Sans Pro"" xml:space=""preserve""> 5291, 157.</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,computational methods;curriculum development;higher education;programming;python,English,asia;comparative (2 or more geographical areas);computer science;contemporary;curricular and pedagogical development and analysis;education/ pedagogy;english;europe
11901,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Introduction to DraCor – Programmable Corpora for Digital Drama Analysis,,Ingo Boerner;Frank Fischer;Carsten Milling;Peer Trilcke;Henny Sluyter-Gäthje,workshop / tutorial,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Aim of the workshop</head>
                <p>In the half-day workshop, DraCor (https://dracor.org), an open platform for researching plays in different languages, will be introduced using practical examples from digital drama analysis. At the center of DraCor are so-called 'Programmable Corpora'. By this we mean infrastructurally research-oriented, open, extensible, Linked-Open-Data-friendly full-text corpora, which should make it possible to address diverse research questions from the field of digital literary studies in a low-threshold way using corpora in a data-based, traceable, and reproducible way (Fischer et al. 2019).</p>
                <p>The workshop aims at people who</p>
                <p>- work or would like to work with literary texts and in particular with dramas and would like to create their own corpora for this purpose or reuse already existing corpora;</p>
                <p>- want to learn methods of digital drama analysis (network analysis, stylometry) or want to try them out on the basis of the Programmable Corpora approach;</p>
                <p>- are interested in the possibilities of researching literary texts using Linked Open Data (LOD).</p>
                <p>There will be a presentation of the concept of 'Programmable Corpora' as well as a demonstration of the exemplary implementation in the DraCor platform including a presentation of all components. Hands-on tutorials will give participants a practical introduction to creating and curating their own drama corpora for analysis with DraCor. Another part introduces the use of the DraCor API as well as the Python library PyDraCor by means of practical examples on the methods stylometry and network analysis. The Application Programming Interface (API) allows customized direct access to specific parts of the corpora. The possibilities for cross-corpus queries and inclusion of information from the Linked Open Data cloud using SPARQL will also be explored.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>The Concept of Programmable Corpora</head>
                <p>The core of DraCor consists of corpora of dramas in eleven languages (German, Russian, French, English, Italian, Swedish, Spanish, Ancient Greek, Alsatian, Latin, Bashkir and Tatar) as well as two additional author corpora (Shakespeare, Calderón), to which the platform offers a variety of possible research accesses: The dramas are encoded as XML files according to the TEI guidelines and are freely available under an open license via GitHub at https://github.com/dracor-org. They can be loaded from there, transformed or enriched by oneself if necessary, and reused for further research with any tools. </p>
                <p>In addition to this ""classical"" modus operandi of corpus-based research, however, DraCor as an open digital ecosystem offers further interfaces and connected tools (network visualizations, Shiny App, Easy Linavis). Fundamental to this is the DraCor REST API (https://dracor.org/doc/api), which provides functions for retrieving data in different formats (TEI, JSON, plaintext, RDF, GEXF, GraphML) as well as some built-in analysis functionalities (e.g. on network metrics). The API can be used to retrieve not only structural and metadata, but also the full texts without further markup, so that methods such as stylometric analysis or topic modeling can be applied without any further intermediate step to remove markup. The DraCor API is documented in the OpenAPI standard and can be used in an interactive documentation implemented using Swagger UI (https://dracor.org/documentation/api) directly from the web browser. </p>
                <p>API libraries are available for the Python (PyDraCor: https://github.com/dracor-org/pydracor) and R (rdracor: https://github.com/dracor-org/rdracor) programming languages, which allow the API functionalities to be integrated quickly and adapted to the respective programming language. For complex queries, a SPARQL endpoint (https://dracor.org/sparql) is available on the platform. This allows both cross-corpus and combined queries (federated queries), in which DraCor can be queried simultaneously with other resources available as LOD, such as Wikidata.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Digital Drama Analysis with DraCor</head>
                <p>Corpus-based analyses of drama, usually using quantitative methods, have emerged as a distinct subfield of Computational Literary Studies (CLS) in recent years (cf. Willand et al. 2017; Reiter 2021). In this context, the provision of jointly curated and open resources such as DraCor has proven productive also for related disciplines such as computational linguistics (cf. for example Pagel, Reiter 2020).</p>
                <p>Methods operating at the word level have focused, for example, on authorship attribution (Schöch 2014) or genre classification with topic modeling (Schöch 2017). Currently, promising reconceptualizations of stylometric measures such as the measure Zeta are being developed and applied (Schöch 2018). Furthermore, on the basis of structurally annotated corpora, targeted analyses of, for example of stage directions can be performed, operating with POS information or semantic fields (Trilcke et al. 2020). </p>
                <p>In the field of structural analysis, drama corpora were studied early on using network analytic approaches, beginning with the work of Stiller, Nettle, Dunbar (2003) and continuing, for example, with Moretti (2011). Typological work on, for example, the concept of Small Worlds (Trilcke et al. 2016) stands here alongside approaches to the quantitative classification of figure types (Fischer et al. 2018). </p>
                <p>Although semantic technologies are now an integral part of the spectrum of methods in the digital humanities, they have rarely been applied in corpus-based CLS (on prose, for example, Frank and Ivanovic 2018; Dittrich 2017). However, the collection of metadata as Linked Data and the connection to external reference resources, especially Wikidata, allow for far-reaching query possibilities and can be profitably used for the analysis of literary corpora. For example, the DraCor corpus data does not contain detailed information on authors and performance locations. However, since the unique Wikidata identifiers are stored for the individual pieces, this information can be retrieved via federated queries in SPARQL and displayed in various visualization forms, such as a map.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Learning objectives and timeline of the workshop</head>
                <p>In the first part of the workshop the concept of 'Programmable Corpora' will be introduced and discussed. Afterwards, the platform DraCor and its components will be introduced, with short practical phases during which the participants can directly try out the presented components and tools. In particular, the different possibilities for the reference and analysis of corpus data will be tested. One focus will be on the use of the API. The API functionalities will be explained with the help of interactive documentation and can be tested extensively by the participants. This will be followed by a short overview of corpus creation and the specifics of TEI encoding as used in DraCor.</p>
                <p>The second part of the workshop will consist of work phases in which three topics can be explored in more depth:</p>
                <p>(1) corpus creation and curation with DraCor: Participants will delve into TEI coding of dramas through hands-on exercises and learn how to set up a local instance of the platform using Docker, customize it if necessary, and populate it with their own corpora.</p>
                <p>(2) Drama analysis with DraCor API and Python: Using Jupyter notebooks with extensively documented Python code, participants will be introduced to methods of digital drama analysis using the DraCor API. The notebooks should also enable participants who have no previous experience in programming with Python to follow the individual analysis steps and to adapt them themselves in the sense of a literate programming approach. The notebooks implement concrete research questions on drama analysis, for example on the literary-historical development of network-analytical measures or on the quantitative dominance of characters.</p>
                <p>(3) Drama Analysis with Linked Data: The focus will be on practical analyses made possible from connecting DraCor to the Linked Open Data Cloud. The workshop will provide a brief crash course in the SPARQL query language, followed by joint queries of DraCor and Wikidata and visualization of the results.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Organizational matters</head>
                <p>Number of possible participants: 25</p>
                <p>The Workshop will be held via Zoom. Software to be installed on local machines (Oxygen XML editor, Docker, ...) will be announced in advance. Materials will be made available on GitHub; Jupyter notebooks will be posted at (https://github.com/dracor-org/dracor-notebooks).</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Contributors / Contact details</head>
                <p>Ingo Börner (ingo.boerner@uni-potsdam.de) works as a research assistant in the project ""CLSInfra"" at the University of Potsdam on the further development of DraCor. His work focuses on data modeling and Linked Open Data.</p>
                <p>Frank Fischer (fr.fischer@fu-berlin.de) is Professor at the Freie Universität Berlin. His involvement with digital drama analysis goes back to the Digital Literary Network Analysis DLINA project (https://dlina.github.io), from which DraCor emerged.</p>
                <p>Peer Trilcke (trilcke@uni-potsdam.de) is Professor of modern German literature at the University of Potsdam. His work focuses on the research-based development of infrastructures for literary corpora and the quantitative analysis of literary texts.</p>
                <p>Carsten Milling (cmil@hashtable.de) is a web developer and is responsible for the development of the DraCor platform in the project ""CLSInfra"" at the University of Potsdam. </p>
                <p>Henny Sluyter-Gäthje (sluytergaeth@uni-potsdam.de) is a research assistant at the Chair of 19th Century German Literature at the University of Potsdam. She holds a Master of Science in Cognitive Systems with a focus on computational linguistics and works on algorithmic processing of literary texts.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Funding</head>
                <p>DraCor is currently being further developed within the EU Horizon 2020 funded project ""CLSInfra"" (grant number: 101004984, https://cordis.europa.eu/project/id/101004984).</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Dittrich, Andreas</hi> (2017): ""Intra-Connecting an Exemplary Literary Corpus with Semantic Web Technologies for Exploratory Literary Studies"" in: Bański, Piotr et al. (Hg.): 
                        <hi rend=""italic"">Proceedings of the Workshop on Challenges in the Management of Large Corpora and Big Data and Natural Language Processing (CMLC-5+BigNLP)</hi> 2017. Mannheim: Institut für Deutsche Sprache. https://nbn-resolving.org/urn:nbn:de:bsz:mh39-62441.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fischer, Frank / Trilcke, Peer / Kittel, Christopher / Milling, Carsten / Skorinkin, Daniil</hi> (2018): ""To catch a protagonist: Quantitative dominance relations in german-language drama (1730–1930)"" in: 
                        <hi rend=""italic"">Digital Humanities 2018. Conference Abstracts.</hi> Mexico City: El Colegio de México / Universidad Nacional Autónoma de México / Red de Humanidades Digitales 193–201. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fischer, Frank / Börner, Ingo / Göbel, Mathias / Hechtl, Angelika / Kittel, Christopher / Milling, Carsten / Trilcke, Peer</hi> (2019): ""Programmable Corpora: Die digitale Literaturwissenschaft zwischen Forschung und Infrastruktur am Beispiel von DraCor "" in: 
                        <hi rend=""italic"">DHd2019: »Digital Humanities: multimedial & multimodal«. Book of Abstracts.</hi> Mainz/Frankfurt a. M.: Johannes Gutenberg Universität Mainz / Goethe Universität Frankfurt, 194–197.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Frank, Andrew / Ivanovic, Christine</hi> (2018): ""Building Literary Corpora for Computational Literary Analysis – A Prototype to Bridge the Gap between CL and DH"" in: Calzolari, Nicoletta et al. (Hg.): 
                        <hi rend=""italic"">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</hi>. Miyazaki, Japan: European Language Resources Association.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Moretti, Franco</hi> (2011): ""Network Theory, Plot Analysis "" in: 
                        <hi rend=""italic"">Stanford Literary Lab Pamphlets</hi> 2. http://litlab.stanford.edu/LiteraryLabPamphlet2.pdf [letzter Zugriff 13.7.2021].
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Pagel, Janis / Reiter, Nils</hi> (2020): ""GerDraCor-Coref: A Coreference Corpus for Dramatic Texts in German"" in: 
                        <hi rend=""italic"">Proceedings of the Language Resources and Evaluation Conference (LREC)</hi>. Marseille 55-64 http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.7.pdf [Letzter Zugriff: 15.7.2021].
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Reiter, Nils</hi> (2021): ""Möglichkeiten Quantitativer Dramenanalyse"" in: 
                        <hi rend=""italic"">Comparatio. Zeitschrift für Vergleichende Literaturwissenschaft</hi> 12(2): 39–52.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Schöch, Christof</hi> (2017): ""Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama"" in: 
                        <hi rend=""italic"">Digital Humanities Quarterly</hi> 11, Nr. 2 http://www.digitalhumanities.org/dhq/vol/11/2/000291/000291.html [Letzter Zugriff: 15.7.2021].
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Schöch, Christof</hi> (2018): ""Zeta für die kontrastive Analyse literarischer Texte. Theorie, Implementierung, Fallstudie"" in: Bernhart, Toni et al. (Hg): 
                        <hi rend=""italic"">Quantitative Ansätze in den Literatur- und Geisteswissenschaften. Systematische und historische Perspektiven</hi>. Berlin: de Gruyter 77–94 doi:10.1515/9783110523300-004.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Schöch, Christof</hi> (2014): ""Corneille, Molière et les autres. Stilometrische Analysen zu Autorschaft und Gattungszugehörigkeit im französischen Theater der Klassik"" in: Schneider, Lars / Schöch, Christof (Hg.): 
                        <hi rend=""italic"">Literaturwissenschaft im digitalen Medienwandel. Beihefte zu Phin</hi> 7 http://web.fu-berlin.de/phin/beiheft7/b7t08.pdf [Letzter Zugriff: 15.07.2021].
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Stiller, James / Nettle, Daniel / Dunbar, Robin I. M</hi>. (2003): ""The Small World of Shakespeare's Plays"" in: 
                        <hi rend=""italic"">Human Nature</hi> 14: 397–408.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Trilcke, Peer / Fischer, Frank / Göbel, Mathias / Kampkaspar, Dario / Kittel, Christopher</hi> (2016): ""Theatre Plays as ›Small Worlds‹? Network Data on the History and Typology of German Drama, 1730-1930"" in: 
                        <hi rend=""italic"">Digital Humanities 2016. Conference Abstracts.</hi> Jagiellonian University & Pedagogical University, Kraków 385-387 https://dh2016.adho.org/abstracts/static/dh2016_abstracts.pdf [Letzter Zugriff: 15.07.2021].
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Trilcke, Peer / Kittel, Christopher / Reiter, Nils / Maximova, Daria / Fischer, Frank</hi> (2020): ""Opening the Stage. A Quantitative Look at Stage Directions in German Drama"" in: 
                        <hi rend=""italic"">Digital Humanities 2020. Conference Abstracts</hi>. Ottawa: University of Ottawa https://dh2020.adho.org/wp-content/uploads/2020/07/337_Opening​the​Stage​A​Quantitative​Look​at​Stage​Directions​in​German​Drama​.html [Letzter Zugriff: 15.07.2021].
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Willand, Marcus / Trilcke, Peer / Schöch, Christof / Rißler-Pipka, Nanette / Reiter, Nils / Fischer, Frank</hi> (2017): ""Aktuelle Herausforderungen der Digitalen Dramenanalyse"" in: 
                        <hi rend=""italic"">DHd 2017. Digitale Nachhaltigkeit. Konferenzabstracts</hi>. Bern: Universität Bern 175–180 doi:10.5281/zenodo.3684825.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,api;computational literary studies;drama;linked open data,English,"18th century;19th century;20th century;english;europe;literary studies;network analysis and graphs theory and application;sustainable procedures, systems, and methods"
11904,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Building infrastructure for annotating medieval, classical and pre-orthographic languages: the Pyrrha ecosystem:",,Thibault Clérice;Vincent Jolivet;Julien Pilla,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head/>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p>For the past five years, we have been working on the development of infrastructure to build corpora and machine learning models for lemmatisation and morphosyntactic tagging. Ancient and medieval languages with rich morphology and high spelling variation represent a hanging fruit in the domain of these corpora. However, producing “gold” corpora is a tedious and costly task: even when the automatically produced annotations gain in quality thanks to ever more efficient models and vice versa, a significant amount of manual correction and validation work remains. </p>
                <p>To reduce the cost and guarantee the interoperability of our corpora, we have built an ecosystem: (1) Pyrrha, a post-correction webapp for lemmatisation and morphosyntactic tags, (2) PyrrhaCI, a continuous integration tool for validating corpora, (3) Protogenie for merging and standardizing sometimes heterogeneous corpora, (4) Pie-Extended, a tagger taking into account the difference between real-world data training corpora and (5) Deucalion, a web service for annotation.</p>
                <p>
                    <figure>
                        <graphic url=""Pictures/07d42222aa0b0e650ac3538e74625a50.png""/>
                        <head>Figure 1: Infrastructure developed at the École nationale des chartes</head>
                    </figure>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Producing data</head>
                <p>Pyrrha (Clérice and Pilla, 2021) is designed to accelerate the correction of lemmatisation and morphosyntactic annotation. When we started our work, our team members were using spreadsheets, which have the ability to display all tags and context at the same time. The Pyrrha web application takes up this principle of a tabular interface but adds powerful validation functionalities thanks to checklists (lexicons of lemmas and morphosyntactic tags) guaranteeing the interoperability of the newly produced corpora, as well as batch correction functionalities, inspired by PoCoto (Vobl et al., 2014), a correction interface for OCR. Both of these functionalities are at the core of Pyrrha and have proven to be useful in speeding up the correction of out-of-domain corpora (
                    <hi rend=""italic"">cf.</hi> Figure 2). The application also allows collaboration, both for corpora and checklists, logging of corrections and export to multiple standards such as TEI and TSV.
                </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/cbbbe4f73bb50f4eeddd43dbf215f9bf.png""/>
                        <head>Figure 2: Rolling average of the number of checked tokens per hour. Checking a token includes verifying its correctness and correcting it if necessary. Three waves of correction are visible, the first corpus was completely out-of-domain compared to the lemmatizer (Classical Latin), with the end of the corpus being very different from the rest of the corpus in terms of spelling (letters K and W appeared), themes and syntax. The second and third wave benefits of a new model, retrained on the data produced in wave 1: as a result, there is less corrections and a faster checking rate on waves 2 and 3. Wave 3 is composed of two blocs: one is Thomas More's 
                            <hi rend=""italic"">Utopia</hi> (beginning of W3) and the other the Legenda Aurea which was nearly 100% correct, hence the effectiveness. Each wave / corpus was corrected and proofread on all categories that Pyrrha allows: Lemma, POS and morphological tags.
                        </head>
                    </figure>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Curating Corpora</head>
                <p>While 
                    <hi rend=""italic"">Pyrrha</hi> produces data that should be compliant with standard reference sets, mistake happens. 
                    <hi rend=""italic"">PyrrhaCI </hi>(Clérice et al., 2021) is meant for testing the following attributes of datasets
                </p>
                <list type=""ordered"">
                    <item>respect of reference sets;</item>
                    <item>cross-categorical annotations (
                        <hi rend=""italic"">e.g. </hi>POS(dog)!=Verb);
                    </item>
                    <item>n-gram tagging (
                        <hi rend=""italic"">e.g.</hi> ADJ should not be followed by VERcon).
                    </item>
                </list>
                <p>Each test failure can be manually ignored for further tests, allowing for a more agile interpretation of grammar. PyrrhaCI is meant to be used as a continuous integration tool, through Github Actions or TravisCI, to validate datasets in open repositories and track the issues raised by editions.</p>
                <p>
                    <hi rend=""italic"">Protogenie </hi>(Clérice, 2020b) is focused on preparing datasets for training. It is meant for the following:
                </p>
                <list type=""ordered"">
                    <item>keeping track of and using the same original train/dev/test splits while adding new data in order to have “uniform”' evaluation,</item>
                    <item>allowing for normalization of datasets that come from different projects in different formats,</item>
                    <item>adding transformation to the original dataset (while respecting (1)), such as removing the distinction between U and V in Latin, replacing labels, splitting multi-categorical tags, etc.</item>
                </list>
                <p>While (1) is easily taken care of, it is, in our experience, common to find datasets with different formatting choices or data-based variations such as punctuation, capitalization, morphological tags. Protogenie enables normalization of the “behavior” of different corpora, without having to work with pre-modified files, facilitating easy update of the latter and ensuring the stability of training and performances evaluation.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Producing new data: our lemmatization pipeline</head>
                <p>Our models are trained with 
                    <hi rend=""italic"">Pie (Manjavacas et al., 2019)</hi>
                    <note xml:id=""ftn1"" place=""foot"" n=""1"">We moved to a small fork of Pie, https://github.com/lascivaroma/PaPie, which includes tailored functionalities for our training sets.</note>, a lemmatizer with state-of-the-art results on pre-orthographic and morphologically rich languages and a relatively flexible and stable python API. Once trained, our models are served through 
                    <hi rend=""italic"">Pie-Extended</hi>. Its first function is to bridge the gap between the real-world data and the curated training data by normalizing the first according to the latter
                    <note xml:id=""ftn2"" place=""foot"" n=""2"">
                        <hi rend=""italic"">E.g.</hi> in our Latin dataset shared with us by the LASLA, there was no punctuation. Unknown character can trigger weird behaviors in neural networks system, from our experience, creating issues for both the context of other lemma and its own lemmatization.
                    </note>. It also provides features such as token
                    <note xml:id=""ftn3"" place=""foot"" n=""3"">
                        <hi rend=""italic"">E</hi>
                        <hi rend=""italic"">.g.</hi> metadata token with text identifiers.
                    </note> passthrough (
                    <hi rend=""italic"">cf.</hi> Figure 3).
                </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/2c360bb474c50c2604f4b2b6d15f5444.png""/>
                        <head>Figure 3: Steps for token pass-through in Pie-Extended</head>
                    </figure>
                </p>
                <p>Finally, as not everyone knows how to install and run a python program in a shell, we produced the Deucalion interface (Clérice, 2020a), meant both for documenting (with complete bibliography for each model and software) and tagging. It is a software layer allowing to use Pie-Extended on the web. This Deucalion interface can be used as a stand-alone web application or an API.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Conclusion</head>
                <p>Over the last five years, this infrastructure has allowed us to build a 1+ million token corpus of Old French (Camps et al., 2021), a couple of datasets in both classical and late Latin (Clérice, 2021; Glaise and Clérice, 2021), one for pre-orthographic Early Modern French (Gabay et al., 2020), and others. There are improvements we would still like to make (
                    <hi rend=""italic"">e.g.</hi> the user-friendliness and capacities of PyrrhaCI) and we now have our eyes on 
                    <hi rend=""italic"">data valorization</hi>, through the reuse of tools such as Blacklab (Does, de et al., 2017)
                    <note xml:id=""ftn4"" place=""foot"" n=""4"">A demo for Latin is available at https://blacklab.alpheios.net/latin-texts/search thanks to Alpheios.</note>. Pyrrha has made lemmatization easier for our collaborators and made it a simpler task to produce data and share them across projects. This paper will be an opportunity to present a proven ecosystem, and also to assess its benefits, its costs and shortcomings.
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Camps, J.-B., Clérice, T., Duval, F., Ing, L., Kanaoka, N. and Pinche, A.</hi> (2021). Corpus and Models for Lemmatisation and POS-tagging of Old French.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clérice, T.</hi> (2020a). 
                        <hi rend=""italic"">Flask_pie, a Pie-Extended Wrapper for Flask</hi>. https://github.com/hipster-philology/flask_pie.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clérice, T.</hi> (2020b). 
                        <hi rend=""italic"">Protogenie, Post-Processing for NLP Dataset</hi>. Zenodo doi:10.5281/zenodo.3883585. https://doi.org/10.5281/zenodo.3883585.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clérice, T.</hi> (2021). Lemmatisation et analyse morpho-syntaxique des Priapées. https://github.com/lascivaroma/priapea-lemmatization.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clérice, T., Blotière, É. and Schmied, M.-C.</hi> (2021). 
                        <hi rend=""italic"">PyrrhaCI</hi>. https://github.com/hipster-philology/pyrrhaCI.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clérice, T. and Pilla, J.</hi> (2021). 
                        <hi rend=""italic"">Pyrrha</hi>. doi:10.5281/zenodo.2325427.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Does, J. de, Niestadt, J. and Depuydt, K.</hi> (2017). Creating research environments with blacklab. 
                        <hi rend=""italic"">CLARIN in the Low Countries</hi>: 245–58.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Gabay, S., Clérice, T., Camps, J.-B., Tanguy, J.-B. and Gille-Levenson, M.</hi> (2020). Standardizing linguistic data: method and tools for annotating (pre-orthographic) French. 
                        <hi rend=""italic"">Proceedings of the 2nd International Conference on Digital Tools & Uses Congress</hi>. pp. 1–7.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Glaise, A. and Clérice, T.</hi> (2021). Du IIème siècle à Thomas More, un corpus gold de latin lemmatisé et annoté en morpho-syntaxe. doi:10.5281/zenodo.1234. https://github.com/chartes/latin-non-classical-data.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Manjavacas, E., Kádár, Á. and Kestemont, M.</hi> (2019). Improving Lemmatization of Non-Standard Languages with Joint Learning. 
                        <hi rend=""italic"">ArXiv:1903.06939 [Cs]</hi> http://arxiv.org/abs/1903.06939 (accessed 24 November 2019).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Vobl, T., Gotscharek, A., Reffle, U., Ringlstetter, C. and Schulz, K. U.</hi> (2014). PoCoTo - an Open Source System for Efficient Interactive Postcorrection of OCRed Historical Texts. 
                        <hi rend=""italic"">Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage</hi>. (DATeCH ’14). New York, NY, USA: ACM, pp. 57–61 doi:10.1145/2595188.2595197. http://doi.acm.org/10.1145/2595188.2595197 (accessed 26 November 2018).
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,corpora management;dataset creation;latin;lemmatization;old french,English,"15th-17th century;5th-14th century;bce-4th century;data publishing projects, systems, and methods;english;europe;linguistics;literary studies;natural language processing"
11907,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Mining and Modeling Spaces and Places for Literary History as Linked Open Data,,Julia Röttgermann;Maria Hinzmann;Katharina Dietz;Henning Gebhard;Anne Klee;Johanna Konstanciak;Christof Schöch;Moritz Steffes,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p style=""text-align: left; "">In literary history and historiography, places and spaces play an important role – not least in the context of the ‘spatial turn’ (Lafon, 1997; Piatti et al., 2009; Dennerlein, 2009; Weber, 2014). In literary works, narrative locations are particularly relevant, but places of publication as well as further spatial dimensions can also be taken into account (Curran 2018; Burrows et al. 2016). Our contribution presents how we obtained spatial statements from three different information sources and combined them in a knowledge network based on the Linked Open Data (LOD) paradigm (Berners-Lee, 2006; Hooland und Verbough, 2014; Hitzler, 2021).</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Project context</head>
                <p style=""text-align: left; "">The aim of the project Mining and Modeling Text is to establish an information network for the humanities built from various sources.<note place=""foot"" xml:id=""ftn1"" n=""1"">
                        <p style=""text-align: left; ""> See https://mimotext.uni-trier.de/en/.</p>
                    </note> This aim is closely linked to the finding that, considering the steadily growing digital cultural heritage, the acquisition of knowledge from large amounts of text and data can no longer be handled by individuals. In representing knowledge as LOD, we see untapped potential that we are exploring in the current project phase on the French Enlightenment novel (Delon/Malandain, 1996; Mylne, 1981).
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Creating spatial statements</head>
                <p style=""text-align: left; "">Information on spatial statements relevant to our domain is extracted from three different types of sources: 1. bibliographic metadata, 2. primary sources, 3. scholarly publications. After focusing on thematic statements in an earlier phase of our project (Schöch et. al., 2022; Röttgermann et al., 2022), we are currently addressing spatial statements.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Mining</head>
                <p style=""text-align: left; "">Bibliographic metadata: For our domain, the Bibliographie du genre romanesque français 1751-1800 (BGRF, Mylne et al., 1977) is central, as it defines the population of about 2000 French Enlightenment novels. The BGRF has been extensively analysed and modeled (Lüschow 2020) and contains rich metadata (including places of publication, narrative locations, narrative form, characters, themes, style).</p>
                <p style=""text-align: left; "">Primary sources: The Collection of Eighteenth-Century French Novels (Röttgermann, 2021) is analysed via SpaCy’s (Honnibal und Montani, 2017) named entity recognition and reconciliation pipeline supported by OpenRefine (Huynh, [2012] 2010). Our pipeline requires human intervention (Hinzmann et al., 2022) concerning the challenges of ambiguity, fictionality and historicity (Heuser et al., 2016; Jockers, 2016; Nielsen, 2016).</p>
                <figure>
                    <graphic n=""1001"" width=""16.002cm"" height=""5.823997222222222cm"" url=""Pictures/81e77fdf146eb2b5e324012ea44c7b77.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 1: Reconciliation of narrative locations with OpenRefine</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Modeling</head>
                <p style=""text-align: left; "">Our approach relies on importing both the text strings as found in the information source (green) and the abstract spatial items (blue) into our Wikibase instance. Combined with the fact that we reference all statements uniquely via the ""stated in"" property (orange), this ensures a high degree of verifiability of our data (see fig. 2).</p>
                <figure>
                    <graphic n=""1002"" width=""16.002cm"" height=""9.361cm"" url=""Pictures/7bb7fdf73b81fbd2a67ab93b66b10c82.jpg"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 2: ‘Narrative locations’ of Diderots La religieuse from NER and BGRF data</p>
                <p style=""text-align: left; "">Our spatial vocabulary was built up incrementally and provides items (=spatial concepts) for 7 properties, of which 5 are currently mapped with Wikidata (see fig. 3).
                    <hi rend=""Footnote_Symbol"">
                        <note place=""foot"" xml:id=""ftn2"" n=""2"">
                            <p style=""text-align: left; ""> See for the vocabulary: https://github.com/MiMoText/vocabularies/blob/main/spatial_vocabulary.tsv.</p>
                        </note>
                    </hi>
                </p>
                <figure>
                    <graphic n=""1003"" width=""16.002cm"" height=""7.068cm"" url=""Pictures/eff996f6a2e71439c2c2cbf74b3e4c29.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 3: Ontology of ‘spatial statements’ within the domain of literary history/historiography</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Infrastructure</head>
                <p style=""text-align: left; "">For the provision of data, we follow Open Science principles, such as the publication of FAIR data in open access as well as the use of open source software – in particular Wikibase (see fig.4).
                    <note place=""foot"" xml:id=""ftn3"" n=""3"">
                        <p style=""text-align: left; ""> Generally, see Suber 2012 and Wilkinson et al. 2016; related to the project, see Röttgermann and Schöch 2020 and Schöch, 2021. We expect the Wikibase instance to become publicly available in mid-2022: https://www.mimotext.uni-trier.de/en</p>
                    </note> We created a custom bot using the Python library Pywikibot to import and update the RDF triples into our Wikibase instance from TSV files.
                    <hi rend=""Footnote_Symbol"">
                        <note place=""foot"" xml:id=""ftn4"" n=""4"">
                            <p style=""text-align: left; ""> See https://github.com/MiMoText/Wikibase-Bot.</p>
                        </note>
                    </hi>
                </p>
                <figure>
                    <graphic n=""1004"" width=""16.002cm"" height=""7.957cm"" url=""Pictures/b83328ca8676dd0ab0ea1646514e19fb.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Fig. 4: Local Wikibase instance</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Spatial Querying</head>
                <p style=""text-align: left; "">Having all the spatial triples stored in our Wikibase allows us to query and visualize them using the DockerWikibaseQueryService interface. We can gain an overview of the entire set of metadata (see fig. 5, query 1), see places of publication appearing and disappearing over time (see fig. 6, query 2) or explore narrative locations linked to specific thematic concepts such as ‘miracle’ (see fig. 7, query 3). Via 'federated queries' (see fig. 8, query 4), information from other knowledge bases (here Wikidata) can be used.</p>
                <figure>
                    <graphic n=""1005"" width=""16.002cm"" height=""9.989cm"" url=""Pictures/9ab1e0bb477aa27418f29764a35f0aab.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 5: Overview of the most frequent places of publication</p>
                <figure>
                    <graphic n=""1006"" width=""16.002cm"" height=""6.311cm"" url=""Pictures/e5e4f70800435de49e0827122d82b4f5.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 6: Places of publication over time</p>
                <figure>
                    <graphic n=""1007"" width=""16.002cm"" height=""8.451cm"" url=""Pictures/f4f91d886a861b89a322cc39339ce70f.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 7: Narrative locations linked to the thematic concept ‘miracle’ (excerpt)</p>
                <figure>
                    <graphic n=""1008"" width=""16.002cm"" height=""7.864997222222223cm"" url=""Pictures/507035e65a9dc7915402ff9e3d4ea18c.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 8: Cluster of dominant publication places based on a federated query (Wikidata)</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Conclusion</head>
                <p style=""text-align: left; "">We showcase key aspects of spatial information extraction and modeling in our project. Our presentation will show how we link spatial statements from three sources into a multilingual knowledge network. Triples on publication dates, themes, locations and authors can be combined and be differentiated by their source, something which allows new perspectives for literary history, book history and other domains. Future work concerns extracting and adding statements from scholarly publications to the Wikibase instance.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Appendix</head>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Query 1: Items (novels) and their place of publication (fig. 5)</head>
                    <figure>
                        <graphic n=""1009"" width=""16.002cm"" height=""6.578cm"" url=""Pictures/ff645e3c54fd0485d1e8daca006aa664.png"" rend=""inline""/>
                    </figure>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Query 2: Places of publication over time (fig. 6)</head>
                    <figure>
                        <graphic n=""10010"" width=""16.002cm"" height=""6.361cm"" url=""Pictures/980cec3f5043c18bae18416fbc5bcd5f.png"" rend=""inline""/>
                    </figure>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Query 3: Narrative location of novels with theme “miracle” (fig. 7)</head>
                    <figure>
                        <graphic n=""10011"" width=""16.002cm"" height=""5.868cm"" url=""Pictures/8d05476351226f98c195a3c183272c32.png"" rend=""inline""/>
                    </figure>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Query 4: Places of publication with geocoordinate location via federated query (fig. 8)</head>
                    <figure>
                        <graphic n=""10012"" width=""16.002cm"" height=""6.135cm"" url=""Pictures/e2d98fdb93df36c6a533b605acc5db8c.png"" rend=""inline""/>
                    </figure>
                </div>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Berners-Lee, T.</hi> (2006). 
                        <hi rend=""italic"">Linked Data – Design Issues</hi>. https://www.w3.org/DesignIssues/LinkedData.html.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Burrows, S. et al.</hi> (2016). Mapping Print, Connecting Cultures. 
                        <hi rend=""italic"">Library & Information History</hi>, 32(4), pp. 259–71. 10.1080/17583489.2016.1220781.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Curran, M.</hi>
                        <hi rend=""DH-Biblio_author"" xml:space=""preserve""> </hi>(2018). 
                        <hi rend=""italic"">The French Book Trade in Enlightenment Europe I: Selling Enlightenment</hi>. London: Bloomsbury Publishing.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Delon, M. and Malandain, P.</hi> (1996). 
                        <hi rend=""italic"">Littérature française du XVIIIe siècle</hi>. Paris: Presses universitaires de France. https://gallica.bnf.fr/ark:/12148/bpt6k48060529.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Dennerlein, K.</hi> (2009). 
                        <hi rend=""italic"">Narratologie Des Raumes</hi>. Berlin, New York: De Gruyter.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Heuser, R., Algee-Hewitt, M. and Lockhart, A.</hi> (2016). Mapping the Emotions of London in Fiction, 1700–1900: A Crowdsourcing Experiment. In 
                        <hi rend=""italic"">Literary Mapping in the Digital Age</hi>. London: Routledge.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Hitzler, P.</hi> (2021). A Review of the Semantic Web Field. 
                        <hi rend=""italic"">Commun. ACM</hi>. 10.1145/3397512.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Honnibal, M. and Montani, I.</hi> (2017). 
                        <hi rend=""italic"">SpaCy 2: Natural Language Understanding with Bloom Embeddings, Convolutional Neural Networks and Incremental Parsing</hi>.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Hooland, S. van. and Verborgh, R.</hi> (2014). 
                        <hi rend=""italic"">Linked Data for Libraries, Archives and Museums: How to Clean, Link and Publish Your Metadata</hi>. Facet Publishing.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Huynh, D.</hi> (2010). 
                        <hi rend=""italic"">OpenRefine</hi>. OpenRefine. https://github.com/OpenRefine/OpenRefine.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jockers, M. L.</hi> (2016). The Ancient World in Nineteenth-Century Fiction; or, Correlating Theme, Geography, and Sentiment in the Nineteenth Century Literary Imagination
                        <hi rend=""italic"">. Digital Humanities Quarterly</hi>, 010(2).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Lafon, H.</hi> (1997). 
                        <hi rend=""italic"">Espaces Romanesques Du XVIIIe Siècle, 1670-1820: De Madame de Villedieu à Nodier</hi>. 1. éd. Paris: Presses Universitaires de France.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Martin, A., Mylne, V. and Frautschi, R. L.</hi> (1977). 
                        <hi rend=""italic"">Bibliographie du genre romanesque français, 1751-1800</hi>. London: Mansell.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Mylne, V.</hi> (1981). 
                        <hi rend=""italic"">The Eighteenth-Century French Novel: Techniques of Illusion</hi>. 2nd Edition. Cambridge, New York: Cambridge University Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Nielsen, F. A.</hi> (2016). Literature, Geolocation and Wikidata. In 
                        <hi rend=""italic"">Wiki@ICWSM</hi>. Proceedings of the International AAAI Conference on Web and Social Media. Cologne, pp. 61–4. https://ojs.aaai.org/index.php/ICWSM/article/view/14833.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Röttgermann, J.</hi> (ed.) (2021). Collection de romans français du dix-huitième siècle (1750-1800) / Eighteenth-Century French Novels (1750-1800) [dataset]. 
                        <hi rend=""italic"">Release v0.2.0</hi>. 10.5281/zenodo.5040855.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Schöch, C. et al.</hi> (2022). Smart Modelling for Digital Literary History. 
                        <hi rend=""italic"">IJHAC: International Journal of Humanities and Arts Computing [Special Issue on Linked Open Data]</hi>, 16(1), pp. 78–93. https://doi.org/10.3366/ijhac.2022.0278.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Suber, P.</hi> (2012). 
                        <hi rend=""italic"">Open Access</hi>. Cambridge, Mass: The MIT Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Weber, A.-K.</hi> (2014). 
                        <hi rend=""italic"">Mapping Literature: Spatial Data Modelling and Automated Cartographic Visualisation of Fictional Spaces</hi>. Zurich: ETH Zurich. 10.3929/ETHZ-A-010106067.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Wilkinson, M. D. et al.</hi> (2016). The FAIR Guiding Principles for Scientific Data Management and Stewardship. 
                        <hi rend=""italic"">Scientific Data</hi>, 3(1), p. 160018. 10.1038/sdata.2016.18.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,data modeling;french enlightenment novel;information retrieval;linked open data;literary history,English,"18th century;english;europe;linked (open) data;literary studies;spatial & spatio-temporal analysis, modeling and visualization"
11928,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Patterns of Verb Usage in Immanuel Kant's Critical Writings:,,Stefan Heßbrüggen-Walter;Frank Fischer;Simon Meier-Vieracker,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>Verbs have not been a prominent object of investigation in the digital humanities, although we do find computational literary studies on acoustic phenomena in novels (Katsma 2014) or narrativity of stage instructions in modernist drama (Trilcke et al. 2020) that both focus on the use of verbs in the respective corpora. Philosophical discussions about verbs often refer only to certain classes that are considered philosophically relevant in a given context: illocutionary verbs (Green 2021), verbs expressing propositional attitudes (Nelson 2019), or intensional transitive verbs (Forbes 2020). Our approach is both more comprehensive and more specific. We look at finite verbs regardless of their semantic classification (in this we follow Langer 1927). At the same time, our interest is ‘philological’ in that we aim to understand how verbs contribute to the meaning and interpretation of historical philosophical texts (Kahn 2003 follows a similar approach, however limited to only one verb, ‘to be’). Whereas most philosophical enquiry focuses on nouns as the linguistic side of relevant concepts like reason, duty, taste, etc., the study of verbs that function as predicates and thus relate these concepts can complete the picture of how philosophical judgements and arguments are made.</p>
            <p>We present first results of an investigation of verb usage in Kant’s major critical writings. This corpus has the advantage that these texts present a unified system, so that we can ignore their diachronic dimension. And yet they allow for a contrastive analysis, because the three philosophical subdisciplines theoretical philosophy, practical philosophy and aesthetics are clearly mirrored in the structure of this corpus. We exclude minor writings published after the first edition of the
                <hi rend=""italic"">Critique of Pure Reason</hi> (1781), since they either cannot be clearly assigned to one of the three subdisciplines of philosophy under investigation or belong to subdisciplines such as philosophy of history, political philosophy or philosophy of religionwhich form only a small part of Kant’s overall critical system. The goal of our analysis consists in the identification of verbs that are typical for the respective subcorpus and philosophical subdiscipline. We aim to show that Kant’s usage of verbs differs depending on the philosophical subdiscipline the respective text belongs to.
            </p>
            <p>The corpus consists of the main writings of Kant’s critical philosophy and is divided into three subcorpora (tab. 1): 1) 
                <hi rend=""italic"">Prolegomena</hi>, 
                <hi rend=""italic"">Metaphysical Foundations of Natural Science</hi>, and the second edition of the 
                <hi rend=""italic"">Critique of Pure Reason</hi> (the inclusion of both editions would have introduced a lack of balance in the dataset) in theoretical philosophy, 2) 
                <hi rend=""italic"">Foundations of the Metaphysics of Morals</hi>, 
                <hi rend=""italic"">Critique of Practical Reason</hi> and 
                <hi rend=""italic"">Metaphysics of Morals</hi> for practical philosophy and 3) the 
                <hi rend=""italic"">Critique of Judgment</hi> for aesthetics and teleology.
            </p>
            <table rend=""frame"" xml:id=""Table1"">
                <row>
                    <cell rend=""start"">Assembled Subcorpora</cell>
                    <cell rend=""start"">Works</cell>
                    <cell rend=""start"">N tokens</cell>
                </row>
                <row>
                    <cell rows=""4"" rend=""start"">
                        <hi rend=""bold"">Theoretical Phil.</hi>
                        <lb/>(3 works)
                    </cell>
                    <cell rend=""start italic"">Prolegomena</cell>
                    <cell rend=""start"">52,588</cell>
                </row>
                <row>
                    <cell rend=""start italic"">Metaphysical Foundations of Natural Science</cell>
                    <cell rend=""start"">41,962</cell>
                </row>
                <row>
                    <cell rend=""start italic"">Critique of Pure Reason</cell>
                    <cell rend=""start"">216,587</cell>
                </row>
                <row>
                    <cell rend=""start bold"">Total</cell>
                    <cell rend=""start bold"">311,137</cell>
                </row>
                <row>
                    <cell rows=""4"" rend=""start"">
                        <hi rend=""bold"">Practical Phil.</hi>
                        <lb/>(3 works)
                    </cell>
                    <cell rend=""start italic"">Foundations of the Metaphysics of Morals</cell>
                    <cell rend=""start"">32,958</cell>
                </row>
                <row>
                    <cell rend=""start italic"">Critique of Practical Reason</cell>
                    <cell rend=""start"">67,090</cell>
                </row>
                <row>
                    <cell rend=""start italic"">Metaphysics of Morals</cell>
                    <cell rend=""start"">106,423</cell>
                </row>
                <row>
                    <cell rend=""start bold"">Total</cell>
                    <cell rend=""start bold"">206,471</cell>
                </row>
                <row>
                    <cell rend=""start"">
                        <hi rend=""bold"">Aesth. / Tel.</hi>
                        <lb/>(1 work)
                    </cell>
                    <cell rend=""start italic"">Critique of Judgment</cell>
                    <cell rend=""start bold"">127,939</cell>
                </row>
            </table>
            <p>Tab. 1 number of tokens per work and subcorpus</p>
            <p>The digital edition we used employs modernised orthography which increases the reliability of verb identification through POS-tagging. The texts were tagged and lemmatized with the Stanza POS tagger (Qi et al. 2020) with some manual post processing. We then calculated the key verbs (Culpeper/Demmen 2015) for each subcorpus in contrast to the complete critical writings as reference corpus. We used log-likelihood ratio (Dunning 1993) as keyness measure which can handle the differences in the subcorpus sizes and results in a list of verbs that are used significantly more often in a subcorpus than would be expected from a hypothetical equal distribution</p>
            <div type=""div1"">
                <head>
                    <anchor xml:id=""id__831d7pzfc9ac""/>Results
                </head>
                <p>With the help of our domain knowledge, we can state that Kant’s verb usage shows clear differences across the three subdisciplines. Moreover, we can identify areas within the respective subdiscipline in which verbs make a substantial semantic contribution to Kant’s philosophical language.</p>
                <p>In practical philosophy, many of the high-ranking verbs belong to the semantic field of law (including the moral law, i. e. the Categorical Imperative): to acquire (
                    <hi rend=""italic"">erwerben</hi>), to obligate (
                    <hi rend=""italic"">verpflichten</hi>), to force (
                    <hi rend=""italic"">zwingen</hi>). Others are generic terms for actions (
                    <hi rend=""italic"">handeln, machen, tun</hi>). Only one verb denotes an emotion (to love, 
                    <hi rend=""italic"">lieben</hi>). In theoretical philosophy, the two most high-ranking verbs are associated with the faculty of sensibility: to give, 
                    <hi rend=""italic"">geben</hi>, associated with what is given in sensibility, and to intuit (
                    <hi rend=""italic"">anschauen</hi>). Others seem to belong to natural philosophy (
                    <hi rend=""italic"">erfüllen</hi>, to fill, e. g. space), to move (
                    <hi rend=""italic"">bewegen</hi>), to begin (
                    <hi rend=""italic"">anfangen</hi>), to change (
                    <hi rend=""italic"">verändern</hi>). Some are what we could call ‘generic ontological verbs’, to take place (
                    <hi rend=""italic"">stattfinden</hi>), to exist
                    <hi rend=""italic""> (existieren</hi>). Only one verb is connected to a pertinent epistemic activity, to construe 
                    <hi rend=""italic"">(konstruieren</hi>). In aesthetics and teleology, i. e. in 
                    <hi rend=""italic"">Critique of Judgment</hi>, verbs that express an activity are more prominent: judging (
                    <hi rend=""italic"">urteilen</hi>, 
                    <hi rend=""italic"">beurteilen</hi>) plays, of course, an eminent role as do verbs that denote an aesthetic response (to please
                    <hi rend=""italic"">, gefallen</hi>, to entertain (
                    <hi rend=""italic"">unterhalten</hi>), the communicative force of an aesthetic judgment (to require
                    <hi rend=""italic"">, ansinnen</hi>) or the act of communication itself (to communicate
                    <hi rend=""italic"">, mitteilen</hi>).
                </p>
                <p>Further research will be required to investigate the syntactic diversity of Kant’s use of verbs (finite verb forms compared to participles or infinitives) and its relation to 18th century German in general. Moreover, the collection of typical verb-noun collocations as 
                    <hi rend=""italic"">Recht erwerben </hi>(to aquire a right) will be a useful step.
                </p>
                <p>Our corpus, code and data will be published under free licenses.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Culpeper, Jonathan / Demmen, Jane</hi> (2015). ""Keywords."" In: Biber, Douglas / Reppen, Randi (eds.): The Cambridge Handbook of English Corpus Linguistics. Cambridge: Cambridge University Press. 90–105. (
                        <ref target=""https://doi.org/10.1017/CBO9781139764377.006"">doi:10.1017/</ref>
                        <ref target=""https://doi.org/10.1017/CBO9781139764377.006"">CBO9781139764377.006</ref>)
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Dunning, Ted</hi> (1993). ""Accurate methods for the statistics of surprise and coincidence."" In: Computational Linguistics 19 (1), S. 61–74.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Forbes, Graeme </hi>(2020), ""Intensional Transitive Verbs"", 
                        <hi rend=""italic"">The Stanford Encyclopedia of Philosophy </hi>(
                        <ptr target=""https://plato.stanford.edu/archives/win2020/entries/intensional-trans-verbs/""/>). 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Green, Mitchell</hi> (2021), “Speech Acts”, in: 
                        <hi rend=""italic"">The Stanford Encyclopedia of Philosophy</hi>, (
                        <ref target=""https://plato.stanford.edu/archives/fall2021/entries/speech-acts/"">
                            <hi rend=""color(#1155cc) underline"">https://plato.stanford.edu/­­­archives/fall2021/entries/speech-acts/</hi>
                        </ref>).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Kahn, Charles H.</hi> (2003) The verb ""be"" in ancient Greek, Indianapolis: Hackett.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Katsma, Holst</hi> (2014). ""Loudness in the Novel."" (= 
                        <hi rend=""italic"">Stanford Literary Lab, Pamphlet</hi> Nr. 7 [September 2014].)
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Langer, Susanne K.</hi> (1927). ""A Logical Study of Verbs."" In: 
                        <hi rend=""italic"">The Journal of Philosophy.</hi> Band 24, Heft 5 (März 1927), S. 120–129. (
                        <ref target=""https://doi.org/10.2307/2015082"">
                            <hi rend=""color(#1155cc) underline"">doi:10.2307/2015082</hi>
                        </ref>)
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Nelson, Michael</hi> (2019) ""Propositional Attitude Reports"", 
                        <hi rend=""italic"">The Stanford Encyclopedia of Philosophy</hi>, (
                        <ptr target=""https://plato.stanford.edu/archives/spr2019/entries/prop-attitude-reports""/>).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Qi, Peng / Zhang, Yuhao / Zhang, Yuhui / Bolton, Jason / Manning, Christopher D.</hi> (2020).
                        <ref target=""https://arxiv.org/abs/2003.07082""> </ref>
                        <ref target=""https://arxiv.org/abs/2003.07082"">
                            <hi rend=""color(#1155cc) underline"">Stanza: A Python Natural Language Processing Toolkit for Many Human Languages.</hi>
                        </ref>In Association for Computational Linguistics (ACL) System Demonstrations. 2020.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Trilcke, Peer / Kittel, Christopher / Reiter, Nils / Maximova, Daria / Fischer, Frank</hi> (2020). ""Opening the Stage: A Quantitative Look at Stage Directions in German Drama."" In: 
                        <hi rend=""italic"">DH2020: »carrefours/intersections«.</hi> 22–24. Juli 2020. Conference Abstracts, University of Ottawa.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,immanuel kant;keyness analysis;verbs,English,18th century;english;europe;philosophy;text mining and analysis
11938,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Tools as Epistemologies in DH? A Corpus-Based Exploration,,Manuel Burghardt;Jan Luhmann;Andreas Niekler,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p>Invarsson (2021) suggests a digital epistemology that is to be “understood as an attempt to do digital humanities without being committed to digital tools and objects”. While it is an intriguing idea to leave digital tools and methods out of the equation in order to discern the true epistemological core of DH, we believe that it is equally possible to argue that the use of specific tools virtually shapes and influences the epistemology of DH, or as Nietzsche (1882) put it: “Unser Schreibzeug arbeitet mit an unseren Gedanken
                    <note place=""foot"" xml:id=""ftn1"" n=""1"">
                        <p style=""text-align: left;"">
                            Translation: “Our writing tools [in Nietzsche’s case: his new typewriter] shape our thoughts”.
                        </p>
                    </note>”. Today, Nietzsche’s observations on writing tools can be easily extended to all kinds of research tools, allowing us to ask questions about the epistemological implications of tools for the digital humanities (see Dalbello, 2011; Drucker, 2002; Ramsay & Rockwell, 2012). As there are manifold, rather diverse tools that are used in DH, there is a certain tradition for tool directories that systematically list and categorize different tools. One of the most popular directories is TAPoR
                    <note place=""foot"" xml:id=""ftn2"" n=""2"">
                        <p style=""text-align: left;"">
                            TAPoR: https://tapor.ca/home
                        </p>
                    </note>, which has steadily evolved and by now includes more than 1,600 tools. 
                </p>
                <p>The TAPoR list of tools has been used lately to extract and analyze tools mentioned in DH abstracts (Barbot et al. 2019, Fischer & Moranville, 2020b) and tutorials (Fischer & Moranville, 2020a). The motivation of these analyses is primarily to identify relevant and widely used tools in order to make them sustainably available via infrastructures like the 
                    <hi rend=""italic"">Social Sciences & Humanities Open Marketplace</hi>
                    <note place=""foot"" xml:id=""ftn3"" n=""3"">
                        <p style=""text-align: left;"">
                            <hi style=""font-size:9pt"" xml:space=""preserve""> SSH Open Marketplace: https://marketplace.sshopencloud.eu/</hi>
                        </p>
                    </note>. While the previous studies so far have only looked at comparatively small corpora, we suggest to enhance the scope of DH tool studies by using a large corpus of DH journal articles (
                    <hi rend=""italic"">Computers and the Humanities</hi>, 
                    <hi rend=""italic"">Digital Humanities Quarterly</hi>, 
                    <hi rend=""italic"">Literary and Linguistic Computing</hi>/
                    <hi rend=""italic"">Digital Scholarship in the Humanities</hi>). The corpus comprises 3,737 articles and covers a time span from 1966-2020, which allows for diachronic analyses of tool usage in DH. In addition to using a larger corpus, we also propose an approach to automatically increase the size of the TAPoR tool list.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Experiments with the TAPoR tool list</head>
                <p>For our experiments we followed the approach described by Barbot et al. 2019 and also used the TaPOR directory to derive queries to find tool occurrences in our corpus. All in all, we found 319 different tools being mentioned throughout the corpus
                    <note place=""foot"" xml:id=""ftn4"" n=""4"">
                        <p style=""text-align: left;"">
                            For a complete list see https://docs.google.com/spreadsheets/d/1BtDVo_2A6a1cLPQCZ8CriNcSGHz3UuVc2mxTsM-ZCxo/edit?usp=sharing
                        </p>
                    </note>. Figure 1 shows the most frequent 25 tools in the overall corpus.
                </p>
                <figure>
                    <graphic n=""1001"" width=""16.002cm"" height=""7.1025527777777775cm"" url=""Pictures/e92813ac55266a286227df4dbc4b88a0.png"" rend=""inline""/>
                    <head>Top 25 tools mentioned in the corpus.</head>
                </figure>
                <p>It is noticeable that among the top 25 DH tools we find many tools for text and data analysis, but also a large proportion of high-level programming languages. This is certainly a bias of the early days of humanities computing. Taking a closer look at the diachronic development reveals the natural rise and fall of programming languages, with the steady rise of 
                    <hi rend=""italic"">Python</hi> in the DH since the beginning of the 2010s being particularly prominent (see Figure 2)
                    <note place=""foot"" xml:id=""ftn5"" n=""5"">
                        <p style=""text-align: left;"">
                            <hi style=""font-size:9pt"" xml:space=""preserve""> An interactive version of the plots in Figures 2+3 alongside with more plots can be found here: https://bbrause.github.io/tools-in-dh/</hi>
                        </p>
                    </note>.
                </p>
                <figure>
                    <graphic n=""1002"" width=""15.689394444444444cm"" height=""9.24718888888889cm"" url=""Pictures/b96b8146f77bd4a8788f1838ba3b52c1.png"" rend=""inline""/>
                    <head>The rise and fall of programming languages in DH.</head>
                </figure>
                <p>To provide some more high-level insights, we also did a cooccurrence analysis of the most frequent 150 tools, i.e. tools that are mentioned together in an article (see Figure 3). Such cooccurrence analyses could yield insights into typical tool combinations and more complex workflows, for instance the use of 
                    <hi rend=""italic"" xml:space=""preserve"">Brat </hi>to annotate 
                    <hi rend=""italic"">Twitter</hi> data and the use of 
                    <hi rend=""italic"">SentiStrength</hi> to perform sentiment analyses of tweets.
                </p>
                <p>All in all, Figures 1-3 show some strong potential to analyze tools to find out more about their epistemological implications of DH. However, the predominance of outdated programming languages and the absence of state-of-the-art tools such as 
                    <hi rend=""italic"">spaCy</hi> or transformer architectures clearly shows large gaps in the TAPoR list.
                </p>
                <figure>
                    <graphic n=""1003"" width=""14.969422222222223cm"" height=""12.357430555555556cm"" url=""Pictures/7a34892832ba371901e8d49c1f52f2b3.png"" rend=""inline""/>
                    <head>UMAP 2D projection of the top 150 most-frequent tools and their nPMI cooccurrence scores (point size indicates numbers of occurrences).</head>
                </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Query expansion experiments by means of tool embeddings</head>
                <p>
                    <hi style=""font-family:Palatino Linotype"" xml:space=""preserve"">To fill these gaps, we conducted a second experiment in which we used BERT embeddings to expand our list of tools, as proposed by Wevers & Koolen (2020). We created embeddings for the 25 most frequent tools (see Figure 1) and looked for their nearest neighbors, i.e. words that have similar embedding vectors as the 25 most frequent tools (see Figure 4). </hi>
                </p>
                <figure>
                    <graphic n=""1004"" width=""16.002cm"" height=""5.7785cm"" url=""Pictures/da2e277c30a285788622f40306684536.png"" rend=""inline""/>
                    <head>Ten nearest neighbors for the embeddings of “python”, “rstudio” and “fortran”, ranked by their cosine similarity.</head>
                </figure>
                <p>This approach allows us to identify tools that are not listed in the TAPoR directory directly, but that are mentioned in similar article contexts as the TAPoR-listed tools. Obviously, not all the nearest neighbors identified in this way are actual tools, but if we rank the results according to the number of nearest neighborhoods for the top 25 tools, there are indeed many promising results in the higher ranks
                    <note place=""foot"" xml:id=""ftn6"" n=""6"">
                        <p style=""text-align: left;"">
                            <hi style=""font-size:9pt"" xml:space=""preserve""> The nearest neighbors for each of the 25 most frequent tools as well as a ranked overall list is available here: https://docs.google.com/spreadsheets/d/1iipWwyk7wVcaSzzpEq-W5_vjTe2FO-dmjk_IGjMitEc/edit?usp=sharing</hi>
                        </p>
                    </note>. To give just one example: 
                    <hi rend=""italic"">XSLT</hi> (Extensible Stylesheet Language Transformations) has a fairly high score of 16, which means it was in the nearest neighbors of 16 of the 25 most frequent tools from the initial list. In the top ranks we find many other promising tool candidates, such as 
                    <hi rend=""italic"">RDF</hi>, 
                    <hi rend=""italic"">SGML</hi>, 
                    <hi rend=""italic"">mySQL</hi> and also more generic concepts, such as 
                    <hi rend=""italic"">NLP</hi> and 
                    <hi rend=""italic"">parsing</hi>, which could be interpreted as tool super categories.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Conclusion and next steps</head>
                <p>The experiments by Barbot et al. 2019 and Fischer & Moranville, 2020a/b as well as our follow-up experiments with a larger corpus of texts demonstrate that the empirical analysis of tool mentions in DH publications can be used to discern patterns in the diachronic use of different types of tools. This allows us to explore the effects of tools as rapidly evolving epistemological frameworks in the DH. At the same time, it became clear that the static list of tools as provided by TAPoR has obvious gaps, as the tool landscape is evolving swiftly. We therefore plan to include further directories in follow-up studies, including 
                    <hi rend=""italic"">ProgrammingHistorian</hi>
                    <note place=""foot"" xml:id=""ftn7"" n=""7"">
                        <p rend=""footnote text"" style=""text-align: left;""> Programming Historian: https://programminghistorian.org/en/lessons/</p>
                    </note>, 
                    <hi rend=""italic"">forTEXT</hi>
                    <note place=""foot"" xml:id=""ftn8"" n=""8"">
                        <p rend=""footnote text"" style=""text-align: left;""> forTEXT: https://fortext.net/</p>
                    </note>, 
                    <hi rend=""italic"">DigiHum</hi>
                    <note place=""foot"" xml:id=""ftn9"" n=""9"">
                        <p rend=""footnote text"" style=""text-align: left;""> DigiHum: https://digihum.de/tools/</p>
                    </note>, 
                    <hi rend=""italic"">DMI</hi> (Digital Methods Initiative)
                    <note place=""foot"" xml:id=""ftn10"" n=""10"">
                        <p rend=""footnote text"" style=""text-align: left;""> DMI: https://wiki.digitalmethods.net/Dmi/ToolDatabase</p>
                    </note>, 
                    <hi rend=""italic"">DH Toychest</hi>
                    <note place=""foot"" xml:id=""ftn11"" n=""11"">
                        <p rend=""footnote text"" style=""text-align: left;""> DH Toychest: http://dhresourcesforprojectbuilding.pbworks.com/w/page/69244319/Digita</p>
                    </note>, etc. In this article, we illustrated the benefits of an embeddings-based approach to further expand these static lists of tools. Our next steps will be to extend our corpus to also include articles from neighboring disciplines, such as computational linguistics, computational social sciences, information science and others. We also plan to expand the nearest neighbor search beyond the limit of the 25 most frequent tools and to filter the results list manually, to identify reasonable tools. 
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""background(white)"">Barbot, L., Fischer, F., Moranville, Y. & Pozdniakov, I. (2019). Which DH tools are actually used in research? Published via weltliteratur.net – A Black Market for the Digital Humanities, https://weltliteratur.net/dh-tools-used-in-research/</hi>
                    </bibl>
                    <bibl>Bush, V. (1945). As we may think. The Atlantic Monthly, 176(1), 101-108.</bibl>
                    <bibl>
                        <hi rend=""background(white)"">Dalbello, M. (2011). A genealogy of digital humanities. Journal of Documentation.</hi>
                    </bibl>
                    <bibl>Drucker, J. (2002), “Theory as praxis: the poetics of electronic textuality”, Modernism/Modernity, Vol. 9, November, pp. 683-91. </bibl>
                    <bibl>
                        <hi rend=""background(white)"">Fischer, F. & Moranville, Y. (2020a). DH tools mentioned in ""The Programming Historian""? Published via weltliteratur.net – A Black Market for the Digital Humanities, https://weltliteratur.net/dh-tools-programming-historian/</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""background(white)"">Fischer, F. & Moranville, Y. (2020b). Tools mentioned in DH2020 abstracts. ublished via weltliteratur.net – A Black Market for the Digital Humanities, https://weltliteratur.net/tools-mentioned-in-dh2020-abstracts/.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""background(white)"">Ingvarsson, J. (2020). Digital Epistemology: An Introduction. In Towards a Digital Epistemology (pp. 1-28). Palgrave Macmillan, Cham.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""background(white)"">Nietzsche, F. (1882). Letter 202. An Heinrich Köselitz in Venedig (Typoskript). Nietzsche Source – Digital Critical Edition (eKGWB): http://www.nietzschesource.org/#eKGWB/BVN-1882,202</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""background(white)"">Ramsay, S., & Rockwell, G. (2012). Developing things: Notes toward an epistemology of building in the digital humanities. Debates in the digital humanities, 75-84.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""background(white)"">Wevers, M., & Koolen, M. (2020). Digital begriffsgeschichte: Tracing semantic change using word embeddings. Historical Methods: A Journal of Quantitative and Interdisciplinary History, 53(4), 226-243.</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,epistemology;text analytics;tool embeddings;tool mining,English,computer science;contemporary;english;europe;humanities computing;meta-criticism (reflections on digital humanities and humanities computing);text mining and analysis
11949,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Gender and Cultural Diversity in Chinese Children’s Picture Books: A Data-led Analysis of Bestselling Modern Titles,,Yi Li;Melissa Terras;Yongning Li,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p>Picture books are a main source for pre-schoolers to learn about the wider world; it is important for children to see themselves in books and be aware of differences (Johnston and Bainbridge, 2017; Latima, 2020). Male dominance in children’s books, such as the dominance of male characters has long been problematic (Gooden and Gooden, 2001; Kim, 2016; Terras, 2018), it is important therefore to consider gender (as a protected characteristic) when considering diversity in the Chinese children’s book market. </p>
                <p>Picture books in different countries reflect diverse cultural preferences (Saxby & Winch, 1987; Wee et al., 2015). With a large, growing children’s picture book market (Johnson, 2018), China has translated children’s titles from countries including US, UK, Japan, etc (Li et al., 2020). This study examines the diversity in gender and popular themes in Chinese children’s picture books, by analysing the book authorship, titles, and blurbs of 2,000 bestselling children’s picture books from Dangdang, the major Chinese online bookseller. It provides a general reflection of topics in children’s books from different countries, including Asian, Western countries and other regions. </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Method</head>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Data Corpus</head>
                    <p>We conducted an experimental approach from publicly available information online. Metadata from 2,000 best-selling pre-school picture books were scraped from Dangdang.com, using Python. All data, including book title, blurbs, author introductions were collected on 24
                        <hi rend=""superscript"">th</hi> September 2020 and filtered by sales, the earliest title was published in 2003. Data was allocated to four separate corpora regarding original language and region of publication including Chinese local, East Asian (Japan, South Korea, etc), English (US, UK, Canada, etc) European, and multiregional books (French, Germany, South Africa, etc).
                    </p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Data Analysis</head>
                    <p>This study firstly matched all authors with their sex and nationality by analysing authors’ introductions, as well as searching for official authorial information online, then compiling a statistical breakdown. Secondly, we tokenized book titles and blurbs using the Jieba package in Python, calculated the top 1,000 word list for each corpus. We then identified gendered words, classified them into five groups: pronouns (he/she); gender roles (mum/dad); nouns (princess/witch); animals (cow/cock); name of character (Carmela/Tintin); calculated frequency and compared them. </p>
                    <p>Thirdly, we adopted topic modelling, a text mining method for understanding contents of a corpus through a group of topics (Heidarysafa et al., 2019), to investigate how book topics differ. We used Bertopic, which supports English and Chinese, and tested different parameters for each corpus. We finally modified the number of topics to 3 and 30 topic words, with a value for each word showing its centrality to the topic. </p>
                    <p>All data was collected in Chinese with Chinese-style narratives. We analysed data in Chinese then translated the results into English, as presented below. Finally, we tried to match characters’ names with their original versions and present English names (if there were any).</p>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Results</head>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Comparison of Authors</head>
                    <p>China had imported picture books from 34 countries and areas, with a male dominance among authors (see in Fig1&2). There are 519 East Asian titles, 730 English titles and 332 multilingual titles. </p>
                    <figure>
                        <anchor xml:id=""OLE_LINK1""/>
                        <anchor xml:id=""OLE_LINK2""/>
                        <graphic n=""1001"" width=""16.002cm"" height=""5.505097222222222cm"" url=""Pictures/0d3a8c5769123c4f8b9e6c142e5f2c1a.png"" rend=""inline""/>
                    </figure>
                    <p>Fig 1 Nationality of Authors</p>
                    <figure>
                        <graphic n=""1002"" width=""14.11111111111111cm"" height=""7.267222222222222cm"" url=""Pictures/415afbc8658fb827796afaf3a91b2c6d.png"" rend=""inline""/>
                    </figure>
                    <p>Fig 2 Gender of Authors
                        <note place=""foot"" xml:id=""ftn1"" n=""1"">
                            <p rend=""footnote text""> There are some titles were written by a group of editors, it is difficult to confirm their sex information, so we classified them into the none group.</p>
                        </note>
                    </p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Gender representation in books </head>
                    <p>A gendered keyword list compared the gender representation in books. There are more male characters in all corpora, however, mum/mom weighed more than dad in all books. Chinese and Asian titles have fewer gendered words, while more characters were portrayed in English books, correspondingly more pronouns are used. </p>
                    <figure>
                        <graphic n=""1003"" width=""14.908694444444444cm"" height=""12.986172222222223cm"" url=""Pictures/9202f9691dc5fb86ffd5065de5794df6.png"" rend=""inline""/>
                    </figure>
                    <p>* Numbers in every blank respectively represent the number of different words in this type and the total frequency of all words in this type.</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Topic clustering between corpora of different regions</head>
                    <p>Topics from each dataset were presented in word clouds (Fig 3-14). Chinese culture, children’s education and books resulting from corporate franchises are three main topics in Chinese local titles. Similar topics can be found in East Asian titles, but there are more local topics. Big brands such as Disney, family education and animal stories are important aspects in English titles. </p>
                    <figure>
                        <graphic n=""1004"" width=""16.51cm"" height=""6.152444444444445cm"" url=""Pictures/235a10b0a2f686d14e694e08cdb1a5f6.png"" rend=""inline""/>
                        <graphic n=""1005"" width=""16.51cm"" height=""6.309430555555555cm"" url=""Pictures/93ef7ed85b6978e5a3160c5d3e03adda.png"" rend=""inline""/>
                    </figure>
                    <figure>
                        <graphic n=""1006"" width=""16.51cm"" height=""6.397625cm"" url=""Pictures/71bd7b32050ff18d7525bf4496a089ff.png"" rend=""inline""/>
                        <graphic n=""1007"" width=""16.51cm"" height=""6.3129583333333334cm"" url=""Pictures/7a007275b824d4a4e0b5dc3d7ccb3f25.png"" rend=""inline""/>
                    </figure>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Discussion</head>
                <p>The data-driven analysis of book authors and blurbs indicates publishing, purchasing, and reading preferences and showed an overall male dominance the Chinese children’s picture book market. Chinese and East Asian titles emphasise cultural contents and are more education-oriented, while books from Western countries portray more characters and focus on storytelling and children’s emotions. However, this study is a partial reflection of the Chinese children’s book market due to limited data collected for popular titles. All translated titles were chosen under the publishing censorship in China, and they might not be proper representatives of diverse picture books. Further studies can expand the dataset, include more languages and book genres, as well as adopting other methods such as network analysis.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Gooden, A. M. and Gooden, M. A.</hi> (2001). Gender Representation in Notable Children’s Picture Books: 1995-1999. 
                        <hi rend=""italic"">Sex Roles</hi>, 
                        <hi rend=""bold"">45</hi>(1/2), pp. 89–101. 
                        <ref target=""http://dx.doi.org/10.1023/A:1013064418674"">http://dx.doi.org/10.1023/A:1013064418674</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Johnston. and Bainbridge, J.</hi> (2017). 
                        <hi rend=""italic"">Reading Diversity through Canadian Picture Books: Preservice Teachers Explore Issues of Identity, Ideology, and Pedagogy</hi>. University of Toronto Press. 
                        <ref target=""https://doi.org/10.3138/9781442666412"">10.3138/9781442666412</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Johnson.</hi> (2018a). 
                        <hi rend=""italic"">China’s Children’s Book Market: Big Numbers and Local Talent</hi>. 
                        <hi rend=""italic"">Publishing Perspectives</hi>. 
                        <ref target=""https://publishingperspectives.com/2018/11/china-childrens-book-market-big-numbers-local-talent/"">https://publishingperspectives.com/2018/11/china-childrens-book-market-big-numbers-local-talent/</ref> (accessed 25 October 2021).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Johnson.</hi> (2018b). 
                        <hi rend=""italic"">Why Children’s Book Publishing in China Is Growing So Fast</hi>. 
                        <hi rend=""italic"">Publishing Perspectives</hi>. 
                        <ref target=""https://publishingperspectives.com/2018/03/why-chinas-childrens-book-industry-is-growing-so-fast/"">https://publishingperspectives.com/2018/03/why-chinas-childrens-book-industry-is-growing-so-fast/</ref> (accessed 25 October 2021).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Kim, S. J.</hi> (2016). Expanding the Horizons for Critical Literacy in a Bilingual Preschool Classroom: Children’s Responses in Discussions with Gender-Themed Picture Books. 
                        <hi rend=""italic"">International Journal of Early Childhood</hi>, 
                        <hi rend=""bold"">48</hi>(3), pp. 311–27. 
                        <ref target=""http://dx.doi.org/10.1007/s13158-016-0171-3"">http://dx.doi.org/10.1007/s13158-016-0171-3</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Li, Yi., Hangxizi, S. and Li, Yongning.</hi> (2020). Is the Chinese Children’s Mainstream Book Market Inclusive Enough? A Data Analysis of Children’s Bestsellers on Dangdang.Com. 
                        <hi rend=""italic"">Publishing Research Quarterly</hi>, 
                        <hi rend=""bold"">36</hi>(1), pp. 129–44. 
                        <ref target=""http://dx.doi.org/10.1007/s12109-019-09706-z"">http://dx.doi.org/10.1007/s12109-019-09706-z</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Saxby, H. M. and Winch, G.</hi> (1987). 
                        <hi rend=""italic"">Give Them Wings: The Experience of Children’s Literature</hi>. South Melbourne: Macmillan Co. of Australia.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Wee, S.-J., Park, S. and Choi, J. S.</hi> (2015). Korean Culture as Portrayed in Young Children’s Picture Books: The Pursuit of Cultural Authenticity. 
                        <hi rend=""italic"">Children’s Literature in Education</hi>, 
                        <hi rend=""bold"">46</hi>(1), pp. 70–87. 
                        <ref target=""https://doi.org/10.1007/s10583-014-9224-0"">10.1007/s10583-014-9224-0</ref>.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,children's picture books;china;keywords diversity;term frequency;topic modelling,English,asia;contemporary;english;library & information science;media studies;text mining and analysis
11951,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Creative Flows: Artistic Inspiration in/through/with Katherine Dunham’s Transnational Circulation,,Harmony Bench;Kate Elswit;Antonio Jimenez-Mavillard;Tia-Monique Uzor,poster / demo / art installation,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>This poster comes from the AHRC-funded project 
                <hi rend=""italic"">Dunham’s Data: Katherine Dunham and Digital Methods for Dance Historical Inquiry</hi>. The overarching project explores 
                <hi rend=""color(010101)"" xml:space=""preserve"">the kinds of questions and problems that make the analysis and visualization of data meaningful for dance history, through the case study of </hi>20th century African American choreographer Katherine Dunham, who toured the globe extensively, picking up performers and gathering culturally specific movement for her repertory as she went (Bench and Elswit 2020; Bench and Elswit 2022). Drawing on data-informed research in theatre history (Varela 2021; Miller 2016) and feminist and anti-racist approaches to data (D’Ignazio and Klein 2020; Johnson 2018), our manually-curated core project datasets represent Dunham’s everyday itinerary of over 5000 days spent between 1947-1960 on every continent but Antarctica, the almost 200 dancers, drummers, and singers who travelled with her, and the almost 200 interconnected elements of repertory that they performed. These are currently being expanded to 1938-63, covering the majority of Dunham’s stage career, and all of her domestic and international touring.
            </p>
            <p>Reflecting the 2022 conference theme “Responding to Asian Diversity,” we will present digital visualizations based on data collected regarding the time Dunham spent touring in the Asia-Pacific region from 1956-1958, in particular highlighting research findings related to: 1) the sites of performances and other travel to 21 cities across Australia, New Zealand, Philippines, Singapore, Malaya, Hong Kong, Korea, and Japan, 2) the performers who toured with her and those who joined her company en route (including two Australians, a New Zealander, and eight Filipinos), and 3) the existing repertory they brought with them to perform in these locations, as well as new repertory inspired by their time in the region.</p>
            <p>The company’s international touring brought them into contact with a broad range of rhythms, gestures, and referents, which then circulated onward as Dunham toured. During this period, the company began to perform a number based on the Maori haka, which was later combined with Baby San and Planting Rice, pieces that referenced travels to Japan, Korea, and the Philippines, to form Eastern Suite. We employ 
                <hi rend=""color(010101)"" xml:space=""preserve"">spatial, network, and computational analyses as they are used in performing arts research (Bollen and Holledge 2011; Balme 2019) to better understand how Dunham’s choreography materializes the influence of the many geographic places that infused her diasporic imagination, and trace the flows of performers working together over time and space as a dynamic collective, and how their embodied knowledge supports the creation and transmission of Dunham’s repertory. The analyses and visualizations displayed on this poster use a combination of Python/Pandas, Matplotlib, Seaborn, Gephi, Leaflet, and NetworkX. Based on Dunham’s program notes for her choreography, </hi>we geolocated every repertory work (accurate to the degree Dunham described) and assigned the map a 2D color palette in such a way that repertory associated with locations of inspiration near each other will have similar colors, which we use to represent these both on the map and off as a stacked bar chart by year.  We then seek to understand the multi-directional force of inspiration by connecting timelines of Dunham’s places visited and of repertory inspired by place as a bipartite graph. This is further complicated by joining three datasets to examine the correlations of Dunham’s travel itinerary by means of a temporal punch card, the trajectories of each company member through the company, and the passports they each carried. Together, these 
                <hi rend=""color(010101)"">analyses make traceable potential ripples of Dunham’s influence in the many locations the company visited, including Dunham’s long term impact in the Australian entertainment landscape (Bollen 2020), and the ways in which her presence is narrated in the development of Japanese Butoh (Michio 2019).</hi>
            </p>
            <p>
                <hi rend=""color(010101)"" xml:space=""preserve"">Because scholars generally consider Dunham’s artistic and political project to be one of </hi>tracing resonances and retentions of Africanist elements in diasporic 
                <hi rend=""color(010101)"" xml:space=""preserve"">movement </hi>practices
                <hi rend=""color(010101)"" xml:space=""preserve""> throughout the Caribbean and Americas (Clark 1994; Manning 2004; Das 2017), they have not fully accounted for Asia as a site of inspiration for her choreographic work, and how her influence may have extended throughout the area as performers joined and left the company while touring, as well as the impact of her depiction of African-diasporic practices on local audiences. This poster connects with current scholarship on the African diaspora beyond the Black Atlantic (Gilroy 1993) toward various Black internationalisms that “have never been contained within the holy trinity of Europe, Africa, and the Americas” (Patterson and Kelley 2000, 32) and offers an opportunity to illuminate Dunham as part of transnational creative flows between the Asia-Pacific region and the Afro-Caribbean and Americas.</hi>
            </p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Balme, C.</hi> (2019). The Globalization of Theatre 1870–1930: The Theatrical Networks of Maurice E. Bandmann
                        <hi rend=""italic"">.</hi> Cambridge: Cambridge University Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Bench, H. and Elswit, K.</hi> (2020). Katherine Dunham’s Global Method and the Embodied Politics of Dance’s Everyday, Theatre Survey, 61(3): 305-30.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Bench, H. and Elswit, K.</hi> (2022). Visceral Data for Dance Histories: Katherine Dunham’s People, Places, and Pieces, TDR, 66(1): 39-62.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Bollen, J.</hi> (2020). Touring Variety in the Asia Pacific Region, 1946–1975
                        <hi rend=""italic"" xml:space=""preserve"">. </hi>London: Palgrave.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Bollen, J. and Holledge, J.</hi> (2011). Hidden Dramas: Cartographic Revelations in the World of Theatre Studies, The Cartographic Journal, 48(4): 226-36.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Caplan, D. </hi>(2016). Reassessing Obscurity: The Case for Big Data in Theatre History. Theatre Journal, 68 (4): 555-573.
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">Clark, V.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (1994). Performing the Memory of Difference in Afro-Caribbean Dance: Katherine Dunham’s Choreography, 1938-87. In Fabre, G and O’Meally, R. G. (eds), History and Memory in African-American Culture. New York: Oxford University Press. 188-204.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">Das, J. D.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (2017). Katherine Dunham: Dance and the African Diaspora. New York: Oxford University Press.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">D’Ignazio, C. and Klein, L. F.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (2020). Data Feminism. Cambridge, MA: The MIT Press.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">Johnson, J. M.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (2018). Markup Bodies: Black [Life] Studies and Slavery [Death] Studies at the Digital Crossroads, Social Text, 36(4):57–79. </hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">Gilroy, P.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (1993). The Black Atlantic: Modernity and Double Consciousness. Cambridge, MA: Harvard University Press.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"" xml:space=""preserve"">Manning, S. </hi>
                        <hi rend=""color(010101)"">(2004). Modern Dance, Negro Dance: Race in Motion. Minneapolis: University of Minnesota Press.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">Michio, A.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (2019). From Vodou to Butoh: Hijikata Tatsumi, Katherine Dunham, and the Trans-Pacific Remaking of Blackness. In Baird, B. and Candelario, R. (eds), The Routledge Companion to Butoh Performance. New York: Routledge.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">Patterson, T. R. and Kelley, R. D. G.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (2000). Unfinished Migrations: Reflections on the African Diaspora and the Making of the Modern World, African Studies Review, 43(1): 11-4.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold color(010101)"">Varela, M. E.</hi>
                        <hi rend=""color(010101)"" xml:space=""preserve""> (2021). Theater as Data: Computational Journeys into Theater Research. Ann Arbor: University of Michigan Press.</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>",xml,This text is republished here with permission from the original rights holder.,,circulation;dance;diaspora;katherine dunham;transnationalism,English,"20th century;comparative (2 or more geographical areas);cultural analytics;english;history;performance studies: dance, theatre;spatial & spatio-temporal analysis, modeling and visualization"
11984,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Extracting and providing online access to annotated and semantically enriched historical data.The AGODA project,,Marie Anna Puren;Pierre Vernus;Aurélien Pellet;Nicolas Bourgeois,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>The AGODA project
                <note place=""foot"" xml:id=""ftn1"" n=""1"">
                    <p rend=""footnote text"">
                        <ref target=""https://github.com/mpuren/agoda"">https://github.com/mpuren/agoda</ref>
                    </p>
                </note> (Puren and Vernus, 2021) is one of five pilot projects supported by the DataLab of the Bibliothèque nationale de France. It aims to create an online platform facilitating the exploration and use of the parliamentary debates of the Chamber of Deputies published in the 
                <hi rend=""italic"">Journal officiel</hi> from 1881 to 1940. In the framework of the DataLab, we are working on a test sub-corpus, namely the parliamentary cycle from 1889 to 1893, to test our hypotheses on a smaller dataset.
            </p>
            <p>Over the past sixty years, a great deal of work has been done on parliamentary debates (Chester and Bowring, 1962; Franklin and Norton, 1993). It is indeed a valuable source for historians (Marnot, 2000; Ouellet and Roussel-Beaulieu, 2003; Ihalainen, 2016; Lemercier, 2021), political scientists (Van Dijk, 2010), sociologists (Cheng, 2015) or linguists (de Galembert et al., 2013; Hirst et al., 2014; Rheault et al., 2016). Access to digitised and ocerised debates thus seems to have a positive effect on the number of historical works using these documents (Mela et al., 2022). The same effect can be observed for other disciplines using contemporary debates (Fišer et al., 2018; Fišer et al., 2020). AGODA is thus part of a wider movement to facilitate the use and analysis of parliamentary data, following the example of ParlaClarin (Fišer and Lenardič, 2018) and ParlaMint (Erjavec et al., 2022a; Erjavec et al., 2022b), which propose to produce comparable and multilingual Parliamentary Proceedings Corpora according to the XML-TEI standard. Naomi Truan has also produced a corpus of parliamentary debates encoded in XML-TEI (Truan, 2016; Truan and Romary, 2021). The production of this type of resource facilitates the publication of works exploiting this data to better understand French political discourse (Diwersy et al., 2018; Blaette et al., 2020; Diwersy and Luxardo, 2020).</p>
            <p>Between 1881 and 1899, 2596 issues of the 
                <hi rend=""italic"">Journal Officiel</hi> were published (50791 JPG images). The debates are also in TXT format but put online without extensive post-correction: the quality of the OCR is not sufficient to provide a satisfactory online browsing experience, and it could have a negative impact on the analyses performed on these texts (van Strien, 2020). Therefore, we chose to ocerise the text, to obtain a better-quality result. We use the PERO OCR (Kodym and Hradiš, 2021; Kohút and Hradiš, 2021; Kišš et al., 2021) based solution developed by the SODUCO project
                <note place=""foot"" xml:id=""ftn2"" n=""2"">
                    <p rend=""footnote text"">
                        <ref target=""https://soduco.github.io/"">https://soduco.github.io/</ref>
                    </p>
                </note>. This tool, still in private alpha version, has been used to prepare the data in (Abadie et al., 2022) that will be accessible via Zenodo.
            </p>
            <p>Ocerised texts are obtained in JSON format; we are developing Python scripts to convert this output into an XML file corresponding to the chosen TEI model. This model is formalised with an adapted XML schema, created using an ODD (Rahtz and Burnard, 2013). We chose to use the ODD created by ParlaClarin (Erjavec and Pančur, 2021) which can be easily adapted to annotate historical parliamentary debates. In the case of France, the rules for transcribing debates were set in the 19th century; thus, the recordings of today's debates are very similar to those produced during the Third Republic. The TEI-encoded corpus will be stored in an eXist-db database, and it will be visualised using the TEI Publisher application, which can transform the source data into HTML web pages. The parliamentary debates will thus be made available to online users as a digital edition and integrated into an application context.</p>
            <p>We will also present the first analyses we have carried out on this corpus with ""bag-of-words"" techniques - these being not too sensitive to the quality of the OCR. We first used topic modelling, an unsupervised learning method that allows us to discover the latent semantic structures of a corpus of texts, without using semantic and lexical resources (Blei et al., 2003). This method is well suited to study parliamentary debates (Bourgeois et al., 2022).</p>
            <figure>
                <graphic n=""1001"" width=""16.002cm"" height=""10.759722222222223cm"" url=""Pictures/47c5da5ce3f9377487ba1a7b2c6dc146.png"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">Distribution of four different topics over time</p>
            <p>Alternatively, we can use word embeddings to reduce the dimension of the original space from several tens of thousands of forms to a hundred axes, and then apply classical data science tools such as clustering or correlation analysis on the reduced space (Mikolov et al., 2013). Word embedding has thus shown its interest in the study of parliamentary debates (Rheault and Cochrane, 2020). We used a continuous bag-of-words model for dimension reduction and an unsupervised classification algorithm - in this case DBSCAN - to group words into clusters.</p>
            <figure>
                <graphic n=""1002"" width=""16.002cm"" height=""10.759722222222223cm"" url=""Pictures/47c5da5ce3f9377487ba1a7b2c6dc146.png"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">t-SNE projection of the centroïds of the clusters</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Abadie, N., Carlinet, E., Chazalon, J., Dumenieu, B.</hi> (2022). A Benchmark of Named Entity Recognition Approaches in Historical Documents. Application to 19th Century French Directories. DAS 2022 15th IAPR International Workshop on Document Analysis Systems. La Rochelle, France. May 22-25, 2022.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Blaette, A., Gehlhar, S. and Leonhardt, C.</hi> (2020). The Europeanization of Parliamentary Debates on Migration in Austria, France, Germany, and the Netherlands. Proceedings of the Second ParlaCLARIN Workshop. Marseille, France: European Language Resources Association, pp. 66–74 
                        <ref target=""https://aclanthology.org/2020.parlaclarin-1.12"">https://aclanthology.org/2020.parlaclarin-1.12</ref> (accessed 21 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Blei, D. M., Ng, A. Y. and Jordan, M. I.</hi> (2003). Latent dirichlet allocation. The Journal of Machine Learning Research, 3: 993–1022.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Cheng, J. E.</hi> (2015). Islamophobia, Muslimophobia or racism? Parliamentary discourses on Islam and Muslims in debates on the minaret ban in Switzerland. Discourse & Society, 
                        <hi rend=""bold"">26</hi>(5). SAGE Publications.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Chester, D. N. and Bowring, N.</hi> (1962). Questions in Parliament. Oxford: Clarendon Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Diwersy, S., Frontini, F. and Luxardo, G.</hi> (2018). The Parliamentary Debates as a Resource for the Textometric Study of the French Political Discourse. Proceedings of the ParlaCLARIN@LREC2018 Workshop. Miyazaki, Japan 
                        <ref target=""https://hal.archives-ouvertes.fr/hal-01832649"">https://hal.archives-ouvertes.fr/hal-01832649</ref> (accessed 21 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Diwersy, S. and Luxardo, G.</hi> (2020). Querying a large annotated corpus of parliamentary debates. LREC, ParlaCLARIN Workshop. (Proceedings of the Second ParlaCLARIN Workshop). Marseille, France 
                        <ref target=""https://hal.archives-ouvertes.fr/hal-03317717"">https://hal.archives-ouvertes.fr/hal-03317717</ref> (accessed 21 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Erjavec, T. and Pančur A.</hi> (2021) Parla-CLARIN: A TEI Schema for Corpora of Parliamentary Proceedings 
                        <ref target=""https://clarin-eric.github.io/parla-clarin/"">https://clarin-eric.github.io/parla-clarin/</ref> (accessed 21 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Erjavec, T., Pančur A. and Kopp M.</hi> (2022a). ParlaMint: Comparable Parliamentary Corpora. GLSL CLARIN ERIC 
                        <ref target=""https://github.com/clarin-eric/ParlaMint"">https://github.com/clarin-eric/ParlaMint</ref> (accessed 21 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Erjavec, T., Ogrodniczuk, M., Osenova, P., Ljubešić, N., Simov, K., Pančur, A., Rudolf, M., et al.</hi> (2022b). The ParlaMint corpora of parliamentary proceedings. Language Resources and Evaluation doi:10.1007/s10579-021-09574-0. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fišer, D., Eskevich, M. and Jong, F. de (eds).</hi> (2018). Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). Paris: European Language Resources Association (ELRA).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fišer, D., Eskevich, M. and Jong, F. de (eds).</hi> (2020). Proceedings of the Second ParlaCLARIN Workshop. Marseille: European Language Resources Association (ELRA).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fišer, D. and Lenardič, J.</hi> (2018). CLARIN resources for parliamentary discourse research. Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). European Language Resources Association (ELRA), pp. 2–7.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Galembert, C. de, Rozenberg, O., Vigour, C. (eds)</hi> (2013). Faire parler le parlement: méthodes et enjeux de l’analyse des débats parlementaires pour les sciences sociales. Paris: LGDL-Lextenso.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Hirst, G., Feng, V., Cochrane, C. and Naderi, N.</hi> (2014). Argumentation, Ideology, and Issue Framing in Parliamentary Discourse. In Cabrio E, Villata S. and Wyner A. S. (eds), Proceedings of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing, Forlì-Cesena, Italy, July 21-25, 2014, CEUR-WS.org, 
                        <ref target=""http://ceur-ws.org/Vol-1341/paper6.pdf"">http://ceur-ws.org/Vol-1341/paper6.pdf</ref> (accessed 26 April 2022). 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Ihalainen, P., Ilie, C. and Palonen, K.</hi> (2018). Parliament and Parliamentarism: A Comparative History of a European Concept, New York, Oxford: Berghahn.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Ilie, C.</hi> (2010). European Parliaments under Scrutiny: Discourse Strategies and Interaction Practices. Amsterdam; Philadelphia: John Benjamins.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Kišš, M., Beneš, K. and Hradiš, M.</hi> (2021). AT-ST: Self-training Adaptation Strategy for OCR in Domains with Limited Transcriptions. In Lladós, J., Lopresti, D., Uchida, S. (eds) Document Analysis and Recognition – ICDAR 2021. ICDAR 2021. Lecture Notes in Computer Science, vol 12824. Cham: Springer, 
                        <ref target=""https://doi.org/10.1007/978-3-030-86337-1_31"">https://doi.org/10.1007/978-3-030-86337-1_31</ref> (accessed 26 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Kodym, O. and Hradiš, M.</hi> (2021). Page Layout Analysis System for Unconstrained Historic Documents. Document Analysis and Recognition – ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5–10, 2021, Proceedings, Part II. Berlin, Heidelberg: Springer-Verlag, pp. 492–506.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Kohút, J. and Hradiš, M.</hi> (2021). TS-Net: OCR Trained to Switch Between Text Transcription Styles. In Lladós, J., Lopresti, D., Uchida, S. (eds) Document Analysis and Recognition – ICDAR 2021. ICDAR 2021. Lecture Notes in Computer Science, vol 12824. Cham: Springer, 
                        <ref target=""https://doi.org/10.1007/978-3-030-86337-1_32"">https://doi.org/10.1007/978-3-030-86337-1_32</ref> (accessed 26 April 2022). 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">La Mela, M., Norén, F., and Hyvönen, E.</hi> (2022). Digital parliamentary data in action (DiPaDA 2022), workshop co-located with the 6th Digital Humanities in the Nordic and Baltic countries conference (DHNB 2022), 
                        <ref target=""https://dhnb.eu/conferences/dhnb2022/workshops/dipada/"">https://dhnb.eu/conferences/dhnb2022/workshops/dipada/</ref> (accessed 26 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Lemercier, C.</hi> (2021). Un catholique libéral dans le débat parlementaire sur le travail des enfants dans l’industrie (1840). Parlement[s], Revue d’histoire politique, 
                        <hi rend=""bold"">33</hi>(1): 195–206.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Marnot, B.</hi> (2000). Les ingénieurs au Parlement sous la IIIe République. Paris: CNRS Editions.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Mikolov, T., Chen, K., Corrado, G. and Dean, J.</hi> (2013). Efficient Estimation of Word Representations in Vector Space. ArXiv:1301.3781 [Cs] 
                        <ref target=""http://arxiv.org/abs/1301.3781"">http://arxiv.org/abs/1301.3781</ref> (accessed 26 April 2022). 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Ouellet, J. and Roussel-Beaulieu, F.</hi> (2003). Les débats parlementaires au service de l’histoire politique. Bulletin d’histoire politique, 
                        <hi rend=""bold"">11</hi>(3). Bulletin d’histoire politique: 23–40 doi:10.7202/1060736ar.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Puren, M. and Vernus, P.</hi> (2021). AGODA : Analyse sémantique et Graphes relationnels pour l’Ouverture et l’étude des Débats à l’Assemblée nationale. Inauguration Du BnF DataLab. Paris, France 
                        <ref target=""https://hal.archives-ouvertes.fr/hal-03382765"">https://hal.archives-ouvertes.fr/hal-03382765</ref> (accessed 26 April 2022). 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Rahtz, S. and Burnard, L.</hi> (2013). Reviewing the TEI ODD system. Proceedings of the 2013 ACM Symposium on Document Engineering. (DocEng ’13). New York, NY, USA: Association for Computing Machinery, pp. 193–96.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Rheault, L., Beelen, K., Cochrane, C. and Hirst, G</hi>. (2016). Measuring Emotion in Parliamentary Debates with Automated Textual Analysis. PLOS ONE, 
                        <hi rend=""bold"">11</hi>(12). Public Library of Science: e0168843 doi:10.1371/journal.pone.0168843.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Rheault, L. and Cochrane, C.</hi> (2020). Word Embeddings for the Analysis of Ideological Placement in Parliamentary Corpora. Political Analysis, 
                        <hi rend=""bold"">28</hi>(1). Cambridge University Press: 112–33 doi:10.1017/pan.2019.26.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Strien, D. A. van, Beelen, K., Ardanuy, M. C., Hosseini, K., McGillivray, B. and Colavizza, G. </hi>(2020). Assessing the Impact of OCR Quality on Downstream NLP Tasks. ICAART doi:10.5220/0009169004840496.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Study of parliament group (GB), F., Mark N. and Norton, P.</hi> (1993). Parliamentary Questions. Oxford: Clarendon Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Truan, N.</hi> (2019). Débats parlementaires sur l'Europe à l'Assemblée nationale (2002-2012) [Corpus]. ORTOLANG (Open Resources and TOols for LANGuage) - www.ortolang.fr, v1.1, 
                        <ref target=""https://hdl.handle.net/11403/fr-parl/v1.1"">https://hdl.handle.net/11403/fr-parl/v1.1</ref> (accessed 21 April 2022c).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Truan, N. and Romary, L.</hi> (2021). Building, Encoding, and Annotating a Corpus of Parliamentary Debates in XML-TEI: A Cross-Linguistic Account. Journal of the Text Encoding Initiative 
                        <ref target=""https://halshs.archives-ouvertes.fr/halshs-03097333"">https://halshs.archives-ouvertes.fr/halshs-03097333</ref> (accessed 21 April 2022).
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,digital history;parlementiary debates;tei,English,"19th century;20th century;data publishing projects, systems, and methods;english;europe;history;natural language processing"
11985,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Take a sip of TEI and relax: a proposition for an end-to-end workflow to enrich and publish data created with automatic text recognition,,Alix Chagué;Hugo Scheithauer;Lucas Terriel;Floriane Chiffoleau;Yves Tadjo Takianpi;Laurent Romary,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>Over the last decades, several breakthroughs have made the dream to automatically transcribe thousands of handwritten documents a reality (Causer et al., 2018; Sánchez et al., 2017; Seaward, 2017; Yin et al., 2013). For example, software like 
                <hi rend=""italic"">Transkribus</hi> (Kahle et al., 2017) and 
                <hi rend=""italic"">eScriptorium</hi> (Stokes et al., 2021) provide non-specialist users with simple environments to conduct transcription campaigns relying on efficient HTR
                <note place=""foot"" xml:id=""ftn1"" n=""1"">
                    <p>
                        <hi style=""font-size:10pt"" xml:space=""preserve""> HTR stands for Handwritten Text Recognition.</hi>
                    </p>
                </note> engines. While transposing scriptures from a piece of paper onto a text editor used to require effort and concentration, it is now possible to imagine simply pressing a button and letting your computer work while you start preparing your next cup of tea. A few minutes later, your drink is ready, and so is the transcription of the two thousand pages you needed. As automatic transcription software is about to produce huge volumes of data (Clanuwat et al., 2019; Camps, 2021. See also the Vietnamica project
                <note place=""foot"" xml:id=""ftn2"" n=""2"">
                    <p>
                        <hi style=""font-size:10pt"" xml:space=""preserve"">Vietnamica is a research project undertaken jointly by the École Pratique des Hautes Études, the Institute of Hán-Nôm Studies, the Social Sciences Academy of Viêt Nam and the National University of Viêt Nam (Faculty of Humanities and Social Sciences). See </hi>
                        <ref target=""https://vietnamica.online/"">
                            <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://vietnamica.online/</hi>
                        </ref>
                    </p>
                </note>.), it seems crucial to think about how we can interact with the resulting files with maximum efficiency.
            </p>
            <p>In response to previous similar initiatives (Carius, 2020), we would like to present an end-to-end workflow revolving around the use of various automatic techniques to go from a set of digital images to the actual publication of a text edition. Such techniques include, on top of HTR, information extraction tools
                <note place=""foot"" xml:id=""ftn3"" n=""3"">
                    <p>
                        <hi style=""font-size:10pt"" xml:space=""preserve""> Rosa Stern defined information extraction as a task consisting of extracting and structuring, in semantic classes, the specific information elements contained in non-structured data for automatic processing, such as coreference resolution, relationship extraction, and named entity recognition (Stern, 2013, p. 59).</hi>
                    </p>
                </note> and an open source and ready-to-use environment for publication. Moreover, we aim to make this framework as simple and generic as possible: it is independent from the transcription engine, and potentially compatible with any language, writing system, and any type of document (Balogh and Griffiths, 2020. See also the TEI Special Interest Group for East Asian/Japanese
                <note place=""foot"" xml:id=""ftn4"" n=""4"">
                    <p>
                        <hi style=""font-size:10pt"" xml:space=""preserve""> See </hi>
                        <ref target=""https://tei-c.org/Activities/SIG/EastAsian/"">
                            <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://tei-c.org/Activities/SIG/EastAsian/</hi>
                        </ref>
                        <hi style=""font-size:10pt"" xml:space=""preserve""> and </hi>
                        <ref target=""https://wiki.tei-c.org/index.php/SIG:East_Asian"">
                            <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://wiki.tei-c.org/index.php/SIG:East_Asian</hi>
                        </ref>
                    </p>
                </note>).
            </p>
            <p>Several key principles ensure the coherence of the workflow: transparency and availability of the data at each step and the use of a fully standardized format like TEI XML as the cornerstone to store all the available information. Other XML standards like ALTO
                <note place=""foot"" xml:id=""ftn5"" n=""5"">
                    <p>
                        <hi style=""font-size:10pt"" xml:space=""preserve""> See the Analyzed Layout and Text Object (ALTO) 4.2 schema specifications at </hi>
                        <ref target=""https://www.loc.gov/standards/alto/news.html#4-2-released"">
                            <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://www.loc.gov/standards/alto/news.html#4-2-released</hi>
                        </ref>
                    </p>
                </note> or PAGE (Pletschacher & Antonacopoulos, 2010) are commonly used by transcription software to export the output, but we advocate for a change of paradigm in order to give more importance to TEI earlier in the workflow (Scheithauer et al., 2020). The TEI guidelines define a set of elements to document this type of data, namely “sourceDoc” and its children
                <note place=""foot"" xml:id=""ftn6"" n=""6"">
                    <p>
                        <hi style=""font-size:10pt"" xml:space=""preserve""> See </hi>
                        <ref target=""https://tei-c.org/release/doc/tei-p5-doc/en/html/ref-sourceDoc.html"">
                            <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://tei-c.org/release/doc/tei-p5-doc/en/html/ref-sourceDoc.html</hi>
                        </ref>
                    </p>
                </note>. Leveraging TEI from the start is essential to connect the metadata of the images
                <note place=""foot"" xml:id=""ftn7"" n=""7"">
                    <p>
                        Including when the images are distributed within the IIIF framework .
                    </p>
                </note> and documents, the text and layout information generated during the transcription, and any further editorial layer added to the raw transcription.
            </p>
            <table rend=""rules"">
                <row>
                    <cell rend=""center"">
                        <figure>
                            <anchor xml:id=""w9p4ioeaonwg""/>
                            <graphic n=""1001"" width=""8.466683333333334cm"" height=""6.773347222222222cm"" url=""Pictures/ab528cf602216654bc3102ca32fc9f32.png"" rend=""inline""/>
                        </figure>
                    </cell>
                </row>
                <row>
                    <cell style=""text-align: left;"">
                        <hi rend=""bold"">Fig. 1: TEI as a threefold structure.</hi>
                    </cell>
                </row>
            </table>
            <p>We imagine a configuration capable of processing a large family of TEI customizations as long as the file follows a structure (Fig. 1) in which:</p>
            <list type=""unordered"">
                <item>“teiHeader” stores the metadata,</item>
                <item>“sourceDoc” the raw transcription, and</item>
                <item>“body” the interpreted logical structure along with the editorial layers
                    <note place=""foot"" xml:id=""ftn8"" n=""8"">
                        <p>
                            <hi style=""font-size:10pt"" xml:space=""preserve""> Logical structure reconstruction can be performed semi-automatically (see the pipeline built for the LECTAUREP project called “LEPIDEMO”, </hi>
                            <ref target=""https://github.com/lectaurep/lepidemo"">
                                <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://github.com/lectaurep/lepidemo</hi>
                            </ref>
                            ), or automatically with tools such as GROBID (
                            <ref target=""https://github.com/kermitt2/grobid"">
                                <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://github.com/kermitt2/grobid</hi>
                            </ref>
                            ).
                        </p>
                    </note>.
                </item>
            </list>
            <p>We thus aggregate two phases in the digitization lifecycle which are often disconnected.</p>
            <p>Editorial operations can include preprocessing tasks such as post-HTR corrections (spell-checking) and text normalization, as well as information extraction (text mining). When the volume of data increases, extracting and linking named entities with indexes quickly risks becoming a laborious task. Instead, natural language processing tools can automate the process (Ehrmann et al., 2020; Frontini et al., 2015) all the while relying on the analysis of the sentences and words within their context. We developed 
                <hi rend=""italic"">Semantic@</hi>, a proof of concept utilizing deep learning models, to extract named entities which are then cycled back into the TEI tree (Fig. 2). The extraction of named entities (i.e. names of people, places, or dates, etc.) is a crucial step before disambiguation which further permits to build links with open general or domain-specific knowledge bases. These steps allow for later explorations of the text with data mining technologies.
            </p>
            <table rend=""rules"">
                <row>
                    <cell rend=""center"">
                        <figure>
                            <anchor xml:id=""vw6wiftzr5mh""/>
                            <graphic n=""1002"" width=""8.466683333333334cm"" height=""6.773347222222222cm"" url=""Pictures/ab528cf602216654bc3102ca32fc9f32.png"" rend=""inline""/>
                        </figure>
                    </cell>
                </row>
                <row>
                    <cell style=""text-align: left;"">
                        <hi rend=""bold"">Fig. 2: Virtuous circle for the enriched TEI document.</hi>
                    </cell>
                </row>
            </table>
            <p>Once all the layers of an edition are connected into the same TEI file, edited documents can be posted online with softwares like 
                <hi rend=""italic"">TEI Publisher</hi> (Turska et al., 2016; Chiffoleau et al., 2021). It provides a fully customizable environment where templates generate “views” based on the content of the XML files. With the aforementioned TEI structure, we propose an edition template containing:
            </p>
            <list type=""ordered"">
                <item>a flat representation of the transcription,</item>
                <item>an imitative representation of the transcription based on SVG
                    <note place=""foot"" xml:id=""ftn9"" n=""9"">
                        <p>
                            <hi style=""font-size:10pt"" xml:space=""preserve""> An XML-based markup language, see the Scalable Vector Graphics (SVG) 2 recommandations at</hi>
                            <ref target=""https://www.w3.org/TR/SVG2/"" xml:space=""preserve""> </ref>
                            <ref target=""https://www.w3.org/TR/SVG2/"">
                                <hi rend=""underline color(1155CC)"" style=""font-size:10pt"">https://www.w3.org/TR/SVG2/</hi>
                            </ref>
                            <hi style=""font-size:10pt"" xml:space=""preserve""> ; we wish to point at the fact that working with SVG when displaying transcriptions allows us to deal with different writing systems and languages.</hi>
                        </p>
                    </note> integrating the layout of the pages,
                </item>
                <item>a diplomatic edition of the source document, based on the content of the body element, and</item>
                <item>a facsimile, using the IIIF protocol (Fig. 3).</item>
            </list>
            <table rend=""rules"">
                <row>
                    <cell style=""text-align: left;"">
                        <figure>
                            <anchor xml:id=""u2c6jdtzl3ua""/>
                            <graphic n=""1003"" width=""15.573375cm"" height=""6.166555555555555cm"" url=""Pictures/98520059aeabe3a55ab1b763764bb94f.png"" rend=""inline""/>
                        </figure>
                    </cell>
                </row>
                <row>
                    <cell style=""text-align: left;"">
                        <hi rend=""bold"">Fig. 3: A mock-up showing the four different views potentially available in an application like TEI-Publisher.</hi>
                    </cell>
                </row>
            </table>
            <p>We would like to take the opportunity of presenting a short paper during the DH2022 international conference to subject our framework (Fig. 4) -and its robustness to different writing systems- to the scrutiny of the DH community. In particular, we believe that our proposition addresses challenges raised by Open Science, primarily the necessity to gain better control over every step within complex pipelines that involve various tools, thus facilitating reproducibility. A paradigm revolving around a pivotal element, like a TEI file grouping the different results, frees us from the constraint of a linear progression by maintaining multiple entry points in the workflow.</p>
            <table rend=""rules"">
                <row>
                    <cell rend=""center"">
                        <figure>
                            <anchor xml:id=""ujktn2vz6rmo""/>
                            <graphic n=""1004"" width=""8.466683333333334cm"" height=""5.926677777777778cm"" url=""Pictures/0f92db4d335c32d62aad91c344402bb2.png"" rend=""inline""/>
                        </figure>
                    </cell>
                </row>
                <row>
                    <cell style=""text-align: left;"">
                        <hi rend=""bold"">Fig. 4: Simplifying the workflow by using TEI from the beginning.</hi>
                    </cell>
                </row>
            </table>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Balogh, D. and Griffiths, A.</hi> (2020). DHARMA Encoding Guide for Diplomatic Editions EFEO ; Humboldt-Universität (Berlin) ; CEAIS - Centre d’Études de l’Inde et de l’Asie du Sud report 
                        <ref target=""https://halshs.archives-ouvertes.fr/halshs-02888186"">https://halshs.archives-ouvertes.fr/halshs-02888186</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Camps, J.-B.</hi> (2021). Gallic(orpor)a: Extraction, annotation et diffusion de l’information textuelle et visuelle en diachronie longue Paper presented at the Inauguration du BnF DataLab, Paris 
                        <ref target=""https://www.academia.edu/58990010/Gallic_orpor_a_Extraction_annotation_et_diffusion_de_l_information_textuelle_et_visuelle_en_diachronie_longue"">https://www.academia.edu/58990010/Gallic_​orpor_​a_​Extraction_​annotation_​et_​diffusion_​de_​l_​information_​textuelle_​et_​visuelle_​en_​diachronie_​longue</ref> (accessed 9 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Carius, J.-C.</hi> (2020). Plateforme d’éditions enrichies à l’INHA : Premier point d’étape d’un projet en cours d’élaboration Billet 
                        <hi rend=""italic"">Numérique et recherche en histoire de l’art</hi>
                        <ref target=""https://numrha.hypotheses.org/1107"">https://numrha.hypotheses.org/1107</ref> (accessed 8 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Causer, T., Grint, K., Sichani, A.-M. and Terras, M.</hi> (2018). ‘Making such bargain’’: Transcribe Bentham and the quality and cost-effectiveness of crowdsourced transcription. 
                        <hi rend=""italic"">Digital Scholarship in the Humanities</hi> doi:
                        <ref target=""https://doi.org/10.1093/llc/fqx064"">10.1093/llc/fqx064</ref>. 
                        <ref target=""https://academic.oup.com/dsh/advance-article/doi/10.1093/llc/fqx064/4810663"">https://academic.oup.com/dsh/advance-article/doi/10.1093/llc/fqx064/4810663</ref> (accessed 11 June 2018).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Chagué, A. and Scheithauer, H.</hi> (2021). 
                        <hi rend=""italic"">LEPIDEMO, a Pipeline Demonstrator for LECTAUREP to Go from EScriptorium to TEI-Publisher</hi>. Jupyter Notebook doi:
                        <ref target=""https://doi.org/10.5072/zenodo.977657"">10.5072/zenodo.977657</ref>. 
                        <ref target=""https://github.com/lectaurep/lepidemo"">https://github.com/lectaurep/lepidemo</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Chiffoleau, F., Baillot, A. and Ovide, M.</hi> (2021). A TEI-based publication pipeline for historical egodocuments -the DAHN project. 
                        <hi rend=""italic"">Next Gen TEI, 2021 - TEI Conference and Members’ Meeting</hi>. Virtual, United States 
                        <ref target=""https://hal.archives-ouvertes.fr/hal-03451421"">https://hal.archives-ouvertes.fr/hal-03451421</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Clanuwat, T., Lamb, A. and Kitamoto, A.</hi> (2019). KuroNet: Pre-Modern Japanese Kuzushiji Character Recognition with Deep Learning. 
                        <hi rend=""italic"">ArXiv:1910.09433 [Cs]</hi>
                        <ref target=""http://arxiv.org/abs/1910.09433"">http://arxiv.org/abs/1910.09433</ref> (accessed 8 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">e-editiones</hi> (2021). 
                        <hi rend=""italic"">Eeditiones/Tei-Publisher-App</hi>. XQuery e-editiones.org 
                        <ref target=""https://github.com/eeditiones/tei-publisher-app"">https://github.com/eeditiones/tei-publisher-app</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Ehrmann, M., Romanello, M., Flückiger, A. and Clematide, S.</hi> (2020). Extended Overview of CLEF HIPE 2020: Named Entity Processing on Historical Newspapers. 
                        <hi rend=""italic"">CLEF 2020 Working Notes. Conference and Labs of the Evaluation Forum</hi>. [online event]: Zenodo doi:
                        <ref target=""https://doi.org/10.5281/ZENODO.4117566"">10.5281/ZENODO.4117566</ref>. 
                        <ref target=""https://zenodo.org/record/4117566"">https://zenodo.org/record/4117566</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Frontini, F., Brando, C. and Ganascia, J.-G.</hi> (2015). Semantic Web Based Named Entity Linking for Digital Humanities and Heritage Texts. In Zucker, A., Draelants, I., Zucker, C. F. and Monnin, A. (eds), 
                        <hi rend=""italic"">First International Workshop Semantic Web for Scientific Heritage at the 12th ESWC 2015 Conference</hi>. Portorož, Slovenia: Arnaud Zucker and Isabelle Draelants and Catherine Faron Zucker and Alexandre Monnin 
                        <ref target=""https://hal.archives-ouvertes.fr/hal-01203358"">https://hal.archives-ouvertes.fr/hal-01203358</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Kahle, P., Colutto, S., Hackl, G. and Mühlberger, G.</hi> (2017). Transkribus - A Service Platform for Transcription, Recognition and Retrieval of Historical Documents. 
                        <hi rend=""italic"">14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</hi>, vol. 04. pp. 19–24 doi:
                        <ref target=""https://doi.org/10.1109/ICDAR.2017.307"">10.1109/ICDAR.2017.307</ref>.
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Kiessling, B.</hi> (2021). 
                        <hi rend=""italic"">Mittagessen/Kraken</hi>. Python 
                        <ref target=""https://github.com/mittagessen/kraken"">https://github.com/mittagessen/kraken</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Lopez, P.</hi> (2008). 
                        <hi rend=""italic"">GROBID</hi>. Java 
                        <ref target=""https://github.com/kermitt2/grobid"">https://github.com/kermitt2/grobid</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Pletschacher, S. and Antonacopoulos, A.</hi> (2010). The PAGE (Page Analysis and Ground-truth Elements) format framework. pp. 257–60 doi:
                        <ref target=""https://doi.org/10.1109/ICPR.2010.72"">10.1109/ICPR.2010.72</ref>.
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Sánchez, J. A., Romero, V., Toselli, A. H., Villegas, M. and Vidal, E.</hi> (2017). ICDAR2017 Competition on Handwritten Text Recognition on the READ Dataset. IEEE Computer Society, pp. 1383–88 doi:
                        <ref target=""https://doi.org/10.1109/ICDAR.2017.226"">10.1109/ICDAR.2017.226</ref>. 
                        <ref target=""https://www.computer.org/csdl/proceedings-article/icdar/2017/3586b383/12OmNy4IEXJ"">https://www.computer.org/csdl/proceedings-article/icdar/2017/3586b383/12OmNy4IEXJ</ref> (accessed 9 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Scheithauer, H., Chagué, A., Gabay, S., Romary, L., Janes, J. and Jahan, C.</hi> (2021). From page to content – which TEI representation for HTR output?. 
                        <hi rend=""italic"">Next Gen TEI, 2021 - TEI Conference and Members’ Meeting</hi>. Weaton (virtual), United States 
                        <ref target=""https://hal.archives-ouvertes.fr/hal-03380807"">https://hal.archives-ouvertes.fr/hal-03380807</ref> (accessed 7 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Seaward, L.</hi> (2017). Project Update – teaching a computer to READ Bentham 
                        <hi rend=""italic"">UCL Transcribe Bentham</hi>
                        <ref target=""http://blogs.ucl.ac.uk/transcribe-bentham/2017/06/09/project-update-teaching-a-computer-to-read-bentham/"">http://blogs.ucl.ac.uk/transcribe-bentham/2017/06/09/project-update-teaching-a-computer-to-read-bentham/</ref> (accessed 4 June 2018).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Stern, R.</hi> (2013). Identification automatique d’entités pour l’enrichissement de contenus textuels Université Paris-Diderot - Paris VII phdthesis 
                        <ref target=""https://tel.archives-ouvertes.fr/tel-00939420"">https://tel.archives-ouvertes.fr/tel-00939420</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Stokes, P. A., Kiessling, B., Ezra, D. S. B., Tissot, R. and Gargem, E. H.</hi> (2021a). The eScriptorium VRE for Manuscript Cultures. 
                        <hi rend=""italic"">Classics@ Journal</hi>. [online] 
                        <ref target=""https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-gargem/"">https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-gargem/</ref> (accessed 30 November 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Stokes, P. A., Kiessling, B., Ezra, D. S. B., Tissot, R. and Gargem, E. H.</hi> (2021b). The eScriptorium VRE for Manuscript Cultures. 
                        <hi rend=""italic"">Classics@ Journal</hi>. [online] 
                        <ref target=""https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-gargem/"">https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-gargem/</ref> (accessed 30 November 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Terriel, L.</hi> (2021). 
                        <hi rend=""italic"">Semantic@</hi>. Python 
                        <ref target=""https://github.com/Lucaterre/semanticat"">https://github.com/Lucaterre/semanticat</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Tissot, R.</hi> (2021). 
                        <hi rend=""italic"">Scripta/EScriptorium</hi>. Python 
                        <ref target=""https://gitlab.com/scripta/escriptorium/-/tree/v0.10.2a"">https://gitlab.com/scripta/escriptorium/-/tree/v0.10.2a</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Turska, M., Cummings, J. and Rahtz, S.</hi> (2016). Challenging the Myth of Presentation in Digital Editions. 
                        <hi rend=""italic"">Journal of the Text Encoding Initiative</hi>(Issue 9). Text Encoding Initiative Consortium doi:
                        <ref target=""https://doi.org/10.4000/jtei.1453"">10.4000/jtei.1453</ref>. 
                        <ref target=""https://journals.openedition.org/jtei/1453"">https://journals.openedition.org/jtei/1453</ref> (accessed 10 December 2021).
                    </bibl>
                    <bibl rend=""Standard"" style=""text-align: justify; "">
                        <hi rend=""bold"">Yin, F., Wang, Q.-F., Zhang, X.-Y. and Liu, C.-L.</hi> (2013). ICDAR 2013 Chinese Handwriting Recognition Competition. IEEE Computer Society, pp. 1464–70 doi:
                        <ref target=""https://doi.org/10.1109/ICDAR.2013.218"">10.1109/ICDAR.2013.218</ref>. 
                        <ref target=""https://www.computer.org/csdl/proceedings-article/icdar/2013/06628856/12OmNxEBzcq"">https://www.computer.org/csdl/proceedings-article/icdar/2013/06628856/12OmNxEBzcq</ref> (accessed 9 December 2021).
                    </bibl>
                    <bibl>
                        <ref target=""https://gitlab.com/scripta/escriptorium/-/tree/v0.10.2a"">
                            <hi rend=""underline color(1155CC)"">https://gitlab.com/scripta/escriptorium/-/tree/v0.10.2a</hi>
                        </ref>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,automatic text recognition;natural language processing;open science;reproducible methodology;tei,English,"computer science;contemporary;data publishing projects, systems, and methods;english;global;humanities computing;text encoding and markup language creation, deployment, and analysis"
11988,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Multilinguals Write Back: Modeling Language, Politics and Identity in Philippine Social Media",,Frances Antoinette Cruz;Mike Kestemont,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p rend=""DH-Heading1"">Research problem statement</p>
            <p>This paper documents the intersections of language and the public sphere through a cross-sectional model of comments on public Facebook (FB) pages of selected newspapers from 2015-2019. The analysis examines language use in discussions of current events, differences between national and regional newspapers, and social media insights into the conduct of public discourse. A common observation in the Philippines is, while English is used for official documents, tertiary education, and national broadsheets, oral discussions tend to involve Filipino or regional languages (Gonzalez, 1998). Class and political differences are also heavily associated with language use and media preferences (Kusaka 2017). Social media, with its informal written language, yet socially and politically relevant content, may thus offer insights into contemporary language use and public engagement with media.</p>
            <p rend=""DH-Heading1"">Methodology</p>
            <p>Comments on public FB pages of selected national and regional newspapers (
                <hi rend=""italic"">Manila Bulletin</hi>, 
                <hi rend=""italic"">Manila Times</hi>, 
                <hi rend=""italic"">Philippine Daily Inquirer</hi>, 
                <hi rend=""italic"">Philippine Star</hi>, 
                <hi rend=""italic"">Cebu Daily News</hi>, 
                <hi rend=""italic"">Mindanews</hi>, 
                <hi rend=""italic"">Mindanao Times</hi>, 
                <hi rend=""italic"">Sun Star Cebu</hi>, 
                <hi rend=""italic"">Sun Star Davao</hi>, and 
                <hi rend=""italic"">The Freeman</hi>) were captured through 
                <hi rend=""italic"">Facepager</hi> (Jünger & Keyling 2019). The corpus is taken from a separate project on Muslim identities in the Philippines and consists of data from selected months in 2015, 2017, and 2019.
            </p>
            <p>While language identification is a common task in natural language processing, most of the available software casts this as a multi-class classification task, where only a single language can be assigned to a textual document. In the present case, involving code-switching as a signature feature, multiple languages can be simultaneously present in a document, thus turning this task effectively into a multilabel classification problem. We finetuned a bespoke multilabel classifier on top of a pretrained BERT (Devlin et al., 2019) feature extractor (the ‘bert-base-multilingual-uncased’ model). We only considered messages where the target language(s) could be identified and divided these into a train, validation and test set of 10,000 social media messages (containing 7,304, and 2 x 913 instances respectively). We manually annotated for the presence/absence of Tagalog/Filipino, Cebuano, and English respectively. We compared the performance of this SOTA approach to a simpler baseline, consisting of a conventional multitarget classifier in the form of a random forest (RF) (Pedregosa et al., 2011) of 16,156 manually annotated entries (with a train, validation and test set of 12,998 entries, and 2 x 2,294 instances), trained on top of a TF-IDF representation of a vocabulary character n-grams (for 2 ≤ n ≤ 6) (see details Table 2 below). Finally, we applied the BERT language detector (with the weights that optimized the validation performance) to the unseen data.</p>
            <figure>
                <graphic n=""1001"" width=""16.51cm"" height=""12.767027777777777cm"" url=""Pictures/a78132cd8e7aedacc7882e711a4a99a2.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">
                <hi rend=""italic"">Table 1</hi> – Number of entries per language in Test, Train and Validation Sets
            </p>
            <figure>
                <graphic n=""1002"" width=""16.51cm"" height=""6.058958333333333cm"" url=""Pictures/d4f50e63a4596d8df7d73984fb711076.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">
                <hi rend=""italic"" xml:space=""preserve"">Table 2 </hi>– Test Accuracies
            </p>
            <p rend=""DH-Heading1"">Findings</p>
            <p>Both classifiers were able to demonstrate similar general trends: Tagalog/Filipino entries were the most common overall (Figures 1 and 2). Regionally, more diverse language use is noticeable. Cebuano comments were prominent in at least two Cebu-based newspapers, while the Mindanao Times and Sun Star Davao featured Tagalog/Filipino as the most-used language, followed by English and Cebuano (Figures 3 and 4), suggesting the usage of Tagalog/Filipino even where Visayan languages are prominent. Despite the presence of monolingual English-language newspapers, the fact that current events are 
                <hi rend=""bold"">written about</hi> and responded to by a multilingual Philippine public sphere is often obscured. Social media thus offers opportunities not only for re-thinking monolingual norms in media, but may also act as a forum for revitalizing written forms of regional languages, while acting as a potent corpus and resource for codeswitching and informal written language for automatic language identifiers. 
            </p>
            <figure>
                <graphic n=""1003"" width=""16.002cm"" height=""10.16cm"" url=""Pictures/2cdae206e88ba36526f21f63f66ed5b2.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">Fig. 1 – Language Use (BERT)</p>
            <figure>
                <graphic n=""1004"" width=""16.002cm"" height=""9.958916666666667cm"" url=""Pictures/388e0103a0f2124ffa217b7df18d7abe.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">Fig. 2 – Language Use (RF)</p>
            <figure>
                <graphic n=""1005"" width=""16.51cm"" height=""7.796388888888889cm"" url=""Pictures/79a7b5790618d78eef70d453f8a45b22.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">Fig. 3 – Languages per Newspaper (BERT)</p>
            <figure>
                <graphic n=""1006"" width=""16.51cm"" height=""7.549444444444444cm"" url=""Pictures/e1a12a1c363b4b20a5323f8e72d50c48.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: center;"">Fig. 4 – Languages per Newspaper (RF)</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Devlin, J., Chang, M.-W., Lee, K. and Toutanova, K.</hi> (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. 
                        <hi rend=""italic"">Proceedings of NAACL-HLT</hi>, Minneapolis, MN, June 2019, pp. 4171–4186.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Gonzalez, A.</hi> (1998). The Language Planning Situation in the Philippines. 
                        <hi rend=""italic"">Journal of Multilingual and Multicultural Development</hi>, 
                        <hi rend=""italic bold"">19</hi>(5 & 6): 487–525.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Jünger, J. and Keyling, T.</hi> (2019). 
                        <hi rend=""italic"">Facepager: An application for automated data retrieval on the web</hi>.
                        <ref target=""https://github.com/strohne/Facepager/"" xml:space=""preserve""> </ref>
                        <ref target=""https://github.com/strohne/Facepager/"">
                            <hi rend=""underline color(1155CC)"">https://github.com/strohne/Facepager/</hi>
                        </ref> (accessed April 7 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Kusaka, W.</hi> (2017). 
                        <hi rend=""italic"">Moral Politics in the Philippines</hi>. Singapore/Japan: NUS Press & Kyoto University Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Bertrand, T., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., David Cournapeau, Brucher, M., Perro, M., and Duchesnay, E.</hi> (2011). Scikit-learn: Machine Learning in Python. 
                        <hi rend=""italic"">Journal of Machine Learning Research</hi>, 
                        <hi rend=""bold"">12</hi>: 2825–2830.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,media;multilingualism;philippines;social media,English,artificial intelligence and machine learning;asia;asian studies;contemporary;english;linguistics;social media analysis and methods
11991,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Everyday memory: A computational analysis of changing relation between past and present in Dutch newspapers in the twentieth Century,,Pim Huijnen,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">Historians have since long stressed the political and cultural functions of memory and heritage for societies. The more born-digital data have a past of their own, the more memory has also become a topic of interest for data scientists (Au Yeung and Jatowt 2011, Keegan and Brubaker 2015, Graus et.al. 2018, West and Leskovec 2021). Stringently connected to memory but much less studied in data science is our experience of time (Jatowt et.al. 2015 and Van Eijnatten and Huijnen 2021 being notable exceptions). The influential theory of François Hartog, for example, explains the memory boom from the establishment of a ‘time regime of the present’ at the end of the 1980s (Hartog 2015). Aleida Assmann goes against Hartog’s subsequent assertion that an increasingly shorter present is all we are left with (Assmann 2020, 139). Instead, she puts forward her notion of cultural memory to replace ideas of temporal ruptures with a model that ‘emphasizes the ineluctable entanglement of [past, present and future]’ (Assmann 2020, 195-6). </p>
            <p style=""text-align: left; "">Departing from this theory, this study proposes a computational approach to study the relation between the present and the past in twentieth century newspapers by analysing trends in phrases of the format ‘n years ago’. Obviously, there is a plethora of ways in language can evoke the past. However, there are two arguments that justify singling out ‘n years ago’. First, ‘n years ago’ is, as an expression, ubiquitous and syntactically stable in Dutch newspaper language throughout the studied period of the twentieth century. Second, unlike explicit references to years, events or persons in the past, ‘n years ago’ intricately ties the past to the present. The phrase presents the past—and keeps it present—
                <hi rend=""italic"">as something useful for the present</hi>. This notion of ‘useful past’ or ‘present past’ (Paul 2015, 25-27) forms part of Assmann’s critique of Hartog’s theory of temporal orders. 
            </p>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Questions and method</head>
                <p style=""text-align: left; "">The questions that are at the center of this study are how trends in references to present pasts relate to named philosophies of time experience, but also which past remains present and how these trends change over time. It takes newspapers as data, because of the vital role they as the ‘first rough draft of history’ have played in memory culture throughout the twentieth century. This study is based on the digitized versions of the most important nation-wide and regional newspapers the Dutch National Library holds and has made available.
                    <note place=""foot"" xml:id=""ftn1"" n=""1"">
                        <p style=""text-align: left; "">
                            <ref target=""http://www.delpher.nl/kranten"">
                                www.delpher.nl/kranten
                            </ref>
                            <hi style=""font-size:10pt"" xml:space=""preserve"">. </hi>
                        </p>
                    </note> The preliminary results presented here are based on the example of the national newspaper Telegraaf (1893-1989) of 10,000 documents (articles and advertisements) per year.
                    <note place=""foot"" xml:id=""ftn2"" n=""2"">
                        <p style=""text-align: left; "">
                            For the final paper, these titles will be complemented with other available newspaper titles with similar century-spanning scopes. Subsequently, all results will be aggregated to come to an encompassing picture of the present past in Dutch newspapers by means of references to ‘n years ago’. The Telegraaf was chosen as an example here, because it shows trends that are paradigmatic for most other newspapers.
                        </p>
                    </note> These documents have been rid of duplicates and cleaned with the help of Python’s NLTK package.
                    <note place=""foot"" xml:id=""ftn3"" n=""3"">
                        <p style=""text-align: left; "">
                            <ref target=""https://github.com/PimHuijnen/looking_back_newspapers"">
                                https://github.com/PimHuijnen/looking_back_newspapers
                            </ref>
                            . Cleaning in this script is mostly restricted to the removal of punctuation and caps. Stop words are not removed to guarantee that the Dutch word for the English indefinite article ‘a’ (‘een’), which is part of any standard stop word list, remains part of the data. Similarly, the removal of numbers is no part of preprocessing to allow for phrases like ’10 years ago’(even though Dutch linguistic convention formally does not allow for numbers in running text).
                        </p>
                    </note>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Analysis and results</head>
                <p style=""text-align: left; "">The analysis is done with Python scripts in Jupyter Notebooks and consists of three subsequent steps: </p>
                <p style=""text-align: left; "">The first step is the extraction of a list of the most common trigrams ending with ‘year(s) ago’
                    <note place=""foot"" xml:id=""ftn4"" n=""4"">
                        <p style=""text-align: left; "">
                            <hi style=""font-size:10pt"" xml:space=""preserve""> The Dutch equivalent of ‘year(s) ago’ is for both one and more years written in the singular form ‘jaar geleden’.</hi>
                        </p>
                    </note> from the cleaned and sampled dataset. This list is sorted by decade and by frequency to get an idea of the years that newspapers most often use in the phrase ‘n years ago’ throughout the twentieth century. This indicates that single digit years (one – nine) make up the most common phrases of ‘n years ago’, along with decades (ten, twenty, etc.) and one hundred.
                </p>
                <p style=""text-align: left; "">
                    <hi rend=""italic"" style=""font-size:10pt"">Table 1: Most common trigrams ending in ‘year(s) ago’ with their English translation from a sample of 10,000 documents from the national newspaper De Telegraaf per decade per million trigrams, 1890-1980.</hi>
                </p>
                <table rend=""rules"" n=""span_all"">
                    <note type=""direction"">
                        <width unit=""pt"">92</width>
                        <width unit=""pt"">92</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                        <width unit=""pt"">32</width>
                    </note>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Trigram</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">English translation</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1890</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1900</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1910</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1920</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1930</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1940</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1950</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1960</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1970</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1980</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Een jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">One year ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,95</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">4,02</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">4,62</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">8,81</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">21,77</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">13,23</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">16,06</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">19,51</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">17,90</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">16,16</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Twee jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Two years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,70</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,10</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,70</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,18</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">7,51</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">5,60</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">12,67</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">22,43</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">27,79</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">31,44</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Twintig jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Twenty years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,27</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,50</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,59</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,34</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,28</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">4,24</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,39</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,34</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">4,07</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">6,08</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Paar jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Few years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,10</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,26</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,06</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,50</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,53</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,39</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,74</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">7,05</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">9,22</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">10,01</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Vier jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Four years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,76</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,17</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,53</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,20</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,48</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,36</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,39</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">7,37</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">10,85</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">11,99</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Drie jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Three years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,68</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,26</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,06</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,86</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,54</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,88</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">6,22</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">11,08</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">14,50</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">14,75</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Dertig jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Thirty years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,59</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,42</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,26</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,72</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,86</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,71</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,42</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,92</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,89</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,09</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Tien jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">Ten years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,51</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,01</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,79</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,80</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">4,16</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">4,24</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">5,25</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">9,54</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">12,39</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">15,42</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Honderd jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">One hundred years ago</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,42</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,50</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,73</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,14</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,08</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,54</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,86</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,86</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,02</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,98</cell>
                    </row>
                    <row>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Acht jaar geleden
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">
                            Eight years ago
                        </cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,42</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,25</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,20</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,60</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,91</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">0,85</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">1,05</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">2,97</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,20</cell>
                        <cell style=""text-align: left;"" rend=""DH-Default"">3,59</cell>
                    </row>
                </table>
                <p style=""text-align: left; "">In a second step, the most common references of ‘n years ago’ are plotted, relative to one another, over time. Figures 1-3 show the trajectories of all single years together (figure 1), of all decades from ten to one hundred (figure 2) and of the single years one, ten, one hundred and two hundred (figure 3). These figures show that Dutch newspapers started to look back in time by the use of the phrase ‘n years ago’ since the 1930s. Once they did, the use of some variations of this phrase strongly gained traction, particularly in reference to the near past (one to ten years ago). </p>
                <p style=""text-align: left; "">The final step of the analysis is to look at the actual years that the phrase ‘n years ago’ referred to throughout the twentieth century. Do newspapers tend to look back at specific years, as in the end of the Second World War being ‘five years ago’ in 1950? Or are ‘notable’ years submerged in what is here called ‘everyday memory culture’? The latter seems to be the case if these years are calculated for ‘n years ago’, where n stands for the years from one to twenty and decades from twenty to two hundred. Figure 5 shows that ‘n years ago’ tends to evoke the recent past itself above any particular year. No single year really stands out.
                    <note place=""foot"" xml:id=""ftn5"" n=""5"">
                        <p rend=""footnote text""> Given the nature of this method, the decline in the frequency of years after 1975 that Figure 5 shows is as necessary as it is meaningless. There is, after all, increasingly less data (that ends in 1989) on which these numbers can be based. </p>
                    </note>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Conclusion</head>
                <p style=""text-align: left; "">In the light of Hartog’s theory of an all-encompassing present, one would have expected a steady decrease of references to the past and the future. This study shows the opposite and substantiates Assmann’s contention that interest for the past returns, particularly in the second half of the twentieth century, in the form of memory culture. With the growing popularity of the studied phrase, Dutch newspapers became mediators of a form of memory culture than can be seen as ‘latent’ or ‘everyday’ in that it emphasizes recurring events rather than returning to a specific thing in the past. This is, particularly, true for the phrases ‘two years ago’ and ‘four years ago’ (Figure 4), the spikes in the diagrams of which indicate references to important sport (Olympics, European and World Championship soccer) and political events (national parliamentary elections).</p>
                <p style=""text-align: left; "">The use of the phrase ‘n years ago’ is by no means the only, nor the most important manifestation of memory culture. This limits the explanatory power of this study. In contrast with official and cultivated forms of memory culture, however, it does shed light on the latent, almost oblique, everyday invocation of the past that forms just as much part of that culture.</p>
                <p style=""text-align: left; "">
                    <hi rend=""italic"" style=""font-size:10pt"" xml:space=""preserve"">Figure 1: Frequency over time of ‘n years ago’, where n stands for one to ten, per million words in a sample of 10,000 documents per year of the national newspaper </hi>
                    De Telegraaf
                    <hi rend=""italic"" style=""font-size:10pt"">, 1893-1989. For similar diagrams (figures 1-4) for other newspapers, see: https://github.com/PimHuijnen/looking_back_newspapers/tree/main/Data.</hi>
                </p>
                <figure>
                    <graphic n=""1001"" url=""Pictures/eaf204fb81e915b310257effe2586912.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">
                    <hi rend=""italic"" style=""font-size:10pt"" xml:space=""preserve"">Figure 2: Frequency over time of ‘n years ago’, where n stands for decades from ten to one hundred, per million words in a sample of 10,000 documents per year of the national newspaper </hi>
                    De Telegraaf
                    <hi rend=""italic"" style=""font-size:10pt"">, 1893-1989.</hi>
                </p>
                <figure>
                    <graphic n=""1002"" url=""Pictures/93ee9a8fb8797bc28dc8571c2ddd5578.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">
                    <hi rend=""italic"" style=""font-size:10pt"" xml:space=""preserve"">Figure 3: Frequency over time of ‘n years ago’, where n stands for one, ten, one hundred and two hundred, per million words in a sample of 10,000 documents per year of the national newspaper </hi>
                    De Telegraaf
                    <hi rend=""italic"" style=""font-size:10pt"">, 1893-1989.</hi>
                </p>
                <figure>
                    <graphic n=""1003"" url=""Pictures/1afe63690720d69de7c7200153283a75.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">
                    <hi rend=""italic"" style=""font-size:10pt"" xml:space=""preserve"">Figure 4: Frequency over time of ‘four years ago’ per million words in a sample of 10,000 documents per year of the national newspaper </hi>
                    De Telegraaf
                    <hi rend=""italic"" style=""font-size:10pt"">, 1893-1989.</hi>
                </p>
                <figure>
                    <graphic n=""1004"" url=""Pictures/4f02ccdd9b8814188633c82db6643ee2.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">
                    <hi rend=""italic"" style=""font-size:10pt"" xml:space=""preserve"">Figure 5: Frequency over time of dates (in years) that are referred to via the phrase ‘n years ago’, where n stands for years from one to twenty and decades from twenty to two hundred, per million words in a sample of 10,000 documents per year of the national newspaper </hi>
                    De Telegraaf
                    <hi rend=""italic"" style=""font-size:10pt"">, 1893-1989.</hi>
                </p>
                <figure>
                    <graphic n=""1005"" url=""Pictures/77af8cf0e722e1b0f579b8ee1a833960.png"" rend=""inline""/>
                </figure>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Assmann, Aleida</hi> (2020). 
                        <hi rend=""italic"" xml:space=""preserve"">Is Time out of Joint? On the Rise and Fall of the Modern Time Regime. </hi>Ithaca: Cornell University Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Au Yeung, Ching-man and Jatowt, Adam</hi> (2011). 
                        <hi rend=""italic"">Studying how the Past is Remembered: Towards Computational History through Lare Scale Text Mining</hi>. 
                        <hi rend=""italic"">Proceedings of the 20</hi>
                        <hi rend=""italic superscript"">th</hi>
                        <hi rend=""italic"" xml:space=""preserve""> ACM International Conference on Information and Knowledge Management</hi>, 1231-1240. DOI: 
                        <ref target=""https://doi.org/10.1145/2063576.2063755"">https://doi.org/10.1145/2063576.2063755</ref>. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Eijnatten, Joris van and Pim Huijnen</hi> (2021). Something Happened to the Future: Reconstructing Temporalities in Dutch Parliamentary Debate, 1814-2018. 
                        <hi rend=""italic"">Contributions to the History of Concepts</hi>, 16: 52-82. DOI: 
                        <ref target=""https://doi.org/10.3167/choc.2021.160204"">https://doi.org/10.3167/choc.2021.160204</ref>. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Graus, David, Daan Odijk and Maarten de Rijke</hi> (2018). The Birth of Collective Memories: Analyzing Emerging Entities in Text Streams. 
                        <hi rend=""italic"">Journal of the Association for Information Science and Technology</hi>, 69: 773-786. DOI: 
                        <ref target=""http://dx.doi.org/10.1002/asi.24004"">http://dx.doi.org/10.1002/asi.24004</ref>. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Hartog, François</hi> (2015). 
                        <hi rend=""italic"">Regimes of Historicity: Presentism and Experiences of Time.</hi> New York: Columbia University Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jatowt, Adam et.al.</hi> (2015). Mapping Temporal Horizons: Analysis of Collective Future and Past related Attention in Twitter. 
                        <hi rend=""italic"">WW ’15: Proceedings of the 24</hi>
                        <hi rend=""italic superscript"">th</hi>
                        <hi rend=""italic"" xml:space=""preserve""> International Conference on World Wide Web</hi>, 484-494. DOI: 
                        <ref target=""http://dx.doi.org/10.1145/2736277.2741632"">http://dx.doi.org/10.1145/2736277.2741632</ref>. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Keegan, Brian C. and Jed R. Brubaker</hi> (2015). ”Is” to “Was”: Coordination and Commemoration in Posthumous Activity on Wikipedia Biographies. 
                        <hi rend=""italic"">Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing,</hi> 533-546. DOI: 
                        <ref target=""https://doi.org/10.1145/2675133.2675238"">https://doi.org/10.1145/2675133.2675238</ref>. 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Paul, Herman</hi> (2015). 
                        <hi rend=""italic"" xml:space=""preserve"">Key Issues in Historical Theory. </hi>New York and London: Routledge.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">West, Robert, Jure Leskovec and Christopher Potts</hi> (2021). Postmortem Memory of Public Figures in News and Social Media. 
                        <hi rend=""italic"">Proceedings of the National Academy of Science</hi> 118. DOI: 
                        <ref target=""https://doi.org/10.1073/pnas.2106152118"">https://doi.org/10.1073/pnas.2106152118</ref>. 
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,memory;newspapers;text mining;time,English,20th century;cultural analytics;english;europe;history;north america;text mining and analysis
11996,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,On Digitizing Historic Music Storage Media For Computational Analysis,,Richard Khulusi;Heike Fricke;David Fuhry;Vera Piontkowitz;Josef Focht,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction </head>
                <p>Between 2018 and 2020, the digitization project TASTEN, funded by the German
                    government, digitized 3200 piano rolls for self-playing pianos preserved at the
                    Musical Instruments Museum at Leipzig University (MIMUL). A piano roll is a historic
                    music storage media (MSM) coding movement impulses through holes punched into
                    paper (Focht, 2020). When played, a pneumatic system uses this code to create
                    sounds at runtime.
                    For musicologists, such piano rolls are of high value. First, they are the only source of
                    musical performances by famous pianists in times preceding sound recording
                    technologies. Secondly, for researchers they offer a rich repository to study the
                    music-making practice and musical interpretation around 1900. We expand our prior
                    source catalogue to include their technical predecessors: Cardboard and metal plates,
                    which also use punched holes as code (Focht, 2021). They share the issue of being
                    fragile – after decades of usage and storage – making it important to digitize them
                    for preservation, also.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Related Work </head>
                <p>We found a lack of publications dealing with challenges, issues, and processing of MSM in general. This may be due to most of such projects being on a small scale in
                    private settings (pianola.co.nz, 2021; IAMMP, 2021). Scientific publications are
                    presented by Debrunner (2013), who developed a scanner capable of reading
                    information directly from piano rolls and dealing with paper based distortion issues,
                    for a single format (Welte piano rolls). Shi et al. (2019) built an online database of almost 500 digitized
                    piano rolls offering representations including images, audios, and MIDI files, focusing
                    only on the same format.
                    No published scientific or private projects are to be found concerning metal or
                    cardboard plates and their digitization.
                </p>
                <figure>
                    <graphic n=""1001"" width=""15.980833333333333cm"" height=""9.233958333333334cm"" url=""Pictures/6892e6f7baf681be247f60f5399a989f.png"" rend=""inline""/>
                </figure>
                <p rend=""Subtitle"" style=""text-align: center; "">Figure 1: Pipeline of the digitizing of piano rolls and plates through different processing steps and manual input of a Musicologist</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Digitizing MSM</head>
                <p>While prior projects show great results in digitizing piano rolls, processes capable of
                    dealing with multiple formats of piano rolls and plates in general are non-existent.
                    Furthermore, digitizing is only the first step for musicologists. This data allows them
                    to answer research questions by reading and hearing the encoded works which are
                    difficult to impossible to read. Additionally, these processes allow for distant reading
                    analysis and comparative approaches.
                    We propose a workflow (Figure~1) capable of digitizing all 3,200 piano rolls of 30
                    different formats available in the MIMUL. Currently, work is done to include more
                    than 25 formats of 438 plates.
                    The workflow begins with a conservator-led cleaning process to protect the objects
                    and the researchers. Damages which would lead to the destruction of the object
                    were documented. Next, metadata like weight, measurements, format, title,
                    composer, and performer was extracted to be included in our research tool
                    musiXplora. For the actual digitizing, a scanning company was commissioned, for which we constructed an unwinding mechanism, making it possible to create a single
                    scan of the piano rolls (as 300dpi .tif images, resulting in up to 5.000x550.000 pixels and up to 5GB).
                    While the prior project (TASTEN – 2018-2020) generated scans of piano rolls, the
                    current DISKOS project focuses more deeply on musicologists’ research questions.
                    Examples would be “How did composers play their own compositions on the piano?”,
                    or “Can the computer use this digital knowledge to identify which pianist played a
                    piano roll of unknown origin?” Also, exploration and visual analysis of the objects can
                    be offered through distant reading visualization systems embedded in the
                    musiXplora.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Technical Details</head>
                <p>Starting with the preprocessing of the backlit images the actual process labels
                    connected components (musical notes) on the image and applies filtering to keep
                    only the components representing notes. Calculating the distance from each hole to
                    the edge of the medium and using mean shift clustering we can assign each note to
                    its respective track. We finally apply corrections to account for empty tracks and
                    distortions and calculate the position and width of each hole. Combining this
                    information with an expert created mapping of tracks to MIDI notes, we can then
                    generate a MIDI file accurately representing the information on the medium.
                    Relevance for Musicology
                    These files allow users to work interactively with the music and help musicologists in
                    their work with these sources. Furthermore, this offers an enhanced experience for
                    museum visitors, by making it possible to voice the digitized piano rolls and plates
                    using the digital representation of keyboard instruments created during TASTEN.
                    Hence, historic media can be experienced on historic instruments even if the physical
                    instruments would not have been interoperable.
                    For the musicologists, these results offer a way to open up previously unreadable
                    sources. Besides close reading approaches, the generated data allows for distant
                    reading (visualization) methodology and novel research questions like examining
                    which schools of interpretation and playing techniques are represented and how they
                    have spread between performers. 
                    Further, these results are also important for educational and playful aspects like
                    listening to these historical virtuous interpretations without risking the media and
                    instruments.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Limitations</head>
                <p>As we are in the first of three project years, some challenges still exist: The image
                    processing results are highly dependable on a suitable preprocessing, which differs
                    quite a lot even between different formats of the same media type. Metal plates in
                    particular are operated under pressure during playback. While the playback
                    instruments themselves are constructed to negate this deformation, a plain
                    photography of the media does not lead to correct results and needs a semi-manual
                    correction process. In general, we are content with our results for cardboard plates
                    and piano rolls of specific formats, but are aware of needed improvements.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Conclusion</head>
                <p>Even with the best preservation techniques, most materials deteriorate from
                    humidity and stress through time. Hence, valuable information stored on analog
                    media is prone to damage and even loss. Such information includes original
                    recordings of famous virtuosos like Edvard Grieg, not only valuable as music
                    recording, but also important for musicologists interested in analyzing playing
                    techniques and differences between musical notation and interpretation by their
                    composers. To allow digital processing of such media, digitization is mandatory. We
                    present a pipeline taking image sources of circular and linear played storage media
                    and creating digital representations in form of MIDI files, which then can be analyzed,
                    further processed, edited, or even played through modern and historical instruments.
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-size:13.5pt"">pianola.co.nz</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve"">(2021): Saving the Music of Yesterday. </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">http://www.pianola.co.nz/public/index.php</hi> (Accessed: 01 January 2022)
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"" xml:space=""preserve"">Comaniciu, D., & Meer, P. </hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve"">(2002). Mean shift: A robust approach toward feature space analysis. </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">IEEE Transactions on Pattern Analysis and Machine Intelligence</hi>
                        , 24(5), 603–619. https://doi.org/10.1109/34.1000236
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">Debrunner, D.</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve""> (2013). Von der Welte-Rolle zu parametrisierbaren Wiedergabe auf synthetischen Instrumenten und MIDI-fähigen Selbstspielklavieren. </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">In C. E. Hänggi & Köpp (Eds.), Recording the Soul of Music: Welte-Künstlerrollen für Orgel und Klavier als authentische Interpretationsdokumente.</hi>
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">Focht, J.</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve""> (2020). </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">MusiXplora</hi>
                        . https://musixplora.de/mxp/2002522 (Accessed 01 January 2022)
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">Focht, J.</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve""> (2021). </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">MusiXplora.</hi>
                        https://musixplora.de/mxp/2003518 (Accessed 01 January 2022)
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">IAMMP</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve"">(2021). </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">International Association of Mechanical Music Preservationalists</hi>
                        . http://www.iammp.org/ (Accessed 01 January 2022)
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve""> (2011). Scikit-learn: Machine Learning in Python. </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">Journal of Machine Learning Research</hi>
                        , 12, 2825–2830.
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">Shi, Z., Sapp, C. S., Arul, K., McBride, J., & Smith III, J. O.</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve""> (2019). Supra: Digitizing the Stanford University Piano Roll Archive. </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">In A. Flexer, G. Peeters, J. Urbano, & A. Volk (Chairs), ISMIR, Delft</hi>
                        .
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">van der Walt, S., L. Schönberger, J., Nunez-Iglesias, J., Boulogne, F., D. Warner, J., Yager, N., Gouillart, E., Yu, T.</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve""> (2014). scikit-image: Image processing in Python.</hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">PeerJ</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve""> 2:e453 https://doi.org/10.7717/peerj.453</hi>
                        </bibl>
               <bibl>
                        <hi rend=""bold"" style=""font-size:13.5pt"">The ImageMagick Development Team.</hi>
                        <hi style=""font-size:13.5pt"" xml:space=""preserve"">(2021). </hi>
                        <hi rend=""italic"" style=""font-size:13.5pt"">ImageMagick</hi>
                        . Retrieved from https://imagemagick.org (Accessed 01 January 2022)
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,digitization;historic musical storage media;midi;musicological analysis;visual analysis,English,"19th century;20th century;computer science;contemporary;data, object, and artefact preservation;english;europe;global;music and sound digitization, encoding, and analysis;musicology"
12003,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Genre Classification in English Poetry with Lexical and Prosodic Features,,Wenyi Shang;Ted Underwood,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">There has been an abundance of research on the lexical (Bergel et al., 2016) and prosodic (Anttila and Heuser, 2016) features of poetic texts. Some recent attempts such as Šeļa et al. (2020) combine the two feature sets to model the association between poetic meter and meaning. In this project, we ask how the relative importance of lexical and prosodic features vary across different forms and genres. We pose this question by classifying different categories of English poetry with lexical and prosodic features separately. Then we compare the results of the parallel experiments, to ask which categories have a stronger lexical or prosodic character.</p>
            <p style=""text-align: left; "">We collected all 37,700 English poems that are tagged with a certain “genre” from the Chadwyck-Healey Literature Collections (http://collections.chadwyck.com). (Note that our use of the term “genre” is drawn from our source; scholars might well characterize some of these genres as “forms” or “modes.”) Since many of the 44 total genres only have a few cases, we kept the poems of the top 8 genres only, which consist of 30,704 (81.44%) poems. Next, we trained a lexical classifier and a prosodic classifier and extracted features for each of them. For the lexical classifier, the features were extracted by transforming the texts into an array of word frequencies, and a grid search was conducted to select the algorithm and number of features used for classification. Optimization is achieved when the random forest algorithm and top 500 features are used. As for the prosodic classifier, we used the Python library “Poesy” (https://github.com/quadrismegistus/poesy) to obtain “foot type”, “feet number”, and “rhyme style” of each poem. Once again, the best performance is achieved when the random forest algorithm is used.</p>
            <p style=""text-align: left; "">We then conducted classification experiments based on a random train-test split (70% training vs 30% testing) and compared the performances of the two classifiers on an 8-genre classification task and a 2-class classification task, where we classified each of the top 8 forms against all others (e.g., “sonnet” vs “non-sonnet”, “ballad” vs “non-ballad”).</p>
            <figure>
                <graphic n=""1001"" width=""15cm"" height=""7.129411111111111cm"" url=""Pictures/4a2cf17902fefa29c613179a1f24d9c5.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: left; "">Figure 1. Confusion matrix of models trained with different feature sets (8-genre classification)</p>
            <p style=""text-align: left; "">In the 8-genre classification experiment, while the lexical and the prosodic classifier have similar overall performances, their results on different genres significantly differ: the lexical classifier classifies ballads and metrical psalms very well, but easily confuses heroic couplets with sonnets and epigrams, while the prosodic classifier classifies heroic couplets very well but easily confuses ballads and metrical psalms with lyrics.</p>
            <figure>
                <graphic n=""1002"" width=""15cm"" height=""10.005883333333333cm"" url=""Pictures/2024eb3f894f8d285c5e5b73f4272d10.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: left; "">Figure 2. F1 score of the classification experiments of different genres trained with different feature sets (2-class classification)</p>
            <p style=""text-align: left; "">The results of 2-class classification demonstrate a similar pattern: sonnets and heroic couplets are better distinguished from other forms when using classifiers trained with prosodic features, while ballads and metrical psalms are better distinguished from other forms when using classifiers trained with lexical features. These results preliminarily suggest that different genres are distinguished with different features: while ballads and metrical psalms are distinguished by the diction they use, sonnets and heroic couplets are defined by prosodic features.</p>
            <p style=""text-align: left; "">We also examined the performance of both classifiers on poems by different authors. Here, we used the “hold-out-one” strategy: we selected all poems by authors with at least 30 poems in the dataset and trained the classifiers with all poems except those written by an author, and tested the results on the poems written by that author.</p>
            <figure>
                <graphic n=""1003"" width=""15cm"" height=""6.953211111111111cm"" url=""Pictures/51ccec6cc6a8f2445bd7db5fa1f41292.jpg"" rend=""inline""/>
            </figure>
            <p style=""text-align: left; "">Figure 3. Performances of classifiers on poems of different poets</p>
            <p style=""text-align: left; "">In figure 3, most authors of translated works are in the bottom of the figure (their works cannot be easily classified by prosodic features). We also see preliminary evidence that there might be a correlation between poetic prominence and prosodic regularity: the prominent poets mostly appear in the upper half (their works can be well classified by prosodic features). It is likely that the prominent poets continuously stick to certain prosody conventions for each genre, while the translated poems use very different prosody in the same genre, which is understandable as prosodic pattens are easily lost in translation. The accuracy of classification with lexical features does not show a consistent pattern. However, two influential early modern authors, Spencer and Shakespeare, appear in the top-right corner (their works can be very well classified by both lexical and prosodic features), perhaps indicating that they set the standard for following authors in both the diction and prosody used in different genres.</p>
            <p style=""text-align: left; "">To further explore these observations, in the future we will further investigate the relationships between the accuracy of prediction and factors such as the date of the poem, the poets’ canonicity, and their nationality. Additionally, we will also take word order into consideration and use N-gram in supplement of single-word frequencies.</p>
            <p style=""text-align: left; "">The findings above already tell us a lot of things about the history of English poetry like the roles of lexical and prosodic features in poetry genre classification, and how such roles differ in different genres. However, the most important potential contribution of this project is to distinguish the concepts of “genre” and “form”: if some poetic categories are best identified by prosody, and others by “content” (represented by lexical features), it might be possible to disentangle “form” from other aspects of “genre.” For example, it is observed that heroic couplets and epigrams use similar diction, what distinguish them as two “genres” is their “forms”; in contrast, ballads and lyrics are in similar “forms”, and they are considered as different “genres” because of the words they use.</p>
            <p style=""text-align: left; "">This could reinforce the argument of King (2021) that “genre” operates on a larger scale than “form”. Furthermore, in addition to understanding how the transformation of poetic “forms” was related to narratives of culture (Martin, 2012), insights can also be gained on the evolution of the roles of “content” and “form” in defining “genres” of poems by different poets and in different periods and locations. While various follow-up experiments need to be done, there is preliminary evidence that the works of prominent poets tend to be close to a prosodic prototype for a genre.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Anttila, A. and Heuser, R.</hi> (2016). Phonological and Metrical Variation across Genres. In Hansson, G. Ó., Farris-Trimble, A., McMullin, K. and Pulleyblank D. (eds), 
                        <hi rend=""italic"">Proceedings of the 2015 Annual Meetings on Phonology</hi>. Washington, D.C.: Linguistic Society of America. https://doi.org/10.3765/amp.v3i0.3679
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Bergel, G., Howe, C. J. and Windram, H. F.</hi> (2016). Lines of Succession in an English Ballad Tradition: The Publishing History and Textual Descent of The Wandering Jew’s Chronicle. 
                        <hi rend=""italic"">Digital Scholarship in the Humanities</hi>, 
                        <hi rend=""bold"">31</hi>(3), 540–562.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">King, R. S.</hi> (2021). The Scale of Genre. 
                        <hi rend=""italic"">New Literary History</hi>, 
                        <hi rend=""bold"">52</hi>(2), 261–284. https://doi.org/10.1353/nlh.2021.0012
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Martin, M.</hi> (2012). 
                        <hi rend=""italic"">The Rise and Fall of Meter: Poetry and English National Culture, 1860</hi>–
                        <hi rend=""italic"">1930</hi>. Princeton: Princeton University Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Šeļa, A., Orekhov, B. and Leibov, R.</hi> (2020). Weak Genres: Modeling Association Between Poetic Meter and Meaning in Russian Poetry. In Karsdorp, F., McGillivray, B., Nerghes, A. and Wevers, M. (eds), 
                        <hi rend=""italic"">Proceedings of the Workshop on Computational Humanities Research (CHR 2020)</hi>. CEUR Workshop Proceedings, pp. 12–31.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,classification;genre;machine learning;poetry;prosody,English,15th-17th century;18th century;19th century;comparative (2 or more geographical areas);cultural analytics;english;europe;library & information science;literary studies;north america;text mining and analysis
12014,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Democratizing Poetry Corpora with Averell:,,Javier de la Rosa;Aitor Díaz;Álvaro Pérez;Salvador Ros;Elena González-Blanco,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading2"">
                <head>Introduction</head>
                <p>Broadly defined, a corpus is a collection of machine-readable texts that are somewhat representative of a particular reality of scholarly interest (McEnery et al. 2006: 5, Xiao 2012: 147). Corpus creation has been part of the research practices of linguists and philologists for decades, and it has recently entered the computer sciences via the mixture field of natural language processing (NLP). Corpora have become a key resource in the development and evaluation of computer systems that deal with language. As these approaches from NLP are being re-discovered, applied, and enriched within the computational humanities, the making of these corpora and their transformation into structured or plain digital texts is of vital importance. Just in the literary domain, there are arguably thousands of corpora available to download or query. In a comprehensive survey, Xiao (2010) describes over a hundred well-known and highly influential corpora in English and other languages. Smaller corpora for understudied or endangered languages have also recently appeared (see Scannell 2007, Ostler 2008, Cox 2011). Notably, only five corpora in these surveys contained poetry and only one of them was annotated with relevant poetic features. As newer poetic corpora with rich annotations are becoming available, we need a proper tool to uniformly access them.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading2"">
                <head>Averell</head>
                <p>Among the characteristics that should guide the building of a corpus (McEnery and Wilson, 2001; Gries and Berez, 2015), two are commonly desired: machine readability and availability to researchers. Unfortunately, even when corpora is made fully available in electronic format, it is often the case that scholars struggle to find a proper way to address their research questions using the ready-made corpora (see e.g., Xiao, 2010). In this sense, Averell is a tool that tries to lower the barrier for researchers interested in the study of multilingual poetry corpora. It provides a unified interface to query, manage, download, and merge corpora of poetic nature in multiple languages based on features relevant for poetry scansion and meter analysis. At its core, Averell is a Python library that connects existing annotated corpora in either JSON, XML, or TEI formats, and makes them available into rich CSV and JSON-lines formats that can be later converted into semantic RDF according to the POSTDATA network of ontologies (González-Blanco et al., 2020). Averell exposes a consistent programming application interface to integrate its functionalities into larger software projects, and it is also packaged as a command line tool for its direct use from the terminal.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading2"">
                <head>Granularity</head>
                <p>Averell is structured around two key aspects: the catalogue and its granularity. Each corpus defines a granularity level at which its documents can be split. All corpora support splitting by poems and lines (verses), but a line can also be split into words, and then syllables, for which metrical patterns might be provided. In some cases, stanzas, a set of structural and often semantical units within the poem, are also available. Extra information such as the lengths of verses, the amount of lines per stanza, or the type of rhymes is also added when available. This granular annotation allows scholars to merge different corpora and extract sets of poems that meet specific criteria. For example, a corpus of hendecasyllabic safic verses, or poems for a specific period only at the level of the stanza. Instances of the use of Averell to carry out studies in poetry already exist. De la Rosa et al. (2020, 2021) used Averell to create training and validation datasets to fine-tune transformers-based models and to create rule-based systems to a metrical prediction task.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading2"">
                <head>Catalogue</head>
                <p>The current catalogue in Averell (Table 1) contains corpora in Czech, English, French, Italian, Portuguese, and Spanish. A total of 12 corpora with 3,847,739 verses are available to download and remix, with different levels of granularity but all of them annotated to a certain extent.</p>
                <p>Since corpora have different sizes, formats, and metrical information, we pre-processed each corpus looking for common metadata tags and structures. We then created reusable parsers to extract the relevant information exposed by Averell. The result is a JSON-lines structure capable of capturing the common details of the different corpora. From this common intermediate format, Averell is able to produce data in formats suitable for analysis such as CSV, Parquet, XML TEI, and even POSTDATA RDF triplets.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading2"">
                <head>Conclusions</head>
                <p>In this work, we have introduced the tool Averell for the management and remixing of annotated poetic corporar in a multilingual setting. We have described its structure and showcased a few of its uses in existing scholarly work. We hope to enrich the tool supporting more formats, better interoperability, a larger catalogue, and an easy-to-use web interface.</p>
                <p>Table 1. Corpora available and granularity levels for each</p>
                <table rend=""frame"" xml:id=""Table1"">
                    <note type=""direction"">
                        <width unit=""pt"">51</width>
                        <width unit=""pt"">141</width>
                        <width unit=""pt"">51</width>
                    </note>
                    <row>
                        <cell>Name</cell>
                        <cell>Description</cell>
                        <cell>Granularity</cell>
                    </row>
                    <row>
                        <cell>Disco v2.1 and v3</cell>
                        <cell>The Diachronic Spanish Sonnet Corpus (DISCO) Spanish 15th and the 19th centuries sonnets corpus</cell>
                        <cell>stanza
                            <lb/>line
                        </cell>
                    </row>
                    <row>
                        <cell>Sonetos siglo de oro</cell>
                        <cell>Spanish 16th and the 17th centuries sonnets corpus (Miguel de Cervantes Virtual Library)</cell>
                        <cell>stanza
                            <lb/>line
                        </cell>
                    </row>
                    <row>
                        <cell>ADSO 100</cell>
                        <cell>Spanish Golden age sonnet corpus</cell>
                        <cell>stanza
                            <lb/>line
                        </cell>
                    </row>
                    <row>
                        <cell>Poesía Lírica Castellana del Siglo de Oro</cell>
                        <cell> Golden Age Castilian lyric poetry corpus </cell>
                        <cell>stanza
                            <lb/>line
                            <lb/>word
                            <lb/>syllable
                        </cell>
                    </row>
                    <row>
                        <cell>Gongocorpus</cell>
                        <cell>Luis de Gongora poetry corpus </cell>
                        <cell>stanza
                            <lb/>line
                            <lb/>word
                            <lb/>syllable
                        </cell>
                    </row>
                    <row>
                        <cell>Eighteenth-Century
                            <lb/>Poetry Archive
                        </cell>
                        <cell>English Eighteenth Century poetry corpus</cell>
                        <cell>stanza
                            <lb/>line
                            <lb/>word
                        </cell>
                    </row>
                    <row>
                        <cell>For Better For Verse</cell>
                        <cell>University of Virginia poetry corpus</cell>
                        <cell>Stanza
                            <lb/>line
                        </cell>
                    </row>
                    <row>
                        <cell>Métrique en Ligne</cell>
                        <cell>Université de Caen Normandie (CRISCO) french poetry corpus</cell>
                        <cell>stanza
                            <lb/>line
                        </cell>
                    </row>
                    <row>
                        <cell>Biblioteca Italiana</cell>
                        <cell>Italian Medioevo to Novecento poetry corpus</cell>
                        <cell>stanza </cell>
                    </row>
                    <row>
                        <cell>Corpus of Czech Verse</cell>
                        <cell>Corpus of Czech poetry of the 19th and of the beginning of the 20th centuries</cell>
                        <cell>stanza
                            <lb/>line
                            <lb/>word
                        </cell>
                    </row>
                    <row>
                        <cell>Stichotheque Portuguese</cell>
                        <cell>Stichotheque project portuguese poetry copus</cell>
                        <cell>stanza
                            <lb/>line
                        </cell>
                    </row>
                </table>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Cox, C.</hi> (2011). 
                        <hi rend=""italic"">Corpus Linguistics and Language Documentation: Challenges for Collaboration</hi>. Brill doi:
                        <ref target=""https://doi.org/10.1163/9789401206884_013"">10.1163/9789401206884_013</ref>. 
                        <ptr target=""https://brill.com/view/book/edcoll/9789401206884/B9789401206884-s013.xml""/> (accessed 28 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">De la </hi>
                        <hi rend=""bold"">Rosa, J., Pérez, Á., Hernández, L., Ros, S. and González-Blanco, E.</hi> (2020). Rantanplan, Fast and Accurate Syllabification and Scansion of Spanish Poetry. 
                        <hi rend=""italic"">Procesamiento del Lenguaje Natural</hi>, 
                        <hi rend=""bold"">65</hi>(0): 83–90.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">De la </hi>
                        <hi rend=""bold"">Rosa, J., Pérez, Á., Sisto, M. de, Hernández, L., Díaz, A., Ros, S. and González-Blanco, E.</hi> (2021). Transformers analyzing poetry: multilingual metrical pattern prediction with transfomer-based language models. 
                        <hi rend=""italic"">Neural Computing and Applications</hi> doi:
                        <ref target=""https://doi.org/10.1007/s00521-021-06692-2"">10.1007/s00521-021-06692-2</ref>. 
                        <ptr target=""https://doi.org/10.1007/s00521-021-06692-2""/> (accessed 28 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">González-Blanco, E., Ros Muñoz, S., De la Rosa, J., Pérez Pozo, Á., Hernández, L., De Sisto, M., Díaz, A., Khalil, O., Rodríguez, J. L. and Leguina, L.</hi> (2020). Towards an Ontology for European Poetry doi:
                        <ref target=""https://doi.org/10.5281/zenodo.4299645"">10.5281/zenodo.4299645</ref>. 
                        <ptr target=""https://zenodo.org/record/4299645""/> (accessed 28 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Gries, S. Th.</hi> (2009). What is Corpus Linguistics?. 
                        <hi rend=""italic"">Language and Linguistics Compass</hi>, 
                        <hi rend=""bold"">3</hi>(5): 1225–41 doi:
                        <ref target=""https://doi.org/10.1111/j.1749-818X.2009.00149.x"">10.1111/j.1749-818X.2009.00149.x</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">McEnery, T. and Wilson, A.</hi> (2001). 
                        <hi rend=""italic"">Corpus Linguistics: An Introduction</hi>. Edinburgh University Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Ostler, N.</hi> (2008). Corpora of less studied languages. 
                        <hi rend=""italic"">Corpus Linguistics: An International Handbook</hi>, 
                        <hi rend=""bold"">1</hi>. Walter de Gruyter Berlin: 457–83.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Scannell, K. P.</hi> (2007). The Crњbadсn Project: Corpus building for under-resourced languages. 
                        <hi rend=""italic"">Cahiers Du Cental</hi>, 
                        <hi rend=""bold"">5</hi>. Citeseer: 1.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Xiao, R.</hi> (2010). Corpus creation. In Indurkhya, N. and Damerau, F. (eds), 
                        <hi rend=""italic"">The Handbook of Natural Language Processing</hi>. 2nd edition. CRC PRESS-TAYLOR & FRANCIS GROUP, pp. 147–65.
                    </bibl>
                    <bibl>Corpus-Based Language Studies: An Advanced Resource Book 
                        <hi rend=""italic"">Routledge & CRC Press</hi>
                        <ptr target=""https://www.routledge.com/Corpus-Based-Language-Studies-An-Advanced-Resource-Book/McEnery-Xiao-Tono/p/book/9780415286237""/> (accessed 28 April 2022).
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,collections as data;corpus management;poetic corpora,English,"19th century;20th century;contemporary;database creation, management, and analysis;english;europe;humanities computing;literary studies;software development, systems, analysis and methods"
12022,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Uncovering the Black Fantastic: Piloting Text Similarity Methods for Finding “Lost” Genre Fiction in HathiTrust (Poster),,Nikolaus Nova Parulian;Ryan Dubnicek;Glen Layne-Worthey;Seretha Williams;Clarissa West-White;Isabella Magni;J. Stephen Downie,poster / demo / art installation,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Background</head>
                <p style=""text-align: left; "">Within the tradition of speculative fiction, many sub-genres of literature engage with world-building and speculation about the future of humanity, civilization, and our institutions. While the term “Afrofuturism” is commonly used to describe the ways in which artists and creators of the African Diaspora engage with the intersections of race and technology in their works, the less contested term ""Black Fantastic"" more accurately reflects transcultural iterations of world-building (Iton, 2008). While there is an active scholarly community studying the Black Fantastic (Third Stone, 2021), the use of computational methods in this study is inhibited by a lack of digital collections of Black Fantastic literature. Though the rise of digital libraries has led to new studies and insights into forms and histories of literary genres (Schöch, 2017; Underwood, 2016; Gittel, 2021; Wilkens, 2016), before genre-specific texts can be studied algorithmically, they must first be identified amidst the massive holdings of digital libraries, such as those of the HathiTrust. This project outlines efforts to use text similarity methods to uncover Black Fantastic texts that may be hidden thanks to incomplete metadata or to cataloging practices not conducive to fine-grained genre identification.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Methods & Analysis</head>
                <p style=""text-align: left; "">Catalog searches in the HathiTrust Digital Library (HTDL) of previously-identified Black Fantastic titles revealed a preliminary list of 13 unique titles. Because metadata records for these volumes do not include “black fantastic” or “afrofuturism,” common library catalog tools would not uncover these known items nor other potential Black Fantastic works. This challenge presented an opportunity to deploy technical methods, specifically text-similarity clustering, to reveal volumes of interest potentially hidden within the HTDL. We started by collecting samples of Black-authored fiction and manually labeling those identified as belonging to the Black Fantastic genre, then analyzed the lexical features that best distinguish these from both general fiction and Black-authored non-Fantastic fiction.</p>
                <p style=""text-align: left; "">We randomly sampled 100 volumes each of Black-authored and general fiction, then used HTRC Extracted Features data to aggregate word usage in each volume. Our first attempt at distinguishing Black Fantastic texts necessarily relied on a very limited, 13-volume sample set. We aggregated frequently-used words most closely associated with each genre and generated a Latent Dirichlet Allocation (LDA) topic model (Blei, et al., 2003; Rehurek and Sojka, 2011) to illustrate the different sets of characteristic words for each sub-genre. Figure 1 shows these words for each text class.</p>
                <figure>
                    <graphic n=""1001"" width=""16.002cm"" height=""7.9674861111111115cm"" url=""Pictures/1bfa16802d9d2b232a63e4224bf6eb75.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; text-align: center;"">(a) General fiction (b) Black-authored fiction</p>
                <figure>
                    <graphic n=""1002"" width=""16.002cm"" height=""8.016875cm"" url=""Pictures/cc70e95163589212334d9a65e768c91e.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; text-align: center;"">(c) Black Fantastic fiction</p>
                <p style=""text-align: left; "">Figure 1. Topic model representation of distinctive words in each sub-genre of the sample. We categorized each genre with a 4-topic model. Words that most distinguish topics from the general fiction category include “duke”, “car”, “dollars”, “president”, and others, whereas topics from Black-authored fiction rely most on words such as “preacher”, “church”, religious”, “worship”, “encampments”. Moreover, with the addition of words distinct to Black-authored fiction, the Black Fantastic topical signal relies more on words such as “politer”, “bodkin”, “sundered”, “libels”, “amble”, “oracular”, etc.</p>
                <p style=""text-align: left; "">Next, we use distinct word sets to develop a classification model for the three sub-genres. We experimented with a hierarchical classification system, first attempting to distinguish Black-authored from general fiction, and then to identify the Black Fantastic sub-genre from among all Black-authored fiction. We used the Stochastic Gradient Descent (SGD) algorithm (Bottou, 2012; Pedregosa, et al., 2011) for our classification models based on Term Frequency-Inverse Document Frequency (TF-IDF) features. Figure 2 shows the confusion matrix for each classification of the test set. As we can see, the classification of Black-authored fiction works well, with 90% accuracy on average, but the Black Fantastic classification is less effective, with 67% accuracy and 75% recall. This further implies that our choice of distinctive tokens as a feature to differentiate fictional sub-genres indeed works, but to a lesser degree for detection of the Black Fantastic as a genre. These errors might result from our limited Black Fantastic training set. Beginning with more Black Fantastic texts, and identifying their most distinctive words, might improve the classification model.</p>
                <figure>
                    <graphic n=""1003"" width=""17.114175cm"" height=""5.816027777777777cm"" url=""Pictures/27051f5a7fd7d4a9eda0c1d251523baa.png"" rend=""inline""/>
                </figure>
                <p style=""text-align: left; "">Figure 2. Confusion matrices for a hierarchical classification model. The left-hand matrix represents classification into two collections: general and Black-authored fiction; and the right-hand represents the classification of the Black-authored set into Black Fantastic and general Black-authored works.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Future Work</head>
                <p style=""text-align: left; "">Our next phase will rely on an enriched Black Fantastic dataset in order to improve our classification accuracy. We will also experiment with different features, such as full text (rather than our bag-of-words approach). In spite of limited results for our ultimate goal of discovering new Black Fantastic texts, our success with this model for distinguishing related categories gives reason for optimism given more robust data.</p>
                <p style=""text-align: left; "">Note: This submission is a companion piece to another one focused on the pedagogical aspects of the “Black Fantastic” project.</p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Blei, D. M., Ng, A. Y. and Jordan, M. I.</hi> (2003). Latent dirichlet allocation. The Journal of Machine Learning Research, 3(null): 993–1022.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Bottou, L.</hi> (2012). Stochastic Gradient Descent Tricks. In Montavon, G., Orr, G. B. and Müller, K.-R. (eds), Neural Networks: Tricks of the Trade: Second Edition. (Lecture Notes in Computer Science). Berlin, Heidelberg: Springer, pp. 421–36 doi:
                        <ref target=""https://doi.org/10.1007/978-3-642-35289-8_25"">10.1007/978-3-642-35289-8_25</ref>. 
                        <ref target=""https://doi.org/10.1007/978-3-642-35289-8_25"">https://doi.org/10.1007/978-3-642-35289-8_25</ref> (accessed 1 June 2022).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Gittel, B.</hi> (2021). An Institutional Perspective on Genres: Generic Subtitles in German Literature from 1500-2020. Journal of Cultural Analytics, 6(1). Department of Languages, Literatures, and Cultures: 22086 doi:
                        <ref target=""https://doi.org/10.22148/001c.22086"">10.22148/001c.22086</ref>.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Iton, R.</hi> (2008). In Search of the Black Fantastic: Politics and Popular Culture in the Post-Civil Rights Era. (Transgressing Boundaries: Studies in Black Politics and Black Communities). New York: Oxford University Press doi:
                        <ref target=""https://doi.org/10.1093/acprof:oso/9780195178463.001.0001"">10.1093/acprof:oso/9780195178463.001.0001</ref>. 
                        <ref target=""https://oxford.universitypressscholarship.com/10.1093/acprof:oso/9780195178463.001.0001/acprof-9780195178463"">https://oxford.universitypressscholarship.com/10.1093/acprof:oso/9780195178463.001.0001/acprof-9780195178463</ref> (accessed 1 June 2022).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., et al.</hi> (2011). Scikit-learn: Machine Learning in Python. The Journal of Machine Learning Research, 12(null): 2825–30.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Rehurek, R., and Sojka, P.</hi> (2011) ""Gensim–python framework for vector space modelling."" NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic 3, no. 2.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Schöch, C.</hi> (2017). Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama. Digital Humanities Quarterly, 011(2).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Underwood, T.</hi> (2016). Genre Theory and Historicism. Journal of Cultural Analytics, 2(2). Department of Languages, Literatures, and Cultures: 11063 doi:
                        <ref target=""https://doi.org/10.22148/16.008"">10.22148/16.008</ref>.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">Wilkens, M.</hi> (2016). Genre, Computation, and the Varieties of Twentieth-Century U.S. Fiction. Journal of Cultural Analytics, 2(2). Department of Languages, Literatures, and Cultures: 11065 doi:
                        <ref target=""https://doi.org/10.22148/16.009"">10.22148/16.009</ref>.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""DH-Biblio_author"">About This Journal</hi> | Third Stone | Rochester Institute of Technology 
                        <ref target=""https://scholarworks.rit.edu/thirdstone/about.html"">https://scholarwor
                            <anchor xml:id=""Hlt105049255""/>ks.rit.edu/thirdstone/about.html
                        </ref> (accessed 10 December 2021).
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,black fantastic;hathitrust;lda;literary genre;sgd,English,19th century;20th century;african and african american studies;contemporary;cultural analytics;english;literary studies;north america;text mining and analysis
12029,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Salience in Literary Texts: A Combined Approach to the Relevance of Passages:,,Frederik Arnold;Benjamin Fiechter;Evelyn Gius;Robert Jäschke;Steffen Martus;Michael Vauth,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>A combined approach to the relevance of text passages</head>
                <p>In this contribution, we want to outline insights that arise from combining two distinct approaches to literary texts that analyse the relevance of specific text passages. We have been working on the identification of the 
                    <hi rend=""bold"">narrativity</hi> represented in literary texts as well as on the 
                    <hi rend=""bold"">quotation</hi> of the texts in research to identify passages especially relevant from a hermeneutical perspective. This now allows us to explore whether the structures and patterns that are emerging from these two approaches can be related to each other in a meaningful way.
                </p>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Narrativity as textual relevance criterion</head>
                    <p>Our identification of narrativity of literary prose texts is based on the annotation of events. By considering the core features of events in narrative theory (i.e., being a state, a process in time and change of state) we classify each verbal phrase in a text as change of state, process event, stative event or non-event.
                        <hi rend=""sup"">
                            <note xml:id=""ftn1"" place=""foot"" n=""1"">For a detailed explanation of the manual annotation on which the data used in this contribution is based cf. Vauth and Gius, 2021.</note>
                        </hi>
                        <hi rend=""sup"">,</hi>
                        <hi rend=""sup"">
                            <note xml:id=""ftn2"" place=""foot"" n=""2"">For a description of classification of events as well as the automation approach and results cf. Vauth et al., 2021. </note>
                        </hi> To enable measuring narrativity, this categorical scaling is transposed into a numerical scaling reflecting the degree of narrativity of the event categories. In accordance with a narrative theory understanding of events, we determine the narrativity of the annotation categories with the values 7 (change of state), 5 (process event), 2 (stative event), and 0 (non-event). By additionally smoothing the narrativity value we are able to model the narrativity of a text as a graph.
                        <hi rend=""sup"">
                            <note xml:id=""ftn3"" place=""foot"" n=""3"">For a discussion of the adequacy of this implementation for literary studies, especially with regard to intersubjectivity, cf. Gius and Vauth, 2022.</note>
                        </hi> Figure 1 shows the narrativity graph for the novella 
                        <hi rend=""italic"">Die Judenbuche</hi> by Annette von Droste-Hülshoff which serves as an example for our approach.
                    </p>
                    <p>
                        <figure>
                            <graphic url=""Pictures/5b427b46663d4966e7f1babd6838fed2.png""/>
                            <head>Figure 1. Narrativity score</head>
                        </figure>
                    </p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Key passages: quotation as textual relevance criterion</head>
                    <p>
                        <hi rend=""background-color(#ffffff)"">We consider key passages as parts of a literary text that are especially relevant for interpretation and can differ in length from only a few words to one or more paragraphs. To learn which parts of a text are more relevant than others, we rely on expert knowledge, which we obtain from numerous interpretations of a literary work containing quoted passages. This is a new approach in text and literature studies, that has not been theoretically founded yet; though the term “Schlüsselstelle” (key passage) and equivalents are used regularly in text interpretations in German language.</hi>
                        <hi rend=""sup background-color(#ffffff)"">
                            <note xml:id=""ftn4"" place=""foot"" n=""4"">For more details on key passages and the aim of the project cf. Arnold and Fiechter, 2022.</note>
                        </hi>
                    </p>
                    <p>
                        <hi rend=""background-color(#ffffff)"">For this study, we limit ourselves to a quantitative view. We have analysed 44 interpretations of </hi>
                        <hi rend=""background-color(#ffffff) italic"">Die Judenbuche</hi>
                        <hi rend=""background-color(#ffffff)"">, all in German language, published between 1995 and 2015 and identified quoted passages with a Python tool for quotation detection in fictional texts.</hi>
                        <hi rend=""sup background-color(#ffffff)"">
                            <note xml:id=""ftn5"" place=""foot"" n=""5"">For a detailed explanation, cf. Arnold and Jäschke (accepted). Source code available at: 
                                <ptr target=""https://scm.cms.hu-berlin.de/schluesselstellen/lotte""/>.
                            </note>
                        </hi>
                        <hi rend=""background-color(#ffffff)""> Figure</hi> 2 
                        <hi rend=""background-color(#ffffff)"">visualises the identified quotations over the course of the text; the histogram shows quotation frequency and the graph the smoothed frequency for each verbal phrase identified during the event annotation (cf. Section 1.1). Notably, the beginning and the end are quoted most frequently, together with three other frequently quoted passages. </hi>
                    </p>
                    <p>
                        <figure>
                            <graphic url=""Pictures/e274101ed46c355d8590797e9011c1aa.png""/>
                            <head>Figure 2. Quotation frequency</head>
                        </figure>
                    </p>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Combining the approaches: frequently quoted (key) passages and narrativity</head>
                <p>By combining exploration of narrativity and quotation frequency (cf. Figure 3) we can explore whether a passage is referred to as one that is mainly interesting for the storyline or for the interpretation. Passages with a high narrativity score are particularly important for the plot and the comprehension of the plot, while passages with a low narrativity value more often contain dialogue or narrator comments in which interpretation proposals are already made that are taken up in literary studies texts. For passages with a medium narrativity value, potential interdependencies are difficult to determine on the basis of only one text, but we are aiming to obtain more detailed knowledge on this in the future, including also non-frequency based analyses of references. Also, the beginning and the end of the text seem to be quoted in a different manner. Here quotation frequency and narrativity seem to be connected only loosely. Instead, these borders of the text seem to be used mostly to provide a framework for interpretations, in which the interpreters select the most interesting passages for their intent. </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/e6e11955724c95fea58c4381ae39f107.png""/>
                        <head>Figure 3. Narrativity score and quotation frequency </head>
                    </figure>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Outlook</head>
                <p>While these findings point out how the quotation of text passages may relate to their narrativity, they should be evaluated against a broader corpus of texts. There, the classification of functions of 
                    <hi rend=""background-color(#ffffff)"">quotations</hi> is the most interesting aspect. We assume that plot-orientated 
                    <hi rend=""background-color(#ffffff)"">quotation</hi>s in the secondary literature correlate with higher narrativity, whereas passages quoted in order to develop a more comprehensive interpretation of the text display less narrativity. For evaluating this, we plan to combine our automated analysis of narrativity with the automated detection of key passages.
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Arnold, F. and Fiechter, B.</hi> (2022). Lesen, was wirklich wichtig ist: Die Identifikation von Schlüsselstellen durch ein neues Instrument zur Zitatanalyse. 
                        <hi rend=""italic"">DHd2022: Konferenzabstracts. </hi>
                        <ptr target=""https://doi.org/10.5281/zenodo.6327917""/> (accessed 11 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Arnold, F. and Jäschke, R.</hi> (accepted). Lotte and Annette: A Framework for Finding and Exploring Key Passages in Literary Works. 
                        <hi rend=""italic"">Proceedings of the Workshop on Natural Language Processing for Digital Humanities at ICON 2021</hi>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Gius, E. and Vauth, M.</hi> (2022). Inter Annotator Agreement und Intersubjektivität. 
                        <hi rend=""italic"">DHd2022: Konferenzabstracts</hi>. 
                        <ptr target=""https://doi.org/10.5281/zenodo.6328209""/> (accessed 11 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Vauth, M. and Gius, E.</hi> (2021). Richtlinien für die Annotation narratologischer Ereigniskonzepte. 
                        <hi rend=""italic"">Zenodo</hi>.
                        <ref target=""https://doi.org/10.5281/zenodo.5078174""> </ref>
                        <ptr target=""https://doi.org/10.5281/zenodo.5078174""/> (accessed 11 April 2022).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Vauth, M., Hatzel, H. O., Gius, E. and Biemann, C.</hi> (2021). Automated Event Annotation in Literary Texts. 
                        <hi rend=""italic"">CHR 2021: Computational Humanities Research Conference.</hi> Amsterdam, pp. 333–45.
                        <ref target=""http://ceur-ws.org/Vol-2989/short_paper18.pdf""> </ref>
                        <ptr target=""http://ceur-ws.org/Vol-2989/short_paper18.pdf""/> (accessed 11 April 2022).
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,annotation;hermeneutics;literature analysis;narrativity;relevance,English,"19th century;annotation structures, systems, and methods;data modeling;english;europe;humanities computing;literary studies"
12048,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Computational approaches to literary periodization: an experiment in Italian narrative of 19""th"" and 20""th"" century",,Fabio Ciotti,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Theoretical background</head>
                <p style=""text-align: left; "">Periodization is one of the fundamental topics of literary studies. As Rene Wellek puts it in one of the most notorious and important books of the last century theory of literature: “the concept of period is certainly one of the main instruments of historical knowledge”, meaning, of course, literary-historical knowledge. 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""MHb3gcBk"",""properties"":{""formattedCitation"":""(Wellek, 1956: 268)"",""plainCitation"":""(Wellek, 1956: 268)"",""noteIndex"":0},""citationItems"":[{""id"":23068,""uris"":[""http://zotero.org/users/563326/items/X69H59ED""],""uri"":[""http://zotero.org/users/563326/items/X69H59ED""],""itemData"":{""id"":23068,""type"":""book"",""archive"":""/z-wcorg/"",""event-place"":""New York"",""ISBN"":""0-15-689084-4"",""language"":""English"",""publisher"":""Harcourt, Brace & World"",""publisher-place"":""New York"",""source"":""http://worldcat.org"",""title"":""Theory of literature"",""author"":[{""family"":""Wellek"",""given"":""Ren??."",""suffix"":""Warren, Austin,,""}],""issued"":{""date-parts"":[[""1956""]]}},""locator"":""268""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Wellek, 1956: 268). And yet is one of the most controversial and debated:
                </p>
                <quote>It is virtually impossible to divide periods according to dates for, as [Jurij] Lotman points out, human culture is a dynamic system. Attempts to locate stages of cultural development within strict temporal boundaries contradict that dynamism. 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""fS5WjYLz"",""properties"":{""formattedCitation"":""(Bassnett, 2013: 41)"",""plainCitation"":""(Bassnett, 2013: 41)"",""noteIndex"":0},""citationItems"":[{""id"":23069,""uris"":[""http://zotero.org/users/563326/items/HYAW8M2G""],""uri"":[""http://zotero.org/users/563326/items/HYAW8M2G""],""itemData"":{""id"":23069,""type"":""book"",""archive"":""/z-wcorg/"",""event-place"":""London"",""ISBN"":""978-0-415-50670-0"",""language"":""English"",""publisher"":""Routledge"",""publisher-place"":""London"",""source"":""http://worldcat.org"",""title"":""Translation studies"",""author"":[{""family"":""Bassnett"",""given"":""Susan"",""suffix"":""""}],""issued"":{""date-parts"":[[""2013""]]}},""locator"":""41""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Bassnett, 2013: 41)
                </quote>
                <p style=""text-align: left; "">How it comes that we can hypostatize the dynamic nature of cultural systems, superimposing on them a scalar chronology? How can we say, as Jameson puts it, that Ulysses is something that happened in 1922 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""wceoZivr"",""properties"":{""formattedCitation"":""(Jameson, 1971: 313)"",""plainCitation"":""(Jameson, 1971: 313)"",""noteIndex"":0},""citationItems"":[{""id"":23070,""uris"":[""http://zotero.org/users/563326/items/PPXFBW2C""],""uri"":[""http://zotero.org/users/563326/items/PPXFBW2C""],""itemData"":{""id"":23070,""type"":""book"",""archive"":""/z-wcorg/"",""event-place"":""Princeton (N.J.)"",""ISBN"":""0-691-01311-X"",""language"":""English"",""publisher"":""Princeton University Press"",""publisher-place"":""Princeton (N.J.)"",""source"":""http://worldcat.org"",""title"":""Marxism and form : twentieth-century dialectical theories of literature"",""author"":[{""family"":""Jameson"",""given"":""Fredric."",""suffix"":""""}],""issued"":{""date-parts"":[[""1971""]]}},""locator"":""313""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jameson, 1971: 313)? Following Meneghelli 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""xtBsafhB"",""properties"":{""formattedCitation"":""(Meneghelli, 2013)"",""plainCitation"":""(Meneghelli, 2013)"",""noteIndex"":0},""citationItems"":[{""id"":23071,""uris"":[""http://zotero.org/users/563326/items/94BW622F""],""uri"":[""http://zotero.org/users/563326/items/94BW622F""],""itemData"":{""id"":23071,""type"":""article-journal"",""container-title"":""CLCWeb: Comparative Literature and Culture"",""DOI"":""10.7771/1481-4374.2386"",""ISSN"":""1481-4374"",""issue"":""7"",""journalAbbreviation"":""CLCWeb: Comparative Literature and Culture"",""language"":""en"",""source"":""DOI.org (Crossref)"",""title"":""Periodization, Comparative Literature, and Italian Modernism"",""URL"":""https://docs.lib.purdue.edu/clcweb/vol15/iss7/12"",""volume"":""15"",""author"":[{""family"":""Meneghelli"",""given"":""Donata""}],""accessed"":{""date-parts"":[[""2021"",12,8]]},""issued"":{""date-parts"":[[""2013"",12,31]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Meneghelli, 2013), we can individuate at least 4 critical issues, or even aporias in literary periodization:
                </p>
                <list rend=""numbered"">
                    <item>Historical categories are related to cultural and social phenomena and overlap and interact in complex ways, determining 
                        <hi rend=""italic"">anisochronies</hi> and 
                        <hi rend=""italic"">dischronies</hi>;
                    </item>
                    <item>Most if not all literary-historical categories have an ontological and trans-historical status and meaning embedded in them (take for instance Romanticism or Modernism);</item>
                    <item>Historical categories interact with and are dependent on geospatial ones, resulting in a multiplicity of asynchronous periodizations;</item>
                    <item>The notion of a historical category in literature is strictly associated with the canonical corpus of texts that are considered representative of a period, and the “dialectics between these two poles, period and canon, are complex and manifold” (Meneghelli, 2013: 3).</item>
                </list>
                <p style=""text-align: left; "">This last point is particularly relevant: literary periodization is usually the product of a process of generalization and synthesis, within a historical and social horizon, of the small-scale critical and interpretive practices that characterize the study of literary texts. Being bound to idiosyncratic hermeneutical practices and to the “epistemology of close reading”, periodization suffers from all the pitfalls and limitations of that approach. In the last two decades, the landscape of literary and cultural studies has been enriched by a methodological perspective that is based on a quantitative approach. Among the various disciplinary labels that identify this current in studies, the most common is distant reading, introduced by Franco Moretti in his work on World Literature 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""ximCqQmL"",""properties"":{""formattedCitation"":""(Moretti, 2000)"",""plainCitation"":""(Moretti, 2000)"",""noteIndex"":0},""citationItems"":[{""id"":9395,""uris"":[""http://zotero.org/groups/113737/items/TBZ8UJQZ""],""uri"":[""http://zotero.org/groups/113737/items/TBZ8UJQZ""],""itemData"":{""id"":9395,""type"":""article-magazine"",""container-title"":""The New Left Review"",""issue"":""1"",""language"":""en"",""title"":""Conjectures on World Literature"",""URL"":""http://newleftreview.org/A2094"",""author"":[{""family"":""Moretti"",""given"":""Franco""}],""issued"":{""date-parts"":[[""2000""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Moretti, 2000) and subsequently extended to denote (even retroactively) the entire tradition of quantitative literary studies 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""qgkuCAs2"",""properties"":{""formattedCitation"":""(Moretti, 2013; Underwood, 2019; Piper, 2018; Jockers, 2013)"",""plainCitation"":""(Moretti, 2013; Underwood, 2019; Piper, 2018; Jockers, 2013)"",""noteIndex"":0},""citationItems"":[{""id"":9592,""uris"":[""http://zotero.org/groups/113737/items/NXW5B9R3""],""uri"":[""http://zotero.org/groups/113737/items/NXW5B9R3""],""itemData"":{""id"":9592,""type"":""book"",""abstract"":""How does a literary historian end up thinking in terms of z-scores, principal component analysis, and clustering coefficient?\n\nIn the ten essays collected in this volume, Franco Moretti reconstructs the intellectual trajectory of his philosophy of ‘distant reading’. From the evolutionary model of ‘Modern European Literature’, through the geo-cultural dominant of ‘Conjectures on World Literature’ and ‘Planet Hollywood’ to the quantitative findings of ‘Style, inc.’ and the abstract patterns of ‘Network Theory, Plot Analysis’, the book follows two decades of critical explorations that have come to define – well beyond the wildest expectations of its author – a growing field of unorthodox literary studies."",""event-place"":""London"",""ISBN"":""978-1-78168-084-1"",""language"":""en"",""number-of-pages"":""224"",""publisher"":""Verso"",""publisher-place"":""London"",""title"":""Distant reading"",""URL"":""http://www.amazon.de/Distant-Reading-Franco-Moretti/dp/1781680841"",""author"":[{""family"":""Moretti"",""given"":""Franco""}],""issued"":{""date-parts"":[[""2013""]]}}},{""id"":78,""uris"":[""http://zotero.org/users/563326/items/B3AUADSC""],""uri"":[""http://zotero.org/users/563326/items/B3AUADSC""],""itemData"":{""id"":78,""type"":""book"",""call-number"":""PN73 .U53 2019"",""event-place"":""Chicago"",""ISBN"":""978-0-226-61266-9"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago"",""source"":""Library of Congress ISBN"",""title"":""Distant horizons: digital evidence and literary change"",""title-short"":""Distant horizons"",""author"":[{""family"":""Underwood"",""given"":""Ted""}],""issued"":{""date-parts"":[[""2019""]]}}},{""id"":77,""uris"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""uri"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""itemData"":{""id"":77,""type"":""book"",""call-number"":""PN98.E4 P56 2018"",""event-place"":""Chicago ; London"",""ISBN"":""978-0-226-56861-4"",""number-of-pages"":""243"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago ; London"",""source"":""Library of Congress ISBN"",""title"":""Enumerations: data and literary study"",""title-short"":""Enumerations"",""author"":[{""family"":""Piper"",""given"":""Andrew""}],""issued"":{""date-parts"":[[""2018""]]}}},{""id"":9743,""uris"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""uri"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""itemData"":{""id"":9743,""type"":""book"",""abstract"":""In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture.\n \nMoving beyond the limitations of literary interpretation based on the \""close-reading\"" of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections."",""collection-title"":""Topics in the Digital Humanities"",""ISBN"":""978-0-252-07907-8"",""language"":""en"",""publisher"":""University of Illinois Press"",""title"":""Macroanalysis: Digital Methods and Literary History"",""URL"":""http://books.google.de/books?hl=de&lr=&id=mPOdxQgpOSUC&oi=fnd&pg=PP2&dq=Macroanalysis:+Digital+Methods+and+Literary+History&ots=R8NZyYyjSh&sig=OkLlZGTVZZMmpYgvq8CQgRzlRSw#v=onepage&q=Macroanalysis%3A%20Digital%20Methods%20and%20Literary%20History&f=false"",""author"":[{""family"":""Jockers"",""given"":""Matthew L.""}],""issued"":{""date-parts"":[[""2013"",6]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Moretti, 2013; Underwood, 2019; Piper, 2018; Jockers, 2013). In this framework literary texts are elements of a population whose synchronic and diachronic characteristics should be empirically investigated on a molar scale, adopting statistical-probabilistic and computational methods. This would require the move from 
                    <hi rend=""italic"">interpretation</hi> to 
                    <hi rend=""italic"">explanation</hi> as the primary methodology of scholarly inquiry in the cultural and literary domains 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""fpyviCGK"",""properties"":{""formattedCitation"":""(Ciotti, 2021)"",""plainCitation"":""(Ciotti, 2021)"",""noteIndex"":0},""citationItems"":[{""id"":23073,""uris"":[""http://zotero.org/users/563326/items/NYDFYR4I""],""uri"":[""http://zotero.org/users/563326/items/NYDFYR4I""],""itemData"":{""id"":23073,""type"":""article-journal"",""abstract"":""Since Franco Moretti coined the successful term distant reading, quantitative/computational text analysis methods have gained wide circulation in literary studies. The diffusion of distant reading approaches has raised a lively debate and has attracted various criticisms, both from “traditional literary scholars” and from self-critical adopters. One important reason underlying these critical positions is the fact that it lacks sound and coherent rationales from the point of view of the theory: distant reading is the first methodology in literary studies that does not come with a theory of literature embedded in it. Consequently, all distant reading studies derive their theoretical frameworks and terms from literary theories that mostly rely on the notion that literary texts can be explained only by the way of interpretation. On what grounds, then, can we construct a theory of literature amenable to distant reading methods? I think that the better theoretical frameworks are the cognitive and bio-evolutionistic approaches to literature and cultural evolution studies. These theoretical approaches require a change in the level of description of the literary domain and justify the move from \""interpretation\"" to \""explanation\"" as the real aim of the scholarly inquiry."",""container-title"":""TESTO & SENSO"",""ISSN"":""2036-2293"",""issue"":""23"",""title"":""Distant reading in literary studies: a methodology in quest of theory"",""author"":[{""family"":""Ciotti"",""given"":""Fabio""}],""issued"":{""date-parts"":[[""2021""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Ciotti, 2021). 
                </p>
                <p style=""text-align: left; "">The possible contribution of a distant reading approach to the literary periodization problem, has been previously explored by some important studies, like 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""6nGWCm9S"",""properties"":{""formattedCitation"":""(Jockers, 2013: chap. 6)"",""plainCitation"":""(Jockers, 2013: chap. 6)"",""noteIndex"":0},""citationItems"":[{""id"":9743,""uris"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""uri"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""itemData"":{""id"":9743,""type"":""book"",""abstract"":""In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture.\n \nMoving beyond the limitations of literary interpretation based on the \""close-reading\"" of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections."",""collection-title"":""Topics in the Digital Humanities"",""ISBN"":""978-0-252-07907-8"",""language"":""en"",""publisher"":""University of Illinois Press"",""title"":""Macroanalysis: Digital Methods and Literary History"",""URL"":""http://books.google.de/books?hl=de&lr=&id=mPOdxQgpOSUC&oi=fnd&pg=PP2&dq=Macroanalysis:+Digital+Methods+and+Literary+History&ots=R8NZyYyjSh&sig=OkLlZGTVZZMmpYgvq8CQgRzlRSw#v=onepage&q=Macroanalysis%3A%20Digital%20Methods%20and%20Literary%20History&f=false"",""author"":[{""family"":""Jockers"",""given"":""Matthew L.""}],""issued"":{""date-parts"":[[""2013"",6]]}},""locator"":""6"",""label"":""chapter""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jockers, 2013: chap. 6), 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""SFTfOWSB"",""properties"":{""formattedCitation"":""(Piper, 2018: chap. 4)"",""plainCitation"":""(Piper, 2018: chap. 4)"",""noteIndex"":0},""citationItems"":[{""id"":77,""uris"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""uri"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""itemData"":{""id"":77,""type"":""book"",""call-number"":""PN98.E4 P56 2018"",""event-place"":""Chicago ; London"",""ISBN"":""978-0-226-56861-4"",""number-of-pages"":""243"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago ; London"",""source"":""Library of Congress ISBN"",""title"":""Enumerations: data and literary study"",""title-short"":""Enumerations"",""author"":[{""family"":""Piper"",""given"":""Andrew""}],""issued"":{""date-parts"":[[""2018""]]}},""locator"":""4"",""label"":""chapter""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Piper, 2018: chap. 4), 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""JXUMQRFz"",""properties"":{""formattedCitation"":""(Underwood, 2019)"",""plainCitation"":""(Underwood, 2019)"",""noteIndex"":0},""citationItems"":[{""id"":78,""uris"":[""http://zotero.org/users/563326/items/B3AUADSC""],""uri"":[""http://zotero.org/users/563326/items/B3AUADSC""],""itemData"":{""id"":78,""type"":""book"",""call-number"":""PN73 .U53 2019"",""event-place"":""Chicago"",""ISBN"":""978-0-226-61266-9"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago"",""source"":""Library of Congress ISBN"",""title"":""Distant horizons: digital evidence and literary change"",""title-short"":""Distant horizons"",""author"":[{""family"":""Underwood"",""given"":""Ted""}],""issued"":{""date-parts"":[[""2019""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Underwood, 2019) for English narrative fiction, all based on a supervised classification approach; while 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""XdMNW8Qe"",""properties"":{""formattedCitation"":""(Jannidis and Lauer, 2014)"",""plainCitation"":""(Jannidis and Lauer, 2014)"",""noteIndex"":0},""citationItems"":[{""id"":14351,""uris"":[""http://zotero.org/groups/643516/items/4DAVX3FR""],""uri"":[""http://zotero.org/groups/643516/items/4DAVX3FR""],""itemData"":{""id"":14351,""type"":""chapter"",""container-title"":""Distant Readings. Topologies of German Culture in the Long Nineteenth Century"",""event-place"":""Rochester"",""language"":""en"",""note"":""bibtex: jannidis_burrowss_2014"",""page"":""29-54"",""publisher"":""Camden House"",""publisher-place"":""Rochester"",""title"":""Burrows’s Delta and Its Use in German Literary History"",""URL"":""gerhardlauer.de/index.php/download_file/view/335/1/"",""author"":[{""family"":""Jannidis"",""given"":""Fotis""},{""family"":""Lauer"",""given"":""Gerhard""}],""editor"":[{""family"":""Erlin"",""given"":""Matt""},{""family"":""Tatlock"",""given"":""Lynne""}],""issued"":{""date-parts"":[[""2014""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jannidis and Lauer, 2014) for German literature adopted a stylometric method. This paper explores the results of a mainly explorative and unsupervised analysis of a corpus of 19
                    <hi rend=""superscript"">th</hi> and 20th century Italian narrative fiction.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>The corpus and the methodology</head>
                <p style=""text-align: left; "">The main research hypothesis is if adopting computational quantitative methods, it’s possible to identify time-based groupings in a set of texts distributed over a long historical period. Related to this there is the question of whether those eventual groupings are aligned with traditional historical periodization. The corpus consists of 660 Italian novels and short novels written between 1810 and 2000 of different aesthetic ""levels"", canonization status, genre, dimension, and authors’ gender. Admittedly, this corpus is still far from being adequate and well balanced, mainly due to the uneven chronological distribution, but it is sufficient for an exploratory inquiry.</p>
                <p style=""text-align: left; "">I wanted to test if the corpus can be clustered in a chronological sensible way using an algorithmic approach without presuming any prior categorization: this explains the preference for unsupervised methods in this research. In particular, I have adopted two different approaches, based on different assumptions, analytical techniques and features selection:</p>
                <list rend=""numbered"">
                    <item>bootstrap consensus network, following (Eder, 2017) that applies phylogenetic consensus networks method to MFW based clustering;</item>
                    <item>lexicon-based text analysis and subsequent K-Means clustering of the results.</item>
                </list>
                <p style=""text-align: left; "">Fort the first experiment I have adopted the popular stylometric R package 
                    <hi rend=""italic"">Stylo</hi>
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""DOw0LjCA"",""properties"":{""formattedCitation"":""(Eder et al., 2016)"",""plainCitation"":""(Eder et al., 2016)"",""noteIndex"":0},""citationItems"":[{""id"":21620,""uris"":[""http://zotero.org/groups/1624882/items/BUVWB3VR""],""uri"":[""http://zotero.org/groups/1624882/items/BUVWB3VR""],""itemData"":{""id"":21620,""type"":""article-journal"",""container-title"":""The R Journal"",""ISSN"":""2073-4859"",""issue"":""1"",""language"":""en"",""page"":""107-121"",""title"":""Stylometry with R: A Package for Computational Text Analysis"",""volume"":""8"",""author"":[{""family"":""Eder"",""given"":""Maciej""},{""family"":""Rybicki"",""given"":""Jan""},{""family"":""Kestemont"",""given"":""Mike""}],""issued"":{""date-parts"":[[""2016""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Eder et al., 2016) to generate the consensus network dataset, conflating ten hierarchical clusterings generated comparing from 100 to 1000 most frequent words. The resulting output dataset is imported into the network analysis tool Gephi 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""dKwsbgCF"",""properties"":{""formattedCitation"":""(Bastian et al., 2009)"",""plainCitation"":""(Bastian et al., 2009)"",""noteIndex"":0},""citationItems"":[{""id"":21501,""uris"":[""http://zotero.org/groups/1624882/items/NUL5XE72""],""uri"":[""http://zotero.org/groups/1624882/items/NUL5XE72""],""itemData"":{""id"":21501,""type"":""webpage"",""language"":""en"",""title"":""Gephi - The Open Graph Viz Platform"",""URL"":""https://gephi.org/"",""author"":[{""family"":""Bastian"",""given"":""Mathieu""},{""family"":""Heymann"",""given"":""Sebastien""},{""family"":""Jacomy"",""given"":""Mathieu""}],""accessed"":{""date-parts"":[[""2018"",11,26]]},""issued"":{""date-parts"":[[""2009""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Bastian et al., 2009) and each node is associated with an attribute that specifies its decade of composition. Then modularity is calculated with a resolution set at 4, resulting in 10 modules, and the final layout is generated applying the layout algorithm Force Atlas 2.
                </p>
                <p style=""text-align: left; "">The second approach is based on the text analysis of the corpus with the tool 
                    <hi rend=""italic"">Linguistic Inquiry and Word Count</hi> (
                    <hi rend=""italic"">LIWC</hi>) 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""jOFaMGB9"",""properties"":{""formattedCitation"":""(Pennebaker et al., 2015)"",""plainCitation"":""(Pennebaker et al., 2015)"",""noteIndex"":0},""citationItems"":[{""id"":23075,""uris"":[""http://zotero.org/users/563326/items/8PZK35JN""],""uri"":[""http://zotero.org/users/563326/items/8PZK35JN""],""itemData"":{""id"":23075,""type"":""article-journal"",""abstract"":""The paper summarizes the nature of the LIWC2015 text analysis program, including the development of the dictionaries and the basic psychometrics of the output. Results of the 2015 version are compared with the 2007 version."",""DOI"":""10.15781/T29G6Z"",""note"":""publisher: University of Texas at Austin"",""source"":""DOI.org (Datacite)"",""title"":""The Development and Psychometric Properties of LIWC2015"",""URL"":""http://hdl.handle.net/2152/31333"",""author"":[{""family"":""Pennebaker"",""given"":""James W.""},{""family"":""Boyd"",""given"":""Ryan L.""},{""family"":""Jordan"",""given"":""Kayla""},{""family"":""Blackburn"",""given"":""Kate""}],""accessed"":{""date-parts"":[[""2021"",12,8]]},""issued"":{""date-parts"":[[""2015""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Pennebaker et al., 2015). For each text, LIWC produces a vector containing the relative frequencies of various words-classes (E.g.: ""Affect Words"", ""Cognitive Processes"", ""Perceptual Processes"", ""Biological Processes""....). The final output is a low dimensional document matrix, to which I have applied a K-Means clustering process, adopting the Python implementation of the algorithm in the 
                    <hi rend=""italic"">SciKit-Learn</hi> library 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""A7QCNvwN"",""properties"":{""formattedCitation"":""(Pedregosa et al., 2011)"",""plainCitation"":""(Pedregosa et al., 2011)"",""noteIndex"":0},""citationItems"":[{""id"":23079,""uris"":[""http://zotero.org/users/563326/items/AM5MGWGN""],""uri"":[""http://zotero.org/users/563326/items/AM5MGWGN""],""itemData"":{""id"":23079,""type"":""article-journal"",""container-title"":""Journal of Machine Learning Research"",""page"":""2825–2830"",""title"":""Scikit-learn: Machine Learning in Python"",""volume"":""12"",""author"":[{""family"":""Pedregosa"",""given"":""F.""},{""family"":""Varoquaux"",""given"":""G.""},{""family"":""Gramfort"",""given"":""A.""},{""family"":""Michel"",""given"":""V.""},{""family"":""Thirion"",""given"":""B.""},{""family"":""Grisel"",""given"":""O.""},{""family"":""Blondel"",""given"":""M.""},{""family"":""Prettenhofer"",""given"":""P.""},{""family"":""Weiss"",""given"":""R.""},{""family"":""Dubourg"",""given"":""V.""},{""family"":""Vanderplas"",""given"":""J.""},{""family"":""Passos"",""given"":""A.""},{""family"":""Cournapeau"",""given"":""D.""},{""family"":""Brucher"",""given"":""M.""},{""family"":""Perrot"",""given"":""M.""},{""family"":""Duchesnay"",""given"":""E.""}],""issued"":{""date-parts"":[[""2011""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Pedregosa et al., 2011). The choice of the number of clusters has been done evaluating 20 different models with 
                    <hi rend=""italic"">Elbow method</hi> and 
                    <hi rend=""italic"">Silhouette Score</hi> tests, which both indicated an optimal value of 4 clusters.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Results and future directions</head>
                <p style=""text-align: left; "">The results of the stylometric approach represented in Fig.1 shows that the texts clustered in time sensible way are only those written in the second half of the 20
                    <hi rend=""superscript"">th</hi> century (that in the network have a blue color tone), while texts written in the first and second half of the 19
                    <hi rend=""superscript"">th</hi> century e in the first half of 20
                    <hi rend=""superscript"">th</hi> are not clearly separated, with the exception of the island in the upper right part of the graph, which is mostly composed of canonical Italian modernist texts.
                </p>
                <figure>
                    <graphic n=""1001"" width=""12.319cm"" height=""12.319cm"" url=""Pictures/f514364a2180618c1abff11b98f948cf.png"" rend=""inline""/>
                    <head>Consensus Network of the corpus: red 1810-1860; green 1860-1900; yellow 1900-1940; blue 1940-2010</head>
                </figure>
                <p style=""text-align: left; "">This overall result is confirmed by the K-Means approach. For my analysis I have produced two matrices using the LIWC dictionary for Italian 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""Oe6Nh7RK"",""properties"":{""formattedCitation"":""(Agosti and Rellini, 2007)"",""plainCitation"":""(Agosti and Rellini, 2007)"",""noteIndex"":0},""citationItems"":[{""id"":23078,""uris"":[""http://zotero.org/users/563326/items/NXQXPK6N""],""uri"":[""http://zotero.org/users/563326/items/NXQXPK6N""],""itemData"":{""id"":23078,""type"":""article-journal"",""container-title"":""Austin, TX: LIWC. net"",""title"":""The Italian LIWC dictionary"",""author"":[{""family"":""Agosti"",""given"":""A.""},{""family"":""Rellini"",""given"":""A.""}],""issued"":{""date-parts"":[[""2007""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Agosti and Rellini, 2007):
                </p>
                <list rend=""bulleted"">
                    <item>a matrix with all LIWC lexical categories;</item>
                    <item>a matrix limited to the following word categories: Verbs, Pronouns, orthographic signs of represented speech, and categories related to emotional and cognitive activity.</item>
                </list>
                <p style=""text-align: left; "">In this way I can test an additional hypothesis very common in literary-historical and critical scholarship: the linguistic sphere of the cognitive and emotional dimension is a characteristic feature of the evolution of narrative along the nineteenth and twentieth centuries, namely it’s a characteristic of the transition to the Modernism. While the K-Means clustering of the first matrix has very little relation to chronology, the second one provides clear indicators of temporal segmentation (Figure 2). Therefore, we can say that the incidence of the lexicon related to the sphere of thought/consciousness/emotivity is a signal of an evolutional pattern in the Italian novel. Anyway, also in this case the more clearly time-based cluster is that of the text written in the second half of the 20
                    <hi rend=""superscript"">th</hi> century.
                </p>
                <figure>
                    <graphic n=""1002"" width=""13.399322222222223cm"" height=""9.051636111111112cm"" url=""Pictures/7ba82f17121d4aa77bfcec9b222cb72f.png"" rend=""inline""/>
                    <head>K-Means clusters in the document matrix restricted to the cognitive/emotional lexicon</head>
                </figure>
                <p style=""text-align: left; "">In conclusion, the first analysis in general confirms for Italian literature the limited role of the time dimension for clustering texts on a purely stylometric base already observed by 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""rjihgbqd"",""properties"":{""formattedCitation"":""(Jockers, 2013: chap. 6)"",""plainCitation"":""(Jockers, 2013: chap. 6)"",""noteIndex"":0},""citationItems"":[{""id"":9743,""uris"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""uri"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""itemData"":{""id"":9743,""type"":""book"",""abstract"":""In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture.\n \nMoving beyond the limitations of literary interpretation based on the \""close-reading\"" of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections."",""collection-title"":""Topics in the Digital Humanities"",""ISBN"":""978-0-252-07907-8"",""language"":""en"",""publisher"":""University of Illinois Press"",""title"":""Macroanalysis: Digital Methods and Literary History"",""URL"":""http://books.google.de/books?hl=de&lr=&id=mPOdxQgpOSUC&oi=fnd&pg=PP2&dq=Macroanalysis:+Digital+Methods+and+Literary+History&ots=R8NZyYyjSh&sig=OkLlZGTVZZMmpYgvq8CQgRzlRSw#v=onepage&q=Macroanalysis%3A%20Digital%20Methods%20and%20Literary%20History&f=false"",""author"":[{""family"":""Jockers"",""given"":""Matthew L.""}],""issued"":{""date-parts"":[[""2013"",6]]}},""locator"":""6"",""label"":""chapter""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jockers, 2013: chap. 6), as compared to authorship and even author gender. Instead, there is some evidence that quantitative empirical analysis partially confirms the relevance of cognitive/emotional lexicon in the evolution of literature. In this direction, I think that a fruitful development of the research will require a more effective way to identify the presence of cognitive/emotional attitudes in texts. To this end, we are training a streamlined Italian BERT language model to identify the relevant textual blocks, and the provisional results are promising.
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Agosti, A. and Rellini, A.</hi> (2007). The Italian LIWC dictionary. 
                        <hi rend=""italic"">Austin, TX: LIWC. Net</hi>.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Bassnett, S.</hi> (2013). 
                        <hi rend=""italic"">Translation Studies</hi>. London: Routledge.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Bastian, M., Heymann, S. and Jacomy, M.</hi> (2009). Gephi - The Open Graph Viz Platform https://gephi.org/ (accessed 26 November 2018).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Ciotti, F.</hi> (2021). Distant reading in literary studies: a methodology in quest of theory. 
                        <hi rend=""italic"">TESTO & SENSO</hi>(23).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Eder, M.</hi> (2017). Visualization in stylometry: Cluster analysis using networks. 
                        <hi rend=""italic"">Digital Scholarship in the Humanities</hi>, 
                        <hi rend=""bold"">32</hi>(1): 50–64 doi:10.1093/llc/fqv061.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Eder, M., Rybicki, J. and Kestemont, M.</hi> (2016). Stylometry with R: A Package for Computational Text Analysis. 
                        <hi rend=""italic"">The R Journal</hi>, 
                        <hi rend=""bold"">8</hi>(1): 107–21.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jameson, Fredric.</hi> (1971). 
                        <hi rend=""italic"">Marxism and Form : Twentieth-Century Dialectical Theories of Literature</hi>. Princeton (N.J.): Princeton University Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jannidis, F. and Lauer, G.</hi> (2014). Burrows’s Delta and Its Use in German Literary History. In Erlin, M. and Tatlock, L. (eds), 
                        <hi rend=""italic"">Distant Readings. Topologies of German Culture in the Long Nineteenth Century</hi>. Rochester: Camden House, pp. 29–54 gerhardlauer.de/index.php/download_file/view/335/1/.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jockers, M. L.</hi> (2013). 
                        <hi rend=""italic"">Macroanalysis: Digital Methods and Literary History</hi>. (Topics in the Digital Humanities). University of Illinois Press 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">helli, D.</hi> (2013). Periodization, Comparative Literature, and Italian Modernism. 
                        <hi rend=""italic"">CLCWeb: Comparative Literature and Culture</hi>, 
                        <hi rend=""bold"">15</hi>(7) doi:10.7771/1481-4374.2386. https://docs.lib.purdue.edu/clcweb/vol15/iss7/12 (accessed 8 December 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Moretti, F.</hi> (2000). Conjectures on World Literature. 
                        <hi rend=""italic"">The New Left Review</hi> http://newleftreview.org/A2094.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Moretti, F.</hi> (2013). 
                        <hi rend=""italic"">Distant Reading</hi>. London: Verso http://www.amazon.de/Distant-Reading-Franco-Moretti/dp/1781680841.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., et al.</hi> (2011). Scikit-learn: Machine Learning in Python. 
                        <hi rend=""italic"">Journal of Machine Learning Research</hi>, 
                        <hi rend=""bold"">12</hi>: 2825–30.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Pennebaker, J. W., Boyd, R. L., Jordan, K. and Blackburn, K.</hi> (2015). The Development and Psychometric Properties of LIWC2015. University of Texas at Austin doi:10.15781/T29G6Z. http://hdl.handle.net/2152/31333 (accessed 8 December 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Piper, A.</hi> (2018). 
                        <hi rend=""italic"">Enumerations: Data and Literary Study</hi>. Chicago ; London: The University of Chicago Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Underwood, T.</hi> (2019). 
                        <hi rend=""italic"">Distant Horizons: Digital Evidence and Literary Change</hi>. Chicago: The University of Chicago Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Wellek, R., Warren, Austin,,</hi> (1956). 
                        <hi rend=""italic"">Theory of Literature</hi>. New York: Harcourt, Brace & World.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,computational literary studies;distant reading;history of literature;italian modernism;theory of literature,English,19th century;20th century;cultural analytics;english;europe;literary studies;text mining and analysis
